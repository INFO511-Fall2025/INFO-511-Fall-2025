{
  "hash": "32fc919667cad6c4dfac6bec84e4617c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 'AE 04: NYC flights + data preprocessing'\nsubtitle: Suggested answers\ncategories:\n  - Application exercise\n  - Answers\nexecute:\n  warning: false\n  error: false\n---\n\n::: callout-important\nThese are suggested answers.\nThis document should be used as reference only, it's not designed to be an exhaustive key.\n:::\n\n::: {#load-packages .cell message='false' execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler\nimport numpy as np\nfrom nycflights13 import flights\n```\n:::\n\n\n## Exercise 1 - Load data\n\nFill in the blanks:\n\n::: {#5873625f .cell execution_count=2}\n``` {.python .cell-code}\n# Load the flights data\ndf = flights\ndf.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 336776 entries, 0 to 336775\nData columns (total 19 columns):\n #   Column          Non-Null Count   Dtype  \n---  ------          --------------   -----  \n 0   year            336776 non-null  int64  \n 1   month           336776 non-null  int64  \n 2   day             336776 non-null  int64  \n 3   dep_time        328521 non-null  float64\n 4   sched_dep_time  336776 non-null  int64  \n 5   dep_delay       328521 non-null  float64\n 6   arr_time        328063 non-null  float64\n 7   sched_arr_time  336776 non-null  int64  \n 8   arr_delay       327346 non-null  float64\n 9   carrier         336776 non-null  object \n 10  flight          336776 non-null  int64  \n 11  tailnum         334264 non-null  object \n 12  origin          336776 non-null  object \n 13  dest            336776 non-null  object \n 14  air_time        327346 non-null  float64\n 15  distance        336776 non-null  int64  \n 16  hour            336776 non-null  int64  \n 17  minute          336776 non-null  int64  \n 18  time_hour       336776 non-null  object \ndtypes: float64(5), int64(9), object(5)\nmemory usage: 48.8+ MB\n```\n:::\n:::\n\n\nThe `flights` data frame has 336776 rows.\nEach row represents a observation.\n\n## Exercise 2 - **Data cleaning**\n\nRemove rows with missing values in the `arr_delay` and `distance` columns.\n\nWhat are the names of the variables in `flights`.\n\n::: {#remove-nans .cell execution_count=3}\n``` {.python .cell-code}\ndf_clean = df.dropna(subset=['arr_delay', 'distance'])\n```\n:::\n\n\n## Exercise 3 - Original Data Distribution\n\n-   Plot the original distributions of `arr_delay` and `distance`.\n\n::: {#cell-original-distribution .cell execution_count=4}\n``` {.python .cell-code}\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\nsns.histplot(df_clean['arr_delay'], bins=30, kde=True, ax=axes[0]).set(title='Original Arrival Delay')\nsns.histplot(df_clean['distance'], bins=30, kde=True, ax=axes[1]).set(title='Original Distance')\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](ae-04-flights-preprocessing-A_files/figure-html/original-distribution-output-1.png){#original-distribution width=1334 height=566}\n:::\n:::\n\n\n## Exercise 4 - Check for Skewness\n\n-   Calculate and print the skewness of `arr_delay` and `distance`.\n\n::: {#check-skewness .cell execution_count=5}\n``` {.python .cell-code}\nskew_arr_delay = df_clean['arr_delay'].skew()\nskew_distance = df_clean['distance'].skew()\nprint(f\"Skewness of Arrival Delay: {skew_arr_delay}\")\nprint(f\"Skewness of Distance: {skew_distance}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSkewness of Arrival Delay: 3.716817480457187\nSkewness of Distance: 1.1133926208294944\n```\n:::\n:::\n\n\n## Exercise 5 - Scaling\n\n-   Check the summary statistics of `arr_delay` and `distance` to see if scaling is necessary.\n\n::: {#cell-describe-arr_delay .cell execution_count=6}\n``` {.python .cell-code}\ndf_clean['arr_delay'].describe()\n```\n\n::: {#describe-arr_delay .cell-output .cell-output-display execution_count=6}\n```\ncount    327346.000000\nmean          6.895377\nstd          44.633292\nmin         -86.000000\n25%         -17.000000\n50%          -5.000000\n75%          14.000000\nmax        1272.000000\nName: arr_delay, dtype: float64\n```\n:::\n:::\n\n\n::: {#cell-describe-distance .cell execution_count=7}\n``` {.python .cell-code}\ndf_clean['distance'].describe()\n```\n\n::: {#describe-distance .cell-output .cell-output-display execution_count=7}\n```\ncount    327346.000000\nmean       1048.371314\nstd         735.908523\nmin          80.000000\n25%         509.000000\n50%         888.000000\n75%        1389.000000\nmax        4983.000000\nName: distance, dtype: float64\n```\n:::\n:::\n\n\n-   Question: Do `arr_delay` and `distance` need to be scaled?\n\nYes, the units are completely different.\n\n-   Apply standard scaling, maximum absolute scaling, and Min-Max Scaling to the transformed `arr_delay` and `distance`.\n\n::: {#standardize-data .cell execution_count=8}\n``` {.python .cell-code}\n# Standard Scaling\nscaler = StandardScaler()\ndf_clean.loc[:, ['arr_delay_standard', 'distance_standard']] = scaler.fit_transform(df_clean[['arr_delay', 'distance']])\n\n# Maximum Absolute Scaling\nmax_abs_scaler = MaxAbsScaler()\ndf_clean.loc[:, ['arr_delay_maxabs', 'distance_maxabs']] = max_abs_scaler.fit_transform(df_clean[['arr_delay', 'distance']])\n\n# Min-Max Scaling\nmin_max_scaler = MinMaxScaler()\ndf_clean.loc[:, ['arr_delay_minmax', 'distance_minmax']] = min_max_scaler.fit_transform(df_clean[['arr_delay', 'distance']])\n```\n:::\n\n\n-   Question: What are the two pros and two cons of standardizing data?\n\n#### Pros\n\n1.  **Improved Model Performance**:\n\n    -   **Consistency**: Ensures that features contribute equally to the model, enhancing performance for algorithms like linear regression and neural networks.\n\n    -   **Speed**: Helps optimization algorithms, like gradient descent, converge faster.\n\n2.  **Enhanced Interpretability**:\n\n    -   **Standardization**: Makes model coefficients easier to understand, especially in linear models.\n\n    -   **Comparison**: Simplifies comparison between features during data analysis.\n\n#### Cons\n\n1.  **Potential Loss of Interpretability**:\n\n    -   **Raw Values**: Scaled values might lose their original meaning and units.\n\n2.  **Assumption of Distribution**:\n\n    -   **Normality**: Some methods assume data is normally distributed, which may not always be true.\n\n    -   **Sensitive to Outliers**: Outliers can distort scaled values in methods like standard scaling.\n\n## Exercise 6 - Transformation\n\n-   Check the summary statistics again with your min-max standardized columns.\n\n::: {#be0ace8b .cell execution_count=9}\n``` {.python .cell-code}\ndf_clean['arr_delay_minmax'].describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\ncount    327346.000000\nmean          0.068406\nstd           0.032867\nmin           0.000000\n25%           0.050810\n50%           0.059647\n75%           0.073638\nmax           1.000000\nName: arr_delay_minmax, dtype: float64\n```\n:::\n:::\n\n\n::: {#de8d4abd .cell execution_count=10}\n``` {.python .cell-code}\ndf_clean['distance_minmax'].describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\ncount    327346.000000\nmean          0.197506\nstd           0.150094\nmin           0.000000\n25%           0.087497\n50%           0.164797\n75%           0.266979\nmax           1.000000\nName: distance_minmax, dtype: float64\n```\n:::\n:::\n\n\n-   Question: Why should you use the min-max scaled data instead of a different scaling for the transformations (hint: especially log transformation)\n\nThe other transformations had with negative values for `arr_delay`.\n\n-   Apply a log transformation to `arr_delay` if it is positively skewed and apply a square root transformation to `distance` if it is negatively skewed (use `if` `else` statements).\n\n-   **Hint:** Logical operators in Python:\n\n    | operator      | definition                                               |\n    |:--------------|:---------------------------------------------------------|\n    | `<`           | is less than?                                            |\n    | `<=`          | is less than or equal to?                                |\n    | `>`           | is greater than?                                         |\n    | `>=`          | is greater than or equal to?                             |\n    | `==`          | is exactly equal to?                                     |\n    | `!=`          | is not equal to?                                         |\n    | `x and y`     | is x AND y?                                              |\n    | `x or y`      | is x OR y?                                               |\n    | `pd.isna(x)`  | is x NA?                                                 |\n    | `~pd.isna(x)` | is x not NA?                                             |\n    | `x in y`      | is x in y?                                               |\n    | `x not in y`  | is x not in y?                                           |\n    | `not x`       | is not x? (only makes sense if `x` is `True` or `False`) |\n\n::: {#transform-data .cell execution_count=11}\n``` {.python .cell-code}\nif skew_arr_delay > 0:\n    df_clean.loc[:, 'arr_delay_transformed'] = np.log1p(df_clean['arr_delay_minmax'])\nelse:\n    df_clean.loc[:, 'arr_delay_transformed'] = df_clean['arr_delay_minmax']\n\nif skew_distance > 0:\n    df_clean.loc[:, 'distance_transformed'] = np.sqrt(df_clean['distance_minmax'])\nelse:\n    df_clean.loc[:, 'distance_transformed'] = df_clean['distance_minmax']\n```\n:::\n\n\n-   Question: Why do we have to add a constant when we perform a log or square-root transformation (i.e., `np.log1p(df['column' + 1])`)?\n\nThe logarithmic and square-root functions do not contain negative numbers or 0.\n\n",
    "supporting": [
      "ae-04-flights-preprocessing-A_files"
    ],
    "filters": [],
    "includes": {}
  }
}