{
  "hash": "ec3f3fc58b535c2123fe42c832734160",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Lab 4 - Ethics\ncategories: Lab\nexecute:\n  warning: false\n  error: false\n---\n\n\n# Introduction\n\nIn this lab you'll review and get practice with a variety of concepts, methods, and tools you've encountered thus far, with a focus on misrepresentation and ethics.\n\n## Guidelines\n\nAs we've discussed in lecture, your plots should include an informative title, axes should be labeled, and careful consideration should be given to aesthetic choices.\n\n::: callout-note\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course.\nThere will be periodic reminders in this assignment to remind you to **Run all, commit, and sync** your changes to GitHub.\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment.\n:::\n\n# Part 1 - Misrepresentation\n\n## Question 1\n\nThe following chart was [shared](https://twitter.com/GraphCrimes/status/1566264004288331776) by \\@GraphCrimes on X/Twitter on September 3, 2022.\n\n![](images/private-sector.png){fig-align=\"center\"}\n\na.  What is misleading about this graph?\nb.  Suppose you wanted to recreate this plot, with improvements to avoid its misleading pitfalls from part (a). You would obviously need the data from the survey in order to be able to do that. How many observations would this data have? How many variables (at least) should it have, and what should those variables be?\nc.  Load the data for this survey from `data/survation.csv`. Confirm that the data match the percentages from the visualization. That is, calculate the percentages of public sector, private sector, don't know for each of the services and check that they match the percentages from the plot.\n\n## Question 2\n\nCreate an improved version of the visualization.\nYour improved visualization:\n\n-   should also be a stacked bar chart with services on the y-axis, presented in the same order as the original plot, and services to create the segments of the plot, and presented in the same order as the original plot\n\n-   should have the same legend location\n\n-   should have the same title and caption\n\n-   does not need to have a bolded title or a gray background\n\nHow does the improved visualization look different than the original?\nDoes it send a different message at a first glance?\n\n::: callout-tip\nUse `\\n` to add a line break to your title.\nAnd note that since the title is very long, it might run off the page in your code.\nThat's ok!\n\nAdditionally, the colors used in the plot are `#808080`, `#FF3205`, and `#006697`.\n:::\n\n::: render-commit-push\nRun all, commit, and sync.\n\n<br>\n\nMake sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.\n:::\n\n# Part 2 - DatasauRus\n\nThe data frame you will be working with in this part is called `datasaurus_dozen.csv`.\nThis single data frame contains 13 datasets, designed to show us why data visualization is important and how summary statistics alone can be misleading.\nThe different datasets are marked by the `dataset` variable, as shown in @fig-datasaurus.\n\n![The `datasaurus_dozen` data frame stacks 13 datasets on top of each other. This figure shows the first three datasets.](images/datasaurus-dozen.png){#fig-datasaurus fig-align=\"center\" width=\"432\"}\n\n::: callout-note\nIf it's confusing that the data frame is called `datasaurus_dozen` when it contains 13 datasets, you're not alone!\nHave you heard of a [baker's dozen](https://www.mentalfloss.com/article/32259/why-bakers-dozen-13)?\n:::\n\nHere is a peek at the top 10 rows of the dataset:\n\n::: {#da91897a .cell execution_count=2}\n``` {.python .cell-code}\ndatasaurus = pd.read_csv(\"data/datasaurus_dozen.csv\")\nprint(datasaurus.head(10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  dataset        x        y\n0    dino  55.3846  97.1795\n1    dino  51.5385  96.0256\n2    dino  46.1538  94.4872\n3    dino  42.8205  91.4103\n4    dino  40.7692  88.3333\n5    dino  38.7179  84.8718\n6    dino  35.6410  79.8718\n7    dino  33.0769  77.5641\n8    dino  28.9744  74.4872\n9    dino  26.1538  71.4103\n```\n:::\n:::\n\n\n## Question 3\n\nCalculate the mean of `x`, mean of `y`, standard deviation of `x`, standard deviation of `y`, and the correlation between `x` and `y` for each level of the `dataset` variable.\nThen, in 1-2 sentences, comment on how these summary statistics compare across groups (datasets).\n\n::: callout-tip\nThere are 13 groups but `DataFrame`s only print out 10 rows by default.\nAdd `print(n = 13)` as the last step to display all rows.\n:::\n\n## Question 4\n\nCreate a scatterplot of `y` versus `x` and color and facet it by `dataset`.\nThen, in 1-2 sentences, how these plots compare across groups (datasets).\nHow does your response in this question compare to your response to the previous question and what does this say about using visualizations and summary statistics when getting to know a dataset?\n\n::: render-commit-push\nRun all, commit, and sync.\n\n<br>\n\nMake sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.\n:::\n\n# Part 3 - Election polling\n\nSurveyUSA polled 1,500 US adults between January 31, 2024 and February 2, 2024.\nOf the 1,500 adults, 1,259 were identified by SurveyUSA as being registered to vote, and of these 1,048 were found to be likely to vote in the 2024 November election for President.[^1]\nThe following question was asked to these 1,048 adults:\n\n[^1]: Full survey results can be found at <https://www.surveyusa.com/client/PollReport.aspx?g=300d50f5-303b-4652-b59e-6fbf1b87e24a>.\n\n> 1,048 were found to be likely to vote in the 2024 November election for President and were asked the substantive questions which follow.\n\nResponses were broken down into the following categories:\n\n| Variable | Levels                                     |\n|:---------|:-------------------------------------------|\n| Age      | 18-49; 50+                                 |\n| Vote     | Donald Trump (R); Joe Biden (D); Undecided |\n\nOf the 1,048 responses, 507 were between the ages of 18-49.\nOf the individuals that are between 18-49, 238 individuals responded that they would vote for Donald Trump, 237 said they would vote for Joe Biden, and the remainder were undecided.\nOf the individuals that are 50+, 271 individuals responded that they would vote for Donald Trump, 228 said they would vote for Joe Biden, and the remainder were undecided.\n\n## Question 5\n\na.  Fill in the code below to create a two-way table that summarizes these data.\n\n::: {#ef799c8f .cell execution_count=3}\n``` {.python .cell-code}\nsurvey_counts = pd.DataFrame({\n  'age': [],\n  'vote': [],\n  'n': []\n  })\n\nsurvey_pivot = survey_counts.pivot(index='___', columns='___', values='___')\nsurvey_pivot\n```\n:::\n\n\nFor parts b-d below, use your response starting with `survey_counts`, calculate the desired proportions, and make sure the result is an **ungrouped** data frame with a column for relevant counts, a column for relevant proportions, and a column for the groups you're interested in.\n\nb.  Calculate the proportions of 18-49 year olds and 50+ year olds in this sample.\n\nc.  Calculate the proportions of those who want to vote for Donald Trump, Joe Biden, and those who are undecided in this sample.\n\nd.  Calculate the proportions of individuals in this sample who are planning to vote for each of the candidates or are undecided among those who are 18-49 years old as well as among those who are 50+ years old.\n\n## Question 6\n\na.  Re-create the following visualization that displays relationship between `age` and `vote`.\n\n![](images/surveyusa-trump-biden.png){width=\"500\"}\n\n::: callout-tip\nThe colors used in the plot are `\"#E81B23\"`, `\"#0015BC\"`, and `\"#808080\"`.\nThe theme is `sns.set_theme(style=\"whitegrid\")`\n:::\n\nb.  Based on your calculations so far, as well as your visualization, write 1-3 sentences that describe the relationship, in this sample, between age and plans for presidential vote.\n\n::: render-commit-push\nRun all, commit, and sync.\n\n<br>\n\nMake sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.\n:::\n\n# Part 4 - Ethics\n\n::: callout-important\nThe following two questions ask you to summarize articles on data science ethics.\nYou are not allowed to use Chat GPT or similar tools in answering these questions – you must actually read the articles and summarize them yourself.\nPlease be ethical, at a minimum when discussing ethics!\n:::\n\n## Question 7\n\nFor each of the following websites, first determine whether you're allowed to scrape data from them using tools we've learned in this course.\n\nThen, read (the relevant portions of their) Terms of Use/Service.\n\n-   ESPN: [https://www.espn.com](https://www.espn.com/) / <https://disneytermsofuse.com/english/#License-Grant-and-Restrictions>\n-   X/Twitter: [https://twitter.com](https://twitter.com/) / <https://twitter.com/en/tos>\n-   Rotten Tomatoes: [https://www.rottentomatoes.com](https://www.rottentomatoes.com/) / <https://www.rottentomatoes.com/policies/terms-of-use>\n\nFinally, summarize your findings about whether you can or cannot scrape data from these websites in 1 sentence for each website.\nAdditionally, quote the relevant sentence(s) from the Terms of Use/Service.\n\n::: callout-tip\n### Hint\n\nIn the Terms of Use/Service documents, it might be productive to search for keywords like \"scrape\" or \"scraping\" to find the relevant portions.\n:::\n\n## Question 8\n\nOne current ethical discussion in data science involves the training of \"Large Language Models\" such as ChatGPT.\nThese models are trained using massive corpora (document sets) that include large amounts of work that is covered under copyright law.\nRead the following two articles:\n\n-   [Do Large Language Models Violate Copyright Law?](https://www.dykema.com/news-insights/do-large-language-models-violate-copyright-law.html)\n-   [Reexamining \"Fair Use\" in the Age of AI](https://hai.stanford.edu/news/reexamining-fair-use-age-ai)\n\nWrite a short paragraph (maximum 8 sentences) discussing the arguments on both sides of the discussion over copyright in training large language models.\n\n## Question 9\n\nAnother major ethical discussion in data science resolves around discriminatory biases in machine learning models.\nThese biases can have real-world impacts in lending, criminal justice, hiring, and more.\nMany of these algorithms are so-called “black boxes”, meaning the exact process they take from input to output is unclear.\nRead the following articles:\n\n-   [Amazon scraps secret AI recruiting tool that showed bias against](https://www.ml.cmu.edu/news/news-archive/2016-2020/2018/october/amazon-scraps-secret-artificial-intelligence-recruiting-engine-that-showed-biases-against-women.html)\n-   [The Atlantic: The False Promise of Risk Assessment](https://www.theatlantic.com/technology/archive/2018/01/equivant-compas-algorithm/550646/)\n\nWrite a short paragraph (maximum 8 sentences) discussing the nature of biases in machine learning and in datasets, and any possible solutions that could help limit those biases.\n\n## Question 10\n\nTo complete this exercise you will first need to watch the documentary Coded Bias.\nTo do so, you either need to be on the Duke network or connected to the Duke VPN. Then go to [U of A Libraries Permalink](https://arizona-primo.hosted.exlibrisgroup.com/permalink/f/6ljalh/01UA_ALMA51833593910003843){.uri} and click on \"View Online\".\nOnce you watch the video, write a reflection in 2-5 bullet points highlighting at least one thing that you already knew about (from the course prep materials) and at least one thing you learned from the movie as well as any other aspects of the documentary that you found interesting / enlightening.\n\n::: callout-important\nThis question requires no code, only narrative.\nRemember that, based on the [syllabus](https://datasciaz.netlify.app/course-syllabus.html), you may not use generative AI tools (e.g., Chat GPT) to write narrative on assignments.\n:::\n\n::: render-commit-push\nRun all, commit, and sync one last time.\n\n<br>\n\nMake sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.\n:::\n\n# Wrap-up\n\n## Submission\n\n::: callout-warning\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo.\nWe will be checking these to make sure you have been practicing how to commit and push changes.\n\nYou must turn in the .ipynb file by the submission deadline to be considered \"on time\".\n:::\n\n::: callout-important\n## Checklist\n\nMake sure you have:\n\n-   attempted all questions\n-   run all code in your Jupyter notebook\n-   committed and pushed everything to your GitHub repository such that the Git pane in VS Code is empty\n:::\n\n## Grading\n\nThe lab is graded out of a total of 50 points.\n\nOn Questions 1 through 10, you can earn up to 5 points on each question:\n\n-   5: Response shows excellent understanding and addresses all or almost all of the rubric items.\n\n-   4: Response shows good understanding and addresses most of the rubric items.\n\n-   3: Response shows understanding and addresses a majority of the rubric items.\n\n-   2: Response shows effort and misses many of the rubric items.\n\n-   1: Response does not show sufficient effort or understanding and/or is largely incomplete.\n\n-   0: No attempt.\n\n",
    "supporting": [
      "lab-4_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}