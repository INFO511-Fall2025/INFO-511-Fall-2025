{
  "hash": "a127f8fca1a310eb8fd842a244faf909",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Linear algebra II\nsubtitle: Lecture 23\nformat:\n  revealjs: default\neditor_options:\n  chunk_output_type: console\nexecute:\n  warning: false\n  error: false\n---\n\n# Eigenvalues + Eigenvectors\n\n## Eigenvalues and Eigenvectors {.smaller}\n\n> ::: incremental\n> -   Eigenvalues and eigenvectors decompose a matrix into its fundamental components.\n> -   Eigenvalue equation: $\\mathbf{A} \\mathbf{v} = \\lambda \\mathbf{v}$\n> :::\n\n## Calculating Eigenvalues and Eigenvectors\n\n::: fragment\nWe will be using Python for this...\n:::\n\n::: fragment\n\n::: {#fb3724f7 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nfrom numpy.linalg import eig\nA = np.array([[1, 2], [4, 5]])\neigenvals, eigenvecs = eig(A)\nprint(\"EIGENVALUES:\", eigenvals)\nprint(\"EIGENVECTORS:\", eigenvecs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEIGENVALUES: [-0.46410162  6.46410162]\nEIGENVECTORS: [[-0.80689822 -0.34372377]\n [ 0.59069049 -0.9390708 ]]\n```\n:::\n:::\n\n\n:::\n\n## Eigen decomposition\n\n-   Decomposition formula: $\\mathbf{A} = \\mathbf{Q} \\mathbf{L} \\mathbf{Q}^{-1}$\n\n-   $\\mathbf{Q}$ is the matrix of eigenvectors, $\\mathbf{L}$ is the diagonal matrix of eigenvalues, and $\\mathbf{Q}^{-1}$ is the inverse of $\\mathbf{Q}$\n\n## Recomposing matrices\n\n::: {#24de0e64 .cell execution_count=2}\n``` {.python .cell-code}\nfrom numpy import diag\nfrom numpy.linalg import inv\nQ = eigenvecs\nL = diag(eigenvals)\nR = inv(Q)\nB = Q @ L @ R\nprint(B)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1. 2.]\n [4. 5.]]\n```\n:::\n:::\n\n\n## Applications in Data Science and Machine Learning\n\n-   Principal Component Analysis (PCA): Reduces dimensionality while preserving variance.\n\n-   Eigenvalues in system stability: Determine stability in control systems and differential equations.\n\n## Special Types of Matrices {.smaller}\n\n::: columns\n::: {.column width=\"33.3%\"}\n::: fragment\n**Identity Matrix**: Diagonal of 1s, other elements are 0s.\n\n$$\n\\mathbf{I} = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n$$\n:::\n:::\n\n::: {.column width=\"33.3%\"}\n::: fragment\n**Diagonal Matrix**: Non-zero elements only on the diagonal.\n\n$$\n\\mathbf{D} = \\begin{bmatrix}\n4 & 0 & 0 \\\\\n0 & 5 & 0 \\\\\n0 & 0 & 6\n\\end{bmatrix}\n$$\n:::\n:::\n\n::: {.column width=\"33.3%\"}\n::: fragment\n**Triangular Matrix**: Triangular shape of non-zero elements (upper $\\mathbf{U}$, lower $\\mathbf{L}$).\n\n$$\n\\mathbf{U} = \\begin{bmatrix}1 & 2 & 3 \\\\0 & 4 & 5 \\\\0 & 0 & 6\\end{bmatrix} \\\\ \\mathbf{L} = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n2 & 3 & 0 \\\\\n4 & 5 & 6\n\\end{bmatrix}\n$$\n:::\n:::\n:::\n\n## `ae-16-pca` {.smaller}\n\n**Principal Component Analysis**\n\n::: {#c5f60ad3 .cell execution_count=3}\n\n::: {.cell-output .cell-output-display}\n![](23-linear-algebra-II_files/figure-revealjs/cell-4-output-1.png){width=662 height=523}\n:::\n:::\n\n\n",
    "supporting": [
      "23-linear-algebra-II_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}