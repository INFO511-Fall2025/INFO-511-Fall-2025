{
  "hash": "c37bad24d734b16f80e1c16f7d6c4a82",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Web scraping\nsubtitle: Lecture 8\nformat:\n  revealjs: default\neditor_options:\n  chunk_output_type: console\nexecute:\n  warning: false\n  error: false\n---\n\n## Setup\n\n::: {#4d124fc2 .cell message='false' execution_count=1}\n``` {.python .cell-code}\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom afinn import Afinn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport numpy as np\nimport ssl\ntry:\n    _create_unverified_https_context = ssl._create_unverified_context\nexcept AttributeError:\n    pass\nelse:\n    ssl._create_default_https_context = _create_unverified_https_context\n\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('punkt_tab')\n\nsns.set_style(\"whitegrid\")\n```\n:::\n\n\n## Before continuing...\n\n::: nonincremental\n-   If you haven't yet done so: Install a Chrome browser and the SelectorGadget extension:\n    -   [Chrome](https://www.google.com/chrome/)\n    -   [SelectorGadget](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb?hl=en)\n-   Go to your `ae` repo, commit any remaining changes, push, and then pull for today's application exercise.\n:::\n\n## Reading The Arizona Daily Wildcat\n\n::: question\nHow often do you read The Arizona Daily Wildcat?\n\n-   Every day\n\n-   3-5 times a week\n\n-   Once a week\n\n-   Rarely\n:::\n\n## Reading The Arizona Daily Wildcat\n\n::: question\nWhat do you think is the most common word in the titles of The Arizona Daily Wildcat opinion pieces?\n:::\n\n## Analyzing The Arizona Daily Wildcat\n\n\n::: {#cell-wildcat-common-words .cell message='false' execution_count=3}\n\n::: {.cell-output .cell-output-display}\n![](08-web-scraping_files/figure-revealjs/wildcat-common-words-output-1.png){#wildcat-common-words width=846 height=464}\n:::\n:::\n\n\n## Analyzing The Arizona Daily Wildcat\n\n::: {#48825f9c .cell execution_count=4}\n\n::: {.cell-output .cell-output-display}\n![](08-web-scraping_files/figure-revealjs/cell-5-output-1.png){width=756 height=538}\n:::\n:::\n\n\n## All of this analysis is done in Python! {.centered}\n\n::: hand\n(mostly) with tools you already know!\n:::\n\n## Common works in The Arizona Daily Wildcat titles {.smaller}\n\nCode for the earlier plot:\n\n::: {#b38d88ae .cell execution_count=5}\n``` {.python .cell-code code-line-numbers=\"|1|2|4|5|7-12\"}\nstop_words = set(stopwords.words('english'))\nwildcat['tokens'] = wildcat['title'].apply(lambda x: [word.lower() for word in word_tokenize(x) if word.isalpha() and word.lower() not in stop_words])\n\nword_counts = Counter(word for title in wildcat['tokens'] for word in title)\ncommon_words = pd.DataFrame(word_counts.most_common(20), columns=['word', 'count'])\n\nplt.figure(figsize=(10, 5))\nsns.barplot(x='count', y='word', data=common_words, palette='viridis')\nplt.xlabel('Number of mentions')\nplt.ylabel('Word')\nplt.title('Arizona Daily Wildcat - Opinion pieces\\nCommon words in the most recent opinion pieces')\nplt.show()\n```\n:::\n\n\n## Avg sentiment scores of titles {.smaller}\n\nCode for the earlier plot:\n\n::: {#568b9ae4 .cell execution_count=6}\n``` {.python .cell-code code-line-numbers=\"|1,2|4|6|7|9-10|12-14|16-18|20-29\"}\nstop_words = set(stopwords.words('english'))\nwildcat['tokens'] = wildcat['title'].apply(lambda x: [word.lower() for word in word_tokenize(x) if word.isalpha() and word.lower() not in stop_words])\n\nafinn = Afinn()\n\nwildcat['sentiment'] = wildcat['title'].apply(lambda x: afinn.score(x))\nauthor_sentiment = wildcat.groupby(['author', 'title'])['sentiment'].sum().reset_index()\n\nauthor_summary = author_sentiment.groupby('author').agg(n_articles=('title', 'count'), avg_sentiment=('sentiment', 'mean')).reset_index()\nauthor_summary = author_summary[(author_summary['n_articles'] > 1) & (author_summary['author'].notna())]\n\ntop_positive = author_summary.nlargest(10, 'avg_sentiment')\ntop_negative = author_summary.nsmallest(10, 'avg_sentiment')\ntop_authors = pd.concat([top_positive, top_negative])\n\ntop_authors['neg_pos'] = np.where(top_authors['avg_sentiment'] < 0, 'neg', 'pos')\ntop_authors['label_position'] = np.where(top_authors['neg_pos'] == 'neg', 0.25, -0.25)\ntop_authors = top_authors.sort_values(by='avg_sentiment', ascending=True)\n\nplt.figure(figsize=(8, 6))\nsns.barplot(x='avg_sentiment', y='author', data=top_authors, hue='neg_pos', dodge=False, palette={'neg': '#4d4009', 'pos': '#FF4B91'})\nplt.xlabel('negative  ←     Average sentiment score (AFINN)     →  positive')\nplt.ylabel(None)\nplt.title('The Arizona Daily Wildcat - Opinion pieces\\nAverage sentiment scores of titles by author')\nplt.legend([], [], frameon=False)\nplt.xlim(-5, 5)\nplt.grid(False)\nplt.gca().invert_yaxis()\nplt.show()\n```\n:::\n\n\n## Where is this data coming from? {.smaller}\n\n<https://wildcat.arizona.edu/category/opinions/>\n\n[![](images/daily-wildcat.png){fig-align=\"center\" width=\"602\"}](https://wildcat.arizona.edu/category/opinions/)\n\n## Where is this data coming from? {.smaller}\n\n::: columns\n::: {.column width=\"20%\"}\n[![](images/daily-wildcat.png){fig-align=\"center\" width=\"800\"}](https://wildcat.arizona.edu/category/opinions/)\n:::\n\n::: {.column width=\"80%\"}\n\n::: {#a334adfc .cell execution_count=7}\n``` {.python .cell-code}\nprint(wildcat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                 title            author  \\\n0    BOOK REVIEW: ‘Fresh Fruit, Broken Bodies’ by D...    Andres F. Diaz   \n1    OPINION: The first presidential debate lacked ...       Luke Lawson   \n2    OPINION: College WBB favorites and sleeper pic...  Melisa Guzeloglu   \n3    OPINION: College MBB favorites and sleeper pic...   Nathaniel Levin   \n4    EDITORIAL: A desk altered but opinions thrive ...   Editor-in-Chief   \n..                                                 ...               ...   \n995                      Here’s how to best help Nepal    Hailey Dickson   \n996                        Adderall abuse not harmless    Maddie Pickens   \n997                     Court rule is legitimate judge   Jacob Winkelman   \n998                 Letters to the editor: May 4, 2015  Gabriel Schivone   \n999            Capability imperfectly captured by TCEs    Maddie Pickens   \n\n               date  abstract   column  \\\n0     July 22, 2024       NaN  Opinion   \n1      July 3, 2024       NaN  Opinion   \n2    March 15, 2024       NaN  Opinion   \n3    March 15, 2024       NaN  Opinion   \n4    March 15, 2024       NaN  Opinion   \n..              ...       ...      ...   \n995     May 5, 2015       NaN  Opinion   \n996     May 5, 2015       NaN  Opinion   \n997     May 4, 2015       NaN  Opinion   \n998     May 4, 2015       NaN  Opinion   \n999     May 4, 2015       NaN  Opinion   \n\n                                                   url  \\\n0    https://wildcat.arizona.edu/155604/opinions/bo...   \n1    https://wildcat.arizona.edu/155594/opinions/op...   \n2    https://wildcat.arizona.edu/154146/opinions/s-...   \n3    https://wildcat.arizona.edu/154116/opinions/s-...   \n4    https://wildcat.arizona.edu/154126/opinions/ed...   \n..                                                 ...   \n995  https://wildcat.arizona.edu/123054/opinions/he...   \n996  https://wildcat.arizona.edu/102511/opinions/ad...   \n997  https://wildcat.arizona.edu/127949/opinions/co...   \n998  https://wildcat.arizona.edu/142548/opinions/le...   \n999  https://wildcat.arizona.edu/100073/opinions/ca...   \n\n                                                tokens  sentiment  \n0    [book, review, fresh, fruit, broken, bodies, s...        0.0  \n1    [opinion, first, presidential, debate, lacked,...        0.0  \n2    [opinion, college, wbb, favorites, sleeper, pi...       -1.0  \n3    [opinion, college, mbb, favorites, sleeper, pi...       -1.0  \n4    [editorial, desk, altered, opinions, thrive, w...        0.0  \n..                                                 ...        ...  \n995                                [best, help, nepal]        5.0  \n996                        [adderall, abuse, harmless]       -3.0  \n997                   [court, rule, legitimate, judge]        0.0  \n998                             [letters, editor, may]        0.0  \n999          [capability, imperfectly, captured, tces]        1.0  \n\n[1000 rows x 8 columns]\n```\n:::\n:::\n\n\n:::\n:::\n\n# Web scraping\n\n## Scraping the web: what? why? {.smaller}\n\n-   Increasing amount of data is available on the web\n\n-   These data are provided in an unstructured format: you can always copy&paste, but it's time-consuming and prone to errors\n\n-   Web scraping is the process of extracting this information automatically and transform it into a structured dataset\n\n-   Two different scenarios:\n\n    -   Screen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy).\n\n    -   Web APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files.\n\n## Hypertext Markup Language {.smaller}\n\nMost of the data on the web is still largely available as HTML - while it is structured (hierarchical) it often is not available in a form useful for analysis (flat / tidy).\n\n::: small\n``` html\n<html>\n  <head>\n    <title>This is a title</title>\n  </head>\n  <body>\n    <p align=\"center\">Hello world!</p>\n    <br/>\n    <div class=\"name\" id=\"first\">John</div>\n    <div class=\"name\" id=\"last\">Doe</div>\n    <div class=\"contact\">\n      <div class=\"home\">555-555-1234</div>\n      <div class=\"home\">555-555-2345</div>\n      <div class=\"work\">555-555-9999</div>\n      <div class=\"fax\">555-555-8888</div>\n    </div>\n  </body>\n</html>\n```\n:::\n\n## BeautifulSoup {.smaller}\n\n::: columns\n::: {.column width=\"50%\"}\n-   The **BeautifulSoup** package makes basic processing and manipulation of HTML data straight forward\n-   [beautiful-soup-4.readthedocs.io](https://beautiful-soup-4.readthedocs.io/en/latest/)\n\n::: {#43790d65 .cell message='false' execution_count=8}\n``` {.python .cell-code}\nfrom bs4 import BeautifulSoup\n```\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n[![](images/beautiful-soup.jpg){fig-alt=\"rvest hex logo\" fig-align=\"right\"}](https://rvest.tidyverse.org/)\n:::\n:::\n\n## BeautifulSoup {.smaller}\n\nCore functions:\n\n-   `requests.get(url)` - send an HTTP GET request to a URL\n\n-   `BeautifulSoup(html, 'html.parser')` - parse HTML data from a string\n\n-   `soup.select('selector')` - select specified elements from the HTML document using CSS selectors\n\n-   `element.get_text()` - extract text content from an element\n\n-   `element['attribute']` - extract attribute value from an element\n\n## HTML, BeautifulSoup, & requests {.smaller}\n\n::: {#5784219c .cell execution_count=9}\n``` {.python .cell-code}\nhtml = '''\n<html>\n  <head>\n    <title>This is a title</title>\n  </head>\n  <body>\n    <p align=\"center\">Hello world!</p>\n    <br/>\n    <div class=\"name\" id=\"first\">John</div>\n    <div class=\"name\" id=\"last\">Doe</div>\n    <div class=\"contact\">\n      <div class=\"home\">555-555-1234</div>\n      <div class=\"home\">555-555-2345</div>\n      <div class=\"work\">555-555-9999</div>\n      <div class=\"fax\">555-555-8888</div>\n    </div>\n  </body>\n</html>\n'''\n```\n:::\n\n\n. . .\n\n::: {#c2fe4007 .cell execution_count=10}\n``` {.python .cell-code}\nsoup = BeautifulSoup(html, 'html.parser')\n```\n:::\n\n\n## Selecting elements\n\n::: {#ed9c94f2 .cell execution_count=11}\n``` {.python .cell-code}\np_elements = soup.select('p')\nprint(p_elements)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[<p align=\"center\">Hello world!</p>]\n```\n:::\n:::\n\n\n. . .\n\n::: {#ba1a456a .cell execution_count=12}\n``` {.python .cell-code}\np_text = [p.get_text() for p in p_elements]\nprint(p_text)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['Hello world!']\n```\n:::\n:::\n\n\n. . .\n\n::: {#b0249d4d .cell execution_count=13}\n``` {.python .cell-code}\np_names = [p.name for p in p_elements]\nprint(p_names)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['p']\n```\n:::\n:::\n\n\n. . .\n\n::: {#9a80f4ad .cell execution_count=14}\n``` {.python .cell-code}\np_attrs = [p.attrs for p in p_elements]\nprint(p_attrs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[{'align': 'center'}]\n```\n:::\n:::\n\n\n. . .\n\n::: {#1778c4a6 .cell execution_count=15}\n``` {.python .cell-code}\np_align = [p['align'] for p in p_elements if 'align' in p.attrs]\nprint(p_align)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['center']\n```\n:::\n:::\n\n\n## More selecting tags {.smaller}\n\n::: medium\n\n::: {#9019e198 .cell execution_count=16}\n``` {.python .cell-code}\ndiv_elements = soup.select('div')\nprint(div_elements)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[<div class=\"name\" id=\"first\">John</div>, <div class=\"name\" id=\"last\">Doe</div>, <div class=\"contact\">\n<div class=\"home\">555-555-1234</div>\n<div class=\"home\">555-555-2345</div>\n<div class=\"work\">555-555-9999</div>\n<div class=\"fax\">555-555-8888</div>\n</div>, <div class=\"home\">555-555-1234</div>, <div class=\"home\">555-555-2345</div>, <div class=\"work\">555-555-9999</div>, <div class=\"fax\">555-555-8888</div>]\n```\n:::\n:::\n\n\n:::\n\n. . .\n\n::: medium\n\n::: {#08bbc849 .cell execution_count=17}\n``` {.python .cell-code}\ndiv_text = [div.get_text() for div in div_elements]\nprint(div_text)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['John', 'Doe', '\\n555-555-1234\\n555-555-2345\\n555-555-9999\\n555-555-8888\\n', '555-555-1234', '555-555-2345', '555-555-9999', '555-555-8888']\n```\n:::\n:::\n\n\n:::\n\n## CSS selectors {.smaller}\n\n-   We will use a tool called SelectorGadget to help us identify the HTML elements of interest by constructing a CSS selector which can be used to subset the HTML document.\n-   Some examples of basic selector syntax is below,\n\n::: small\n| Selector            | Example         | Description                                        |\n|:------------------|:------------------|:---------------------------------|\n| .class              | `.title`        | Select all elements with class=\"title\"             |\n| #id                 | `#name`         | Select all elements with id=\"name\"                 |\n| element             | `p`             | Select all \\<p\\> elements                          |\n| element element     | `div p`         | Select all \\<p\\> elements inside a \\<div\\> element |\n| element\\>element    | `div > p`       | Select all \\<p\\> elements with \\<div\\> as a parent |\n| \\[attribute\\]       | `[class]`       | Select all elements with a class attribute         |\n| \\[attribute=value\\] | `[class=title]` | Select all elements with class=\"title\"             |\n:::\n\n## CSS classes and ids\n\n::: {#3ee4d8f9 .cell execution_count=18}\n``` {.python .cell-code}\nname_elements = soup.select('.name')\nprint(name_elements)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[<div class=\"name\" id=\"first\">John</div>, <div class=\"name\" id=\"last\">Doe</div>]\n```\n:::\n:::\n\n\n. . .\n\n::: {#21a5ce9c .cell execution_count=19}\n``` {.python .cell-code}\nfirst_name = soup.select('#first')\nprint(first_name)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[<div class=\"name\" id=\"first\">John</div>]\n```\n:::\n:::\n\n\n## Text with `get_text()`\n\n::: {#f2ec28f5 .cell execution_count=20}\n``` {.python .cell-code}\nhtml = '''\n<p>  \n  This is the first sentence in the paragraph.\n  This is the second sentence that should be on the same line as the first sentence.<br>This third sentence should start on a new line.\n</p>\n'''\n```\n:::\n\n\n. . .\n\n::: {#35ffd5b4 .cell execution_count=21}\n``` {.python .cell-code}\nsoup = BeautifulSoup(html, 'html.parser')\ntext = soup.get_text()\nprint(text)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  \n  This is the first sentence in the paragraph.\n  This is the second sentence that should be on the same line as the first sentence.This third sentence should start on a new line.\n\n\n```\n:::\n:::\n\n\n## HTML tables with `read_html()` {.smaller}\n\n::: {#159578c6 .cell execution_count=22}\n``` {.python .cell-code}\nhtml_table = '''\n<html>\n  <head>\n    <title>This is a title</title>\n  </head>\n  <body>\n    <table>\n      <tr> <th>a</th> <th>b</th> <th>c</th> </tr>\n      <tr> <td>1</td> <td>2</td> <td>3</td> </tr>\n      <tr> <td>2</td> <td>3</td> <td>4</td> </tr>\n      <tr> <td>3</td> <td>4</td> <td>5</td> </tr>\n    </table>\n  </body>\n</html>\n'''\n```\n:::\n\n\n. . .\n\n::: {#33fa3c32 .cell execution_count=23}\n``` {.python .cell-code}\nsoup = BeautifulSoup(html_table, 'html.parser')\ntable = pd.read_html(str(soup.select('table')[0]))[0]\nprint(table)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   a  b  c\n0  1  2  3\n1  2  3  4\n2  3  4  5\n```\n:::\n:::\n\n\n## SelectorGadget\n\n**SelectorGadget** ([selectorgadget.com](http://selectorgadget.com)) is a javascript based tool that helps you interactively build an appropriate CSS selector for the content you are interested in.\n\n![](images/selectorgadget.png){fig-align=\"center\" width=\"1000\"}\n\n# Application exercise\n\n## Opinion articles in The Arizona Daily Wildcat\n\nGo to <https://wildcat.arizona.edu/category/opinions/>.\n\n::: question\nHow many articles are on the page?\n:::\n\n## Goal\n\n::: columns\n::: {.column width=\"50%\"}\n-   Scrape data and organize it in a tabular format in Python\n-   Perform light text parsing to clean data\n-   Summarize and visualze the data\n:::\n\n::: {.column width=\"50%\"}\n![](images/wildcat-data.png){fig-align=\"center\"}\n:::\n:::\n\n## `ae-06`\n\n::: appex\n-   Open a new window in VS Code (File \\> New Window) and open the project called ae.\n-   If there are any uncommitted files, commit them, and then click Pull.\n-   Open the file called `wildcat-scrape.py` and follow along.\n:::\n\n## Recap\n\n-   Use the SelectorGadget identify tags for elements you want to grab\n-   Use BeautifulSoup to first read the whole page (into Python) and then parse the object you've read in to the elements you're interested in\n-   Put the components together in a data frame and analyze it like you analyze any other data\n\n## A new Python workflow {.smaller}\n\n-   When working in a Jupyter notebook, your analysis is re-run each time you execute the notebook\n-   If web scraping in a notebook, you'd be re-scraping the data each time you run the notebook, which is undesirable (and not *nice*)!\n-   An alternative workflow:\n    -   Use a Python script to save your code\n\n    -   Saving interim data scraped using the code in the script as CSV or pickle files\n\n    -   Use the saved data in your analysis in your notebook\n\n# Web scraping considerations\n\n## Ethics: \"Can you?\" vs \"Should you?\"\n\n![](images/ok-cupid-1.png){fig-align=\"center\" width=\"579\"}\n\n::: aside\nSource: Brian Resnick, [Researchers just released profile data on 70,000 OkCupid users without permission](https://www.vox.com/2016/5/12/11666116/70000-okcupid-users-data-release), Vox.\n:::\n\n## \"Can you?\" vs \"Should you?\"\n\n![](images/ok-cupid-2.png){fig-align=\"center\" width=\"699\"}\n\n## Challenges: Unreliable formatting\n\n![](images/unreliable-formatting.png){fig-align=\"center\" width=\"699\"}\n\n::: aside\n[alumni.arizona.edu/celebrate-arizona/notable-alumni](https://alumni.arizona.edu/celebrate-arizona/notable-alumni)\n:::\n\n## Challenges: Data broken into many pages\n\n![](images/many-pages.png){fig-align=\"center\"}\n\n## Workflow: Screen scraping vs. APIs\n\nTwo different scenarios for web scraping:\n\n-   Screen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy)\n\n-   Web APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files\n\n",
    "supporting": [
      "08-web-scraping_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}