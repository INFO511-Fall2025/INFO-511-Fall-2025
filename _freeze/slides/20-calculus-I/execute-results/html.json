{
  "hash": "f45c004ce342f3f74955fb772af3027d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Calculus I\nsubtitle: Lecture 20\nformat:\n  revealjs: default\neditor_options:\n  chunk_output_type: console\nexecute:\n  warning: false\n  error: false\n---\n\n##  {background-image=\"images/calculus.png\"}\n\n## Calculus in data science {.smaller}\n\n::: incremental\n-   **Optimization Algorithms**: Calculus is essential for understanding and implementing optimization algorithms like gradient descent, which are used to minimize error functions in machine learning models.\n\n-   **Modeling Change**: Derivatives help in modeling and understanding the rate of change in various phenomena, which is crucial for predictive analytics and dynamic systems in data science.\n\n-   **Integral Applications**: Integrals are used in calculating areas under curves, which is fundamental for probability distributions, statistical inference, and understanding cumulative effects in data analysis.\n:::\n\n## Functions and their graphs {.smaller}\n\n::: panel-tabset\n## Definition\n\n::: incremental\n-   A function is a relation between a set of inputs and a set of permissible outputs, where each input is related to exactly one output.\n\n-   Mathematical notation: $f(x)$ denotes a function named $f$ with $x$ as the input variable.\n:::\n\n## Examples\n\n-   Linear function: $f(x)=2x+3$\n\n-   Quadratic function: $f(x)=x^2-4x+4$\n\n-   Exponential function: $f(x)=e^x$\n\n-   Logarithmic function: $f(x)=log(x)$\n\n## Plotting\n\n::: columns\n::: {.column width=\"50%\"}\n**Using `matplotlib`**\n\n::: {#f2616d04 .cell execution_count=1}\n\n::: {.cell-output .cell-output-display}\n![](20-calculus-I_files/figure-revealjs/cell-2-output-1.png){width=819 height=449}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n**Using `SymPy`**\n\n::: {#e89cc323 .cell execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![](20-calculus-I_files/figure-revealjs/cell-3-output-1.png){width=950 height=470}\n:::\n:::\n\n\n:::\n:::\n\n## Code\n\n::: columns\n::: {.column width=\"50%\"}\n**Using `matplotlib`**\n\n::: {#b566a0eb .cell execution_count=3}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the function\ndef f(x):\n    return 2 * x + 3\n\n# Generate x values\nx = np.linspace(-10, 10, 400)\ny = f(x)\n\n# Plot the function\nplt.plot(x, y, label='f(x) = 2x + 3')\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.title('Graph of the Linear Function')\nplt.legend()\nplt.grid(True)\nplt.show()\n```\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n**Using `SymPy`**\n\n::: {#ca666400 .cell execution_count=4}\n``` {.python .cell-code}\nfrom sympy import symbols, plot\n\n# Define the variable and function\nx = symbols('x')\nf = 2 * x + 3\n\n# Plot the function\nplot(f)\n```\n:::\n\n\n:::\n:::\n:::\n\n## Importance of functions in modeling {.smaller}\n\n::: incremental\n-   **Predictive Modeling**:\n\n    -   Functions predict outputs from inputs, essential for machine learning.\n\n    -   Example: Linear regression predicts continuous outcomes.\n\n-   **Descriptive Analysis**:\n\n    -   Functions describe relationships, revealing patterns and trends.\n\n    -   Example: Growth functions model population or business growth.\n\n-   **Decision Making**:\n\n    -   Functions formulate decision rules and optimization problems.\n\n    -   Example: Cost functions minimize expenses or maximize profits.\n:::\n\n## Overview of Calculus {.smaller}\n\n> Branch of mathematics that studies continuous change.\n\n::: columns\n::: {.column width=\"50%\"}\n**Differential** (rates of change & slopes of curves)\n\n![](images/derivative.gif){fig-align=\"center\" width=\"444\"}\n:::\n\n::: {.column width=\"50%\"}\n**Integral** (accumulation of quantities & areas under curves)\n\n![](images/integral.gif){fig-align=\"center\" width=\"500\"}\n:::\n:::\n\n## Differentiation and Integration {.smaller}\n\n::: panel-tabset\n## Differentiation\n\n::: incremental\n-   Measures the rate at which a quantity changes.\n\n-   Example: In machine learning, the derivative of the loss function with respect to model parameters helps in finding the optimal parameters.\n\n-   Symbol: $\\frac{dy}{dx}$ of $f^{'}(x)$\n\n-   Practical Application: Gradient Descent Algorithm\n:::\n\n## Integration\n\n::: incremental\n-   Measures the accumulation of quantities and the area under a curve.\n\n-   Example: Used to compute the area under probability distribution functions, which is essential in statistics and data analysis.\n\n-   Symbol: $\\int f(x) dx$\n\n-   Practical Application: Calculating Cumulative Distribution Functions (CDFs)\n:::\n:::\n\n# Derivatives\n\n## Calculating the slope {.smaller}\n\n::: columns\n::: {.column width=\"50%\"}\n![](images/slope.png){fig-align=\"center\"}\n:::\n\n::: {.column width=\"50%\"}\n::: fragment\n$\\text{slope}=\\frac{\\text{rise}}{\\text{run}}$\n:::\n\n::: fragment\n$\\text{slope}=\\frac{\\text{change in distance}(\\Delta x)}{\\text{change in time}(\\Delta t)}$\n:::\n\n::: fragment\n$\\text{slope}=\\frac{x(15)-x(10)}{t(15)-t(10)}$\n:::\n\n::: fragment\n$\\text{slope}=\\frac{202m - 122m}{15s-10s}$\n:::\n\n::: fragment\n$\\text{slope}=\\frac{80m}{5s}=16m/s$\n:::\n:::\n:::\n\n## The derivative\n\n![](images/derivative-1.png){fig-align=\"center\"}\n\n## The derivative\n\n![](images/derivative-2.png){fig-align=\"center\"}\n\n## The derivative\n\n![](images/derivative-3.png){fig-align=\"center\"}\n\n## The derivative\n\n![](images/derivative-4.png){fig-align=\"center\"}\n\n## The derivative\n\n![](images/derivative-5.png){fig-align=\"center\"}\n\n## The derivative\n\n![](images/derivative-6.png){fig-align=\"center\"}\n\n## Derivatives in Python {.smaller}\n\n**Calculating derivatives using SymPy**\n\n::: {#7781fea1 .cell execution_count=5}\n``` {.python .cell-code}\nfrom sympy import symbols, diff\n\nx = symbols('x')\nf = x**2 # x^2\ndf = diff(f)\nprint(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2*x\n```\n:::\n:::\n\n\n## Solving derivatives {.smaller}\n\n**Differentiation rules**\n\n::: incremental\n-   Constant rule: $\\frac{d}{dx} (c) = 0$\n\n-   Power rule: $\\frac{d}{dx} (x^n) = nx^{n-1}$\n\n-   Constant multiple rule: $\\frac{d}{dx} [c \\cdot f(x)] = c \\cdot f'(x)$\n\n-   Sum rule: $\\frac{d}{dx} [f(x) + g(x)] = f'(x) + g'(x)$\n\n-   Difference rule: $\\frac{d}{dx} [f(x) - g(x)] = f'(x) - g'(x)$\n:::\n\n## Example 1: Differentiating a Constant\n\n::: incremental\n-   Function: $f(x) = 7$\n\n-   Derivative: $f'(x) = 0$\n:::\n\n## Example 2: Power rule\n\n::: incremental\n-   Function: $f(x) = x^3$\n\n-   Derivative: $f'(x) = \\frac{d}{dx} (x^3) = 3x^2$\n:::\n\n## Example 3: Constant multiple rule\n\n::: incremental\n-   Function: $f(x) = 5x^2$\n\n-   Derivative: $f'(x) = 5 \\cdot \\frac{d}{dx} (x^2) = 5 \\cdot 2x = 10x$\n:::\n\n## Example 4: Sum and difference rule\n\n::: incremental\n-   Function: $f(x) = x^3 + 4x - 5$\n\n-   Derivative: $f'(x) = \\frac{d}{dx} (x^3) + \\frac{d}{dx} (4x) - \\frac{d}{dx} (5) = 3x^2 + 4 - 0 = 3x^2 + 4$\n:::\n\n## Solving complex derivatives {.smaller}\n\n**Complex Derivatives**:\n\n::: incremental\n-   Involves functions composed of multiple less complex functions.\n\n-   Requires application of rules like the chain rule and product rule for differentiation.\n:::\n\n::: fragment\n**Example Function:** $$\nh(x)=(\\ln(x) \\cdot e^{ax})^k\n$$\n:::\n\n::: incremental\n-   Objective: Find the derivative $\\frac{d}{dx}h(x)$\n:::\n\n## The Chain Rule\n\n$$\n(f(g(x)))^{'}=f{'}(g(x)) \\cdot g{'}(x)\n$$\n\n-   Used when differentiating a composition of functions\n\n## The Chain Rule: Composition {.smaller}\n\n**Function**: $f(x) = (3x^{2} + 2)^{5}$\n\n::: fragment\n1.  **Identify the Outer and Inner Functions**\n\n::: incremental\n-   Outer function: $u^5$\n\n-   Inner function: $u = 3x^2 + 2$\n:::\n:::\n\n::: fragment\n2.  **Apply the Chain Rule**\n\n$f{'}(x) = 5(3x^{2}+2)^{4} \\cdot \\frac{d}{dx}(3x^2 + 2)$\n:::\n\n## The Chain Rule: Composition {.smaller}\n\n**Function**: $f(x) = (3x^{2} + 2)^{5}$\n\n::: fragment\n3.  **Differentiate the Inner Function**\n\n$\\frac{d}{dx}(3x^2 + 2) = 6x$\n:::\n\n::: fragment\n4.  **Combine the results**\n\n$f{'}(x)=5(3x^2 + 2)^{4} \\cdot 6x$\n\n$f{'}(x)=30x(3x^2 + 2)^{4}$\n:::\n\n## The Chain Rule: Nested composition {.smaller}\n\n**Function**: $g(x) = \\sin(x^3 + 4x)$\n\n::: fragment\n1.  **Identify the Outer and Inner Functions**\n\n::: incremental\n-   Outer function: $\\sin(u)$\n\n-   Inner function: $u=x^3+4x$\n:::\n:::\n\n::: fragment\n2.  **Apply the Chain Rule**\n\n$g'(x) = \\cos(x^3 + 4x) \\cdot \\frac{d}{dx}(x^3 + 4x)$\n:::\n\n## The Chain Rule: Nested composition {.smaller}\n\n**Function**: $g(x) = \\sin(x^3 + 4x)$\n\n::: fragment\n3.  **Differentiate the Inner Function**\n\n$\\frac{d}{dx}(x^3 + 4x) = 3x^2 + 4$\n:::\n\n::: fragment\n4.  **Combine the Results**\n\n$g'(x) = \\cos(x^3 + 4x) \\cdot (3x^2 + 4)$\n:::\n\n## The Chain Rule: Complex nested composition {.smaller}\n\n**Function**: $h(x) = \\left( e^{x^2} \\cdot \\ln(x) \\right)^2$\n\n::: fragment\n1.  **Identify the Outer and Inner Functions**\n\n::: incremental\n-   Outer function: $u^2$\n\n-   Inner function: $u=e^{x^{2}} \\cdot \\ln(x)$\n:::\n:::\n\n::: fragment\n2.  **Apply the Chain Rule**\n\n$h'(x) = 2\\left( e^{x^2} \\cdot \\ln(x) \\right) \\cdot \\frac{d}{dx}(e^{x^2} \\cdot \\ln(x))$\n:::\n\n## The Chain Rule: Complex nested composition {.smaller}\n\n**Function**: $h(x) = \\left( e^{x^2} \\cdot \\ln(x) \\right)^2$\n\n::: fragment\n3.  **Differentiate the Inner Function using the Product Rule**\n\n::: incremental\n-   Inner function: $u=e^{x^{2}} \\cdot \\ln(x)$\n\n-   Product rule: $(u \\cdot v)' = u' \\cdot v + u \\cdot v'$\n\n-   Let $u = e^{x^2}$ and $\\quad v = \\ln(x)$\n\n-   $u' = \\frac{d}{dx}(e^{x^2}) = 2xe^{x^2}$\n\n-   $v' = \\frac{d}{dx}(\\ln(x)) = \\frac{1}{x}$\n:::\n:::\n\n## The Chain Rule: Complex nested composition {.smaller}\n\n**Function**: $h(x) = \\left( e^{x^2} \\cdot \\ln(x) \\right)^2$\n\n::: fragment\n4.  **Combine the Produce Rule Results**\n\n::: incremental\n-   $\\frac{d}{dx}(e^{x^2} \\cdot \\ln(x)) = (2xe^{x^2}) \\cdot \\ln(x) + e^{x^2} \\cdot \\frac{1}{x}$\n\n-   $= 2xe^{x^2} \\ln(x) + \\frac{e^{x^2}}{x}$\n:::\n:::\n\n## The Chain Rule: Complex nested composition {.smaller}\n\n**Function**: $h(x) = \\left( e^{x^2} \\cdot \\ln(x) \\right)^2$\n\n::: fragment\n5.  **Combine with the Outer Function Derivative**\n\n::: incremental\n-   $h'(x) = 2\\left( e^{x^2} \\cdot \\ln(x) \\right) \\cdot \\left( 2xe^{x^2} \\ln(x) + \\frac{e^{x^2}}{x} \\right)$\n\n-   Simplify:\n\n-   $h'(x) = 2e^{x^2} \\ln(x) \\left( 2xe^{x^2} \\ln(x) + \\frac{e^{x^2}}{x} \\right)$\n\n-   $h'(x) = 2e^{x^2} \\ln(x) \\left( 2xe^{x^2} \\ln(x) + e^{x^2} \\cdot x^{-1} \\right)$\n:::\n:::\n\n# Partial derivatives\n\n## Partial derivatives {.smaller}\n\n**Definition**:\n\n::: incremental\n-   A partial derivative represents the rate of change of a function with respect to one variable while keeping other variables constant.\n\n-   Notation: $\\frac{\\partial f}{\\partial x}$ denotes the partial derivative of $f$ with respect to $x$.\n:::\n\n## Partial derivatives {.smaller}\n\n**Significance**:\n\n::: incremental\n-   Essential in understanding functions of multiple variables.\n\n-   Crucial for optimization in multivariable calculus.\n\n-   Used in various fields such as physics, engineering, and economics to model complex systems.\n:::\n\n## Application in multi-variable functions {.smaller}\n\n::: fragment\n**Multi-variable functions:**\n\n::: incremental\n-   Functions that depend on two or more variables, e.g., $f(x,y)=x^2+y^2$\n:::\n:::\n\n::: fragment\n**Gradient:**\n\n::: incremental\n-   The vector of all partial derivatives in a function.\n\n-   Indicates the direction of the steepest ascent\n\n-   Notation: $\\nabla f=(\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y})$\n:::\n:::\n\n## Partial derivatives in Python {.smaller}\n\nGiven the function $f(x,y)=x^3+3xy+y^3$, calculate the partial derivatives with respect to $x$ and $y$:\n\n::: {#efc8fd37 .cell execution_count=6}\n``` {.python .cell-code}\nfrom sympy import symbols, diff\n\n# Define the variables and function\nx, y = symbols('x y')\nf = x**3 + 3*x*y + y**3\n\n# Calculate partial derivatives\npartial_x = diff(f, x)\npartial_y = diff(f, y)\n\nprint(partial_x)  # Output: 3*x**2 + 3*y\nprint(partial_y)  # Output: 3*x + 3*y**2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n3*x**2 + 3*y\n3*x + 3*y**2\n```\n:::\n:::\n\n\n## Gradient descent {.smaller}\n\nYou'll learn more about this in [INFO 521: Introduction to Machine Learning](https://infosci.arizona.edu/course/info-521-introduction-machine-learning)\n\n![](images/gradient_descent_line_graph.gif){fig-align=\"center\"}\n\n## `ae-13-derivation`\n\nDerivations (**you will be tested on this in Exam 2**)\n\n",
    "supporting": [
      "20-calculus-I_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}