{
  "hash": "d3805e3f9f4e163b5ef7124177143927",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Logistic regression\nsubtitle: Lecture 17\nformat:\n  revealjs: default\neditor_options:\n  chunk_output_type: console\nexecute:\n  warning: false\n  error: false\n---\n\n## Setup\n\n::: {#d1c4a07f .cell message='false' execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nsns.set_theme(style=\"whitegrid\", rc={\"figure.figsize\": (10, 6), \"axes.labelsize\": 16, \"xtick.labelsize\": 14, \"ytick.labelsize\": 14})\n```\n:::\n\n\n## Recap: Modeling Loans{.smaller}\n\n-   What is the practical difference between a model with parallel and non-parallel lines?\n\n-   What is the definition of R-squared?\n\n-   Why do we choose models based on adjusted R-squared and not R-squared?\n\n## Predict interest rate... {.smaller}\n\nfrom credit utilization and homeownership\n\n\n::: {#rate-util-home-fit .cell execution_count=3}\n``` {.python .cell-code}\nX = loans[['credit_util', 'homeownership']]\nX = pd.get_dummies(X, drop_first=True).astype(float)\ny = loans['interest_rate']\n\nX = sm.add_constant(X)  \nmodel = sm.OLS(y, X).fit()\n```\n:::\n\n\n::: {#rate-util-home-tidy .cell execution_count=4}\n``` {.python .cell-code}\nprint(model.summary2())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                   Results: Ordinary least squares\n=====================================================================\nModel:                OLS              Adj. R-squared:     0.068     \nDependent Variable:   interest_rate    AIC:                59859.3779\nDate:                 2024-08-19 13:43 BIC:                59888.2185\nNo. Observations:     9998             Log-Likelihood:     -29926.   \nDf Model:             3                F-statistic:        243.7     \nDf Residuals:         9994             Prob (F-statistic): 1.25e-152 \nR-squared:            0.068            Scale:              23.309    \n---------------------------------------------------------------------\n                       Coef.  Std.Err.    t    P>|t|   [0.025  0.975]\n---------------------------------------------------------------------\nconst                  9.9250   0.1401 70.8498 0.0000  9.6504 10.1996\ncredit_util            5.3356   0.2074 25.7266 0.0000  4.9291  5.7421\nhomeownership_Mortgage 0.6956   0.1208  5.7590 0.0000  0.4588  0.9323\nhomeownership_Own      0.1283   0.1552  0.8266 0.4085 -0.1760  0.4326\n---------------------------------------------------------------------\nOmnibus:              1150.070       Durbin-Watson:          1.981   \nProb(Omnibus):        0.000          Jarque-Bera (JB):       1616.376\nSkew:                 0.900          Prob(JB):               0.000   \nKurtosis:             3.800          Condition No.:          6       \n=====================================================================\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors\nis correctly specified.\n```\n:::\n:::\n\n\n## Intercept {.smaller}\n\n::: {#864b83f6 .cell ref.label='rate-util-home-tidy' execution_count=5}\n\n::: {.cell-output .cell-output-stdout}\n```\n                   Results: Ordinary least squares\n=====================================================================\nModel:                OLS              Adj. R-squared:     0.068     \nDependent Variable:   interest_rate    AIC:                59859.3779\nDate:                 2024-08-19 13:43 BIC:                59888.2185\nNo. Observations:     9998             Log-Likelihood:     -29926.   \nDf Model:             3                F-statistic:        243.7     \nDf Residuals:         9994             Prob (F-statistic): 1.25e-152 \nR-squared:            0.068            Scale:              23.309    \n---------------------------------------------------------------------\n                       Coef.  Std.Err.    t    P>|t|   [0.025  0.975]\n---------------------------------------------------------------------\nconst                  9.9250   0.1401 70.8498 0.0000  9.6504 10.1996\ncredit_util            5.3356   0.2074 25.7266 0.0000  4.9291  5.7421\nhomeownership_Mortgage 0.6956   0.1208  5.7590 0.0000  0.4588  0.9323\nhomeownership_Own      0.1283   0.1552  0.8266 0.4085 -0.1760  0.4326\n---------------------------------------------------------------------\nOmnibus:              1150.070       Durbin-Watson:          1.981   \nProb(Omnibus):        0.000          Jarque-Bera (JB):       1616.376\nSkew:                 0.900          Prob(JB):               0.000   \nKurtosis:             3.800          Condition No.:          6       \n=====================================================================\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors\nis correctly specified.\n```\n:::\n:::\n\n\n-   Intercept: Loan applicants who rent and have 0 credit utilization are predicted to receive an interest rate of 9.93%, on average.\n\n## Slopes {.smaller}\n\n::: panel-tabset\n## Model\n\n::: {#9f3d00d5 .cell ref.label='rate-util-home-tidy' execution_count=6}\n\n::: {.cell-output .cell-output-stdout}\n```\n                   Results: Ordinary least squares\n=====================================================================\nModel:                OLS              Adj. R-squared:     0.068     \nDependent Variable:   interest_rate    AIC:                59859.3779\nDate:                 2024-08-19 13:43 BIC:                59888.2185\nNo. Observations:     9998             Log-Likelihood:     -29926.   \nDf Model:             3                F-statistic:        243.7     \nDf Residuals:         9994             Prob (F-statistic): 1.25e-152 \nR-squared:            0.068            Scale:              23.309    \n---------------------------------------------------------------------\n                       Coef.  Std.Err.    t    P>|t|   [0.025  0.975]\n---------------------------------------------------------------------\nconst                  9.9250   0.1401 70.8498 0.0000  9.6504 10.1996\ncredit_util            5.3356   0.2074 25.7266 0.0000  4.9291  5.7421\nhomeownership_Mortgage 0.6956   0.1208  5.7590 0.0000  0.4588  0.9323\nhomeownership_Own      0.1283   0.1552  0.8266 0.4085 -0.1760  0.4326\n---------------------------------------------------------------------\nOmnibus:              1150.070       Durbin-Watson:          1.981   \nProb(Omnibus):        0.000          Jarque-Bera (JB):       1616.376\nSkew:                 0.900          Prob(JB):               0.000   \nKurtosis:             3.800          Condition No.:          6       \n=====================================================================\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors\nis correctly specified.\n```\n:::\n:::\n\n\n## Slope\n\n::: incremental\n-   All else held constant, for each additional percent credit utilization is higher, interest rate is predicted to be higher, on average, by 0.0534%.\n\n-   All else held constant, the model predicts that loan applicants who have a mortgage for their home receive 0.696% higher interest rate than those who rent their home, on average.\n\n-   All else held constant, the model predicts that loan applicants who own their home receive 0.128% higher interest rate than those who rent their home, on average.\n:::\n:::\n\n# Transformations\n\n## Predict log(interest rate)\n\n::: {#rate-log-cc-fit .cell execution_count=7}\n``` {.python .cell-code}\nX_log = loans[['credit_checks']]\nX_log = sm.add_constant(X_log)\ny_log = np.log(loans['interest_rate'])\n\nmodel_log = sm.OLS(y_log, X_log).fit()\n```\n:::\n\n\n## Model {.smaller}\n\n::: {#ddb171c0 .cell ref.label='rate-log-cc-fit' execution_count=8}\n\n::: {.cell-output .cell-output-stdout}\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:          interest_rate   R-squared:                       0.020\nModel:                            OLS   Adj. R-squared:                  0.020\nMethod:                 Least Squares   F-statistic:                     202.2\nDate:                Mon, 19 Aug 2024   Prob (F-statistic):           1.91e-45\nTime:                        13:43:48   Log-Likelihood:                -4912.6\nNo. Observations:                9998   AIC:                             9829.\nDf Residuals:                    9996   BIC:                             9844.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P>|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nconst             2.3947      0.005    467.428      0.000       2.385       2.405\ncredit_checks     0.0236      0.002     14.220      0.000       0.020       0.027\n==============================================================================\nOmnibus:                      329.756   Durbin-Watson:                   2.002\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              152.256\nSkew:                          -0.010   Prob(JB):                     8.67e-34\nKurtosis:                       2.396   Cond. No.                         4.17\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n:::\n:::\n\n\n. . .\n\n$$\n\\widehat{log(interest~rate)} = 2.39 + 0.0236 \\times credit~checks\n$$\n\n## Slope {.smaller}\n\n::: {#8eadac9e .cell ref.label='rate-log-cc-fit' execution_count=9}\n\n::: {.cell-output .cell-output-stdout}\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:          interest_rate   R-squared:                       0.020\nModel:                            OLS   Adj. R-squared:                  0.020\nMethod:                 Least Squares   F-statistic:                     202.2\nDate:                Mon, 19 Aug 2024   Prob (F-statistic):           1.91e-45\nTime:                        13:43:48   Log-Likelihood:                -4912.6\nNo. Observations:                9998   AIC:                             9829.\nDf Residuals:                    9996   BIC:                             9844.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P>|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nconst             2.3947      0.005    467.428      0.000       2.385       2.405\ncredit_checks     0.0236      0.002     14.220      0.000       0.020       0.027\n==============================================================================\nOmnibus:                      329.756   Durbin-Watson:                   2.002\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              152.256\nSkew:                          -0.010   Prob(JB):                     8.67e-34\nKurtosis:                       2.396   Cond. No.                         4.17\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n:::\n:::\n\n\n. . .\n\nFor each additional credit check, log of interest rate is predicted to be higher, on average, by 0.0236%.\n\n## Slope {.smaller}\n\n$$\nlog(interest~rate_{x+1}) - log(interest~rate_{x}) =  0.0236\n$$\n\n. . .\n\n$$\nlog(\\frac{interest~rate_{x+1}}{interest~rate_{x}}) = 0.0236\n$$\n\n. . .\n\n$$\ne^{log(\\frac{interest~rate_{x+1}}{interest~rate_{x}})} = e^{0.0236}\n$$\n\n. . .\n\n$$\n\\frac{interest~rate_{x+1}}{interest~rate_{x}} = 1.024\n$$\n\n. . .\n\nFor each additional credit check, interest rate is predicted to be higher, on average, by **a factor of 1.024**.\n\n# Logistic regression\n\n## What is logistic regression?\n\n::: columns\n::: {.column width=\"50%\"}\n::: incremental\n-   Similar to linear regression....\n    but\n\n-   Modeling tool when our response is categorical\n:::\n:::\n\n::: {.column width=\"50%\"}\n![](images/logistic.png){fig-align=\"center\"}\n:::\n:::\n\n## Modelling binary outcomes\n\n::: incremental\n-   Variables with binary outcomes follow the **Bernouilli distribution**:\n\n    -   $y_i \\sim Bern(p)$\n\n    -   $p$: Probability of success\n\n    -   $1-p$: Probability of failure\n\n-   We can't model $y$ directly, so instead we model $p$\n:::\n\n## Linear model\n\n$$\np_i = \\beta_o + \\beta_1 \\times X_1 + \\cdots + \\epsilon\n$$\n\n::: incremental\n-   But remember that $p$ must be between 0 and 1\n\n-   We need a **link function** that transforms the linear model to have an appropriate range\n:::\n\n## Logit link function\n\nThe **logit** function take values between 0 and 1 (probabilities) and maps them to values in the range negative infinity to positive infinity:\n\n$$\nlogit(p) = log \\bigg( \\frac{p}{1 - p} \\bigg)\n$$\n\n\n## This isn't exactly what we need though.....\n\n::: incremental\n-   Recall, the goal is to take values between -$\\infty$ and $\\infty$ and map them to probabilities.\n\n-   We need the opposite of the link function...\n    or the *inverse*\n\n-   Taking the inverse of the logit function will map arbitrary real values back to the range \\[0, 1\\]\n:::\n\n## Generalized linear model {.smaller}\n\n::: fragment\n-   We model the logit (log-odds) of $p$ :\n:::\n\n::: fragment\n$$\nlogit(p) = log \\bigg( \\frac{p}{1 - p} \\bigg) = \\beta_o + \\beta_1 \\times X1_i + \\cdots + \\epsilon \n$$\n:::\n\n::: fragment\n-   Then take the inverse to obtain the predicted $p$:\n:::\n\n::: fragment\n$$\np_i = \\frac{e^{\\beta_o + \\beta_1 \\times X1_i + \\cdots + \\epsilon}}{1 + e^{\\beta_o + \\beta_1 \\times X1_i + \\cdots + \\epsilon}}\n$$\n:::\n\n## A logistic model visualized\n\n::: {#2775e8f6 .cell execution_count=11}\n\n::: {.cell-output .cell-output-display}\n![](17-logistic-regression_files/figure-revealjs/cell-12-output-1.png){width=827 height=537}\n:::\n:::\n\n\n## Takeaways\n\n::: incremental\n-   Generalized linear models allow us to fit models to predict non-continuous outcomes\n\n-   Predicting binary outcomes requires modeling the log-odds of success, where p = probability of success\n:::\n\n",
    "supporting": [
      "17-logistic-regression_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}