[
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "",
    "text": "This course presents fundamental aspects of data science, including Python programming (e.g., data collection, cleaning, visualization), statistics, and mathematics (e.g., linear algebra and calculus). The course establishes the foundation for advanced data-intensive classes, providing both theoretical understanding and practical knowledge essential for comprehending Data Science and its applications.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-description",
    "href": "course-syllabus.html#course-description",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "",
    "text": "This course presents fundamental aspects of data science, including Python programming (e.g., data collection, cleaning, visualization), statistics, and mathematics (e.g., linear algebra and calculus). The course establishes the foundation for advanced data-intensive classes, providing both theoretical understanding and practical knowledge essential for comprehending Data Science and its applications.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-offering",
    "href": "course-syllabus.html#course-offering",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Course offering",
    "text": "Course offering\n468-2251-1 INFO 511 201 – Fundamentals of Data Science",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#instructor-information",
    "href": "course-syllabus.html#instructor-information",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Instructor Information",
    "text": "Instructor Information\n\nInstructor\nDr. Greg Chism,\nAssistant Professor of Practice,\nSchool of Information\ngchism@arizona.edu\nOffice Hours: Tuesdays, 11:30am-12:30pm, or by appointment via Zoom",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#prerequisites",
    "href": "course-syllabus.html#prerequisites",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Prerequisites",
    "text": "Prerequisites\nStudents should be comfortable with mathematical functions of one and two variables, should have at least some familiarity with basic concepts of probability and experience with a programming language.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-format",
    "href": "course-syllabus.html#course-format",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Course Format",
    "text": "Course Format\nAsynchronous online lectures. Videos of each lecture will be available no later than the Monday of each week by 9am AZ time.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-objective",
    "href": "course-syllabus.html#course-objective",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Course Objective",
    "text": "Course Objective\nThis course will (1) discuss effective approaches for acquiring, manipulating, and analyzing data, (2) outline fundamental concepts in programming such as variables, data types, and control structures, (3) discuss the use of Python libraries that are central for data science (e.g., NumPy, Matplotlib), (4) present a solid foundation in descriptive statistics, probability and (5) discuss the mathematical foundations that are essential for data science.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#learning-outcomes",
    "href": "course-syllabus.html#learning-outcomes",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\n\nRecognize the skills required to perform data science tasks from data acquisition to storytelling with data.\nReview fundamental topics in linear algebra and calculus for data science.\nUse Python programming techniques to prepare, visualize, and transform data.\nDemonstrate an understanding of how data science projects are approached.\nCommunicate and present data science projects and results.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Textbooks",
    "text": "Textbooks\nThe following are freely available through the UA’s library system.\n\nData Science from Scratch first principles with Python. Joel Grus. O’Reilly, 2nd edition, 2019. (Main textbook)\nEssential Math for Data Science.\n\nAll remaining books are freely available online.\n\nPython for Data Analysis. Wes McKinneyz. Python for Data Analysis. O’Reilly, 3rd edition 2023.\nPractical Statistics for Data Science. Peter Bruce, Andrew Bruce, Peter Gedeck. O’Rielly, 2016.\nIntroduction to Statistical Learning with Applications in Python. James Garth, Witten Daniela, Hastie Trevor, Tibshirani Robert. Springer, 2021/2023.\nPython Companion to Statistical Thinking in the 21st Century. Russell A. Poldrack.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-competencies",
    "href": "course-syllabus.html#course-competencies",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Course competencies",
    "text": "Course competencies\nThis course is a core requirement for the MS in Data Science. It will help you master the following competencies:\n\nMS1. Students will establish the ability to exercise the four key techniques of computational thinking: decomposition, pattern recognition, abstraction, and algorithms.\nMS2. Students will obtain the skills of collecting, manipulating, and analyzing different types of data at different scales, and interpreting the results properly.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-schedule",
    "href": "course-syllabus.html#course-schedule",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Course Schedule",
    "text": "Course Schedule\nAn up-to-date schedule, assignments, and due dates can be found on the course website: datasciaz.netlify.app.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-community",
    "href": "course-syllabus.html#course-community",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Course Community",
    "text": "Course Community\n\nU of A Community Standard\nAll students must adhere to the U of A Student Rights & Responsibilities: The University of Arizona is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with U of A’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you have a name that differs from those that appear in your official U of A records, please let me know! You’ll be able to note this in the Getting to know you survey.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website: datasciaz.netlify.app.\nI will regularly send course announcements via email and Slack, make sure to check one or the other of these regularly. If an announcement is sent Monday through Thursday, I will assume that you have read the announcement by the next day. If an announcement is sent on a Friday or over the weekend, I will assume that you have read it by Monday.\n\n\nWhere to get help\n\nIf you have a question during lecture, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the course Slack. There is a chance another student has already asked a similar question, so please check the other posts on Slack before adding a new question. If you know the answer to a question posted on Slack, I encourage you to respond!\n\nCheck out the Support page for more resources.\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don’t hesitate to ask.\n\nYou never owe me personal information about your health (mental or physical) but you’re always welcome to talk to me. If I can’t help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this crisis.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#lectures",
    "href": "course-syllabus.html#lectures",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Lectures",
    "text": "Lectures\nThe goal of the lectures is for them to be as interactive as possible. My role as instructor is to introduce you new tools and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. You are expected to meaningfully contribute to in-class exercises and discussion.\nYou are expected to bring a laptop to each class so that you can take part in the in-class exercises. Please make sure your laptop is fully charged before you come to class as the number of outlets in the classroom will not be sufficient to accommodate everyone. See the U of A Libraries loaner technology if you need a loaner laptop.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#activities-assessment",
    "href": "course-syllabus.html#activities-assessment",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nYou will be assessed based on five components: application exercises, assignments, and final project.\n\nApplication exercises\nEach due Friday the following week after assigned, there will be 16 in total\nParts of some lectures will be dedicated to working on Application Exercises (AEs). These exercises which give you an opportunity to practice apply the statistical concepts and code introduced in the prepare assignment. These AEs are due by the end of the week of the corresponding lecture period (Friday at midnight). To submit the AEs all you need to do is to push your work to your GitHub repo.\nBecause these AEs are for practice, they will be graded based on completion, i.e., a good-faith effort has been made in attempting all parts. Successful on-time completion of at least 80% of AEs (will result in full credit for AEs in the final course grade.\n\n\nHomework assignments\nThere will be 6 in total\nIn homework assignments, you will apply what you’ve learned in the videos and during lectures to complete data analysis tasks. You may discuss homework assignments with other students; however, homeworks should be completed and submitted individually. Homework assignments must be typed up using the provided ds.py scripts, all work must be pushed to your GitHub repository for the homework by the deadline.\nHomework assignments are due at 5pm AZ time on the indicated due date.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nSummative assignments\nThere will be two summative assignments in this course. Each assignment will be open-note take-home. Through these assignments you have the opportunity to demonstrate what you’ve learned in the course thus far. The assignments will focus on both conceptual understanding of the content and application through analysis and computational tasks. The content of the assignment will be related to the content in videos and reading assignments, lectures, application exercises, and homework assignments.\nMore detail about the assignments will be given during the semester.\n\n\nProject\nThe purpose of the project is to apply what you’ve learned throughout the semester to analyze an interesting data-driven research question. The project will be completed individually, working through codabench to meet a benchmark. The top 5 individuals will receive 5% extra credit in the class. The write-up will be due on the same day as the end of the competition. More to come on this.\nYou cannot pass this course if you have not completed the project.\nMore information about the project will be provided during the semester.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#grading",
    "href": "course-syllabus.html#grading",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nHomeworks (6, lowest dropped)\n30%\n\n\nProject\n25%\n\n\nSummative assignment 1\n10%\n\n\nSummative assignment 2\n10%\n\n\nApplication Exercises (13 required)\n25%\n\n\n\nWhile there are no specific points allocated to participation, we will be recording your participation (mainly via slack) in periodically throughout the semester, and this information will be used as “extra credit” if you’re in between two grades and a minor bump would help. For reference, this would equate to a 1-2% bump.\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 90\n\n\nB\n80 - 89.99\n\n\nC\n70 - 79.99\n\n\nD\n60 - 69.99\n\n\nE\n50-59.99\n\n\nF\n&lt; 50\n\n\n\nThese are upper bounds for grade cutoffs, depending on the class performance the cutoffs may be lowered but they won’t be increased.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#five-tips-for-success",
    "href": "course-syllabus.html#five-tips-for-success",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. The course has been organized so that the burden of learning is on you. I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you’re not sure about the homework, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings.\nDo the homework. The earlier you start, the better. It’s not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an assignment, for example).\nDon’t procrastinate. The content builds upon what was taught in previous weeks, so if something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, etc. Don’t let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours and work with a member of the teaching team to help you identify a good (re)starting point.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-policies",
    "href": "course-syllabus.html#course-policies",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic honesty\nTL;DR: Don’t cheat!\nPlease abide by the following as you work on assignments in this course:\n\nCollaboration: No work is permitted to be completed collaboratively.\n\nYou may discuss homework assignments with other students; however, you may not directly share (or copy) code or write up with other students. Unauthorized sharing (or copying) of the code or write up will be considered a violation for all students involved, resulting in a 0 for the assignment.\nYou may not discuss or otherwise work with others on the assignments. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the assignment date.\nFor the project, collaboration within teams is not only allowed, but expected. Communication between individuals at a high level is also allowed however you may not share code or components of the project across teams.\nOn assignments you may not directly share work (including code) with another student in this class.\n\nOnline resources: I am well aware that a huge volume of code is available on the web to solve any number of problems. Unless I explicitly tell you not to use something, the course’s policy is that you may make use of any online resources (e.g., StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of generative artificial intelligence (AI): You should treat generative AI, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course1:\n\nCognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning.\nEthical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n\n✅ AI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\n❌ AI tools for narrative: Unless instructed otherwise, you may not use generative AI to write narrative on assignments. In general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you.\n\nYou are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\nIf you are unsure if the use of a particular resource complies with the academic honesty policy, please ask a member of the teaching team.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#college-of-information-science-academic-integrity-policy",
    "href": "course-syllabus.html#college-of-information-science-academic-integrity-policy",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "College of Information Science Academic Integrity Policy",
    "text": "College of Information Science Academic Integrity Policy\nThis policy agreed upon by faculty in the College of Information Science at the University of Arizona (InfoSci) applies in addition to the Dean of Students’ Code of Academic Integrity.\nStudents in courses at the U of A InfoSci are expected to maintain rigor in their academic performance with intent to learn, practice, and overcome challenges toward personal growth and enrichment. As future professionals in digital environments, InfoSci students are also expected to exercise transparency and integrity in collaborations and in the use of tools and resources that may aid completion in assignments for our courses.\nConsider the following PROHIBITED practices in this course, unless the instructor has specifically written instructions or permission to do otherwise:\n\nPosting a question on an online site such as Chegg.com, and copying and pasting some or all of the response into an assessment\nPosting an assessment from the course on online sharing sites such as Course Hero. Aiding other students in violation of academic integrity is also a violation, and is potential copyright infringement.\nGenerating and submitting, in whole or in part, text or code through Artificial Intelligence such as ChatGPT, QuillBot, and text summarizers\nUsing, in whole or in part, computer code not written by the student (for example, from another student, a book, or the internet) in an assignment or project. This includes using such code in modified or unmodified form.\nSearching for solutions to projects or assignments on the internet or through other tools, when your instructor intended for you to learn the solution through exercises (e.g. Googling for the solution to a question on an assignment).\nSimultaneously submitting the same assignment as another student enrolled into the course without prior permission from the instructor\n\nExceptions: Clear Instructions will be Provided\nIn any cases in which this course requires or permits students to use practices in the list above, clear written instructions will specify the tools allowed or required, so students can be certain they are working as instructed. See the U of A InfoSci Academic Integrity Policy, the U of A Code of Academic Integrity and Syllabus policy for more information.\n\nLLMs and ChatGPT\nLarge language models (LLMs) like ChatGPT are a type of artificial intelligence (AI) engine that can look like it generates the code you need for Python homeworks and short answer questions. You are encouraged to use ChatGPT to debug code and experiment. However, abuse of ChatGPT can be traced (e.g., failing to give credit or cite ChatGPT when it is used) which could result in your suspension or termination from the course and even your program of study. Keep in mind, too, that while the code may appear legitimate, early studies have shown ChatGPT is not all that accurate with sophisticated coding. Exercise your scholarly discretion and maintain a sense of integrity in your statistical learning journey.\nSee my additional policies on this subject above.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#late-work-extensions",
    "href": "course-syllabus.html#late-work-extensions",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Late work & extensions",
    "text": "Late work & extensions\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework assignment will be dropped to accommodate such circumstances.\n\nhomeworks may be submitted up to 2 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThere is no late work accepted for application exercises, since these are designed to help you prepare for other assessments in the course.\nThere is no late work accepted for assignments.\nThe late work policy for the project will be provided with the project instructions.\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing an application exercise or homework assignment by the stated due date, you may email me (gchism@arizona.edu) before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used for once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let me know if you need help contacting your academic dean.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#regrade-requests",
    "href": "course-syllabus.html#regrade-requests",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Regrade requests",
    "text": "Regrade requests\nRegrade requests must be submitted on GitHub within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the project presentations.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#incomplete-grade",
    "href": "course-syllabus.html#incomplete-grade",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "“Incomplete” grade",
    "text": "“Incomplete” grade\nThe grade of “I” may be awarded only at the end of a term, when all but a minor portion of the course work has been satisfactorily completed. The grade of I is not to be awarded in place of a failing grade or when the student is expected to repeat the course; in such a case, a grade other than I must be assigned. Students should make arrangements with the instructor to receive an incomplete grade before the end of the term. If the incomplete is not removed by the instructor within one year the I grade will revert to a failing grade.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#tutoring",
    "href": "course-syllabus.html#tutoring",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Tutoring",
    "text": "Tutoring\nTutoring can be found through the U of A Think Tank.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#accessibility",
    "href": "course-syllabus.html#accessibility",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Accessibility",
    "text": "Accessibility\nAccessibility and Accommodations: At the University of Arizona, we strive to make learning experiences as accessible as possible. If you anticipate or experience barriers based on disability or pregnancy, please contact the Disability Resource Center (520-621-3268, https://drc.arizona.edu) to establish reasonable accommodations.\nNote: If you’ve read this far in the syllabus, email me a picture of your pet if you have one or your favorite meme!",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#additional-university-policies",
    "href": "course-syllabus.html#additional-university-policies",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Additional university policies",
    "text": "Additional university policies\nAdditional policies can be found at this link (please read through them): https://catalog.arizona.edu/syllabus-policies",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#safety-on-campus-and-in-the-classroom",
    "href": "course-syllabus.html#safety-on-campus-and-in-the-classroom",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Safety on Campus and in the Classroom",
    "text": "Safety on Campus and in the Classroom\nFor a list of emergency procedures for all types of incidents, please visit the website of the Critical Incident Response Team (CIRT): https://cirt.arizona.edu/case-emergency/overview\nAlso watch the video available at https://arizona.sabacloud.com/Saba/Web_spf/NA7P1PRD161/common/learningeventdetail/crtfy000000000003560",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#important-dates",
    "href": "course-syllabus.html#important-dates",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Important dates",
    "text": "Important dates\n\nWednesday, January 15: Classes begin\nMonday, January 20: Martin Luther King Jr. Day\nWednesday, January 22: Drop/add ends\nTuesday, February 11: Last day to drop without a W (withdraw)\nSaturday, March 8 - Sunday, March 16: Spring recess ☀️\nTuesday, April 01: Last day to withdraw from a class online through UAccess\nWednesday, May 07: Last day of class, no registration changes can be made\nWednesday, May 14: Project reports, due by 5pm AZ time\n\nFor more important dates, see the full U of A Academic Calendar.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#graduate-student-resources",
    "href": "course-syllabus.html#graduate-student-resources",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Graduate Student Resources",
    "text": "Graduate Student Resources\nUniversity of Arizona’s Basic Needs Resources page for graduate students: http://basicneeds.arizona.edu/index.html",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#footnotes",
    "href": "course-syllabus.html#footnotes",
    "title": "INFO 511 - Fundamentals of Data Science",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D.↩︎",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "computing/computing-git.html",
    "href": "computing/computing-git.html",
    "title": "Setting up Git",
    "section": "",
    "text": "Git is a distributed version control system that allows developers to track changes in their code, collaborate with others, and manage different versions of their projects. GitHub, on the other hand, is a web-based platform built around Git’s functionality, offering a place to host repositories, collaborate with others, and provide tools for code review, project management, and community interaction. While Git provides the underlying version control capabilities, GitHub enhances these capabilities with a user-friendly interface and additional features. Together, they are crucial for modern software development, fostering collaboration, ensuring code integrity, and enabling the open-source movement.",
    "crumbs": [
      "Computing",
      "Setting up Git"
    ]
  },
  {
    "objectID": "computing/computing-git.html#git-vs.-github",
    "href": "computing/computing-git.html#git-vs.-github",
    "title": "Setting up Git",
    "section": "",
    "text": "Git is a distributed version control system that allows developers to track changes in their code, collaborate with others, and manage different versions of their projects. GitHub, on the other hand, is a web-based platform built around Git’s functionality, offering a place to host repositories, collaborate with others, and provide tools for code review, project management, and community interaction. While Git provides the underlying version control capabilities, GitHub enhances these capabilities with a user-friendly interface and additional features. Together, they are crucial for modern software development, fostering collaboration, ensuring code integrity, and enabling the open-source movement.",
    "crumbs": [
      "Computing",
      "Setting up Git"
    ]
  },
  {
    "objectID": "computing/computing-git.html#installing-git",
    "href": "computing/computing-git.html#installing-git",
    "title": "Setting up Git",
    "section": "Installing Git",
    "text": "Installing Git\n\nFor Mac:\n\nCheck Existing Installation: Since macOS might already have Git installed, open Terminal and type:\ngit --version\nIf Git is installed, this command will return the version number. If not, proceed to the next steps.\nInstall Homebrew (if not already installed): Homebrew is a package manager for macOS that makes it easy to install software. In Terminal, type:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\nInstall Git via Homebrew: After installing Homebrew, you can easily install Git with:\nbrew install git\n\n\n\nWindows (PC)\nFor Windows (PC):\n\nDownload the Installer: Go to Git’s official website and download the Windows installer.\nRun the Installer: Execute the downloaded .exe file. This will open the installation wizard.\nInstallation Settings: During installation, you’ll be presented with several options. For most users, the default settings will be adequate. However, you can customize them based on your preferences.\nFinish the Installation: Click through the rest of the setup steps, and Git will be installed.\nOpen Git Bash or Command Prompt: Once installed, you can use Git Bash (a Git-specific command terminal) or the regular Command Prompt to use Git.",
    "crumbs": [
      "Computing",
      "Setting up Git"
    ]
  },
  {
    "objectID": "computing/computing-git.html#setting-up-git",
    "href": "computing/computing-git.html#setting-up-git",
    "title": "Setting up Git",
    "section": "Setting up Git",
    "text": "Setting up Git\n\nTerminal\nSetting Up Git Configurations in a terminal:\n\nOpen a new terminal: Ctrl + Shift + N (Windows); Cmd + Space to open spotlight search, type terminal and hit return.\nSet Git Configurations: In the terminal, set your email and name which will be used for commits:\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"youremail@example.com\"\n\n\n\nVS Code\nSetting Up Git Configurations in VS Code:\n\nOpen VS Code and ensure you have the Git extension installed. By default, VS Code comes with it.\nSet Git Configurations: In the terminal, set your email and name which will be used for commits:\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"youremail@example.com\"\n\nSetting Up Token-Based Authentication for GitHub:\n\nGenerate a New Token on GitHub:\n\nGo to your GitHub settings (click your profile picture in the top right &gt; Settings).\nIn the left sidebar, click on Developer settings.\nClick on Personal access tokens, then Generate new token.\nGive your token a name, set the necessary scopes (permissions). For typical Git operations, you’ll need repo, workflow, and write:packages, read:packages, delete:packages (for package management), and user (for account details).\nClick Generate token at the bottom.\n\nCopy the Generated Token: Once generated, you’ll see the token value. Make sure to copy the token now as you won’t be able to view it again.\n(Optional) Use Token in VS Code: When you push or pull from a GitHub repository, VS Code will prompt for authentication. Instead of your GitHub password, you’ll provide the token you just generated.\nIf you previously saved your credentials and VS Code isn’t prompting for authentication, you might need to update or remove your old credentials.\nFor Mac: If you’re on a Mac and had previously saved your credentials in the Keychain, you can update them:\n\nOpen Keychain Access, which you can find with Spotlight.\nIn Keychain Access, search for github.com.\nFind the internet password entry for github.com and edit or delete it.\n(Optional) The next time you push/pull from VS Code, you’ll be prompted for your username and the new token.\n\nFor Windows: If you’re on Windows and had previously saved your credentials:\n\nGo to the Control Panel &gt; User Accounts &gt; Credential Manager &gt; Windows Credentials.\nFind the credentials related to GitHub and edit or remove them.\n(Optional) The next time you push/pull from VS Code, you’ll be prompted for your username and the new token.",
    "crumbs": [
      "Computing",
      "Setting up Git"
    ]
  },
  {
    "objectID": "computing/computing-quarto.html",
    "href": "computing/computing-quarto.html",
    "title": "Setting up Quarto",
    "section": "",
    "text": "Quarto is an open-source scientific and technical publishing system built on Pandoc, the universal document converter. It is designed to create dynamic and reproducible documents, presentations, and reports. Quarto extends the functionality of Markdown by integrating with computational tools like Jupyter, R, and Python, allowing users to weave together narrative text and code in a single document. This integration enables the direct embedding of code outputs (like graphs and tables) into the final document, which is especially useful in data science and academic research."
  },
  {
    "objectID": "computing/computing-quarto.html#quarto",
    "href": "computing/computing-quarto.html#quarto",
    "title": "Setting up Quarto",
    "section": "",
    "text": "Quarto is an open-source scientific and technical publishing system built on Pandoc, the universal document converter. It is designed to create dynamic and reproducible documents, presentations, and reports. Quarto extends the functionality of Markdown by integrating with computational tools like Jupyter, R, and Python, allowing users to weave together narrative text and code in a single document. This integration enables the direct embedding of code outputs (like graphs and tables) into the final document, which is especially useful in data science and academic research."
  },
  {
    "objectID": "computing/computing-quarto.html#installing-quarto",
    "href": "computing/computing-quarto.html#installing-quarto",
    "title": "Setting up Quarto",
    "section": "Installing Quarto",
    "text": "Installing Quarto\n\nFor all systems:\n\nCheck the newest version: quarto.org has a great Get Started page\nIf Quarto is installed, this command in a terminal will return the version number. If not, proceed to the next steps.\nquarto -v \nInstall Homebrew (if not already installed): Homebrew is a package manager for macOS that makes it easy to install software. In Terminal, type:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\nInstall Git via Homebrew: After installing Homebrew, you can easily install Git with:\nbrew install git\n\n\n\nWindows (PC)\nFor Windows (PC):\n\nDownload the Installer: Go to Git’s official website and download the Windows installer.\nRun the Installer: Execute the downloaded .exe file. This will open the installation wizard.\nInstallation Settings: During installation, you’ll be presented with several options. For most users, the default settings will be adequate. However, you can customize them based on your preferences.\nFinish the Installation: Click through the rest of the setup steps, and Git will be installed.\nOpen Git Bash or Command Prompt: Once installed, you can use Git Bash (a Git-specific command terminal) or the regular Command Prompt to use Git."
  },
  {
    "objectID": "computing/computing-quarto.html#setting-up-git",
    "href": "computing/computing-quarto.html#setting-up-git",
    "title": "Setting up Quarto",
    "section": "Setting up Git",
    "text": "Setting up Git\n\nTerminal\nSetting Up Git Configurations in a terminal:\n\nOpen a new terminal: Ctrl + Shift + N (Windows); Cmd + Space to open spotlight search, type terminal and hit return.\nSet Git Configurations: In the terminal, set your email and name which will be used for commits:\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"youremail@example.com\"\n\n\n\nVS Code\nSetting Up Git Configurations in VS Code:\n\nOpen VS Code and ensure you have the Git extension installed. By default, VS Code comes with it.\nSet Git Configurations: In the terminal, set your email and name which will be used for commits:\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"youremail@example.com\"\n\nSetting Up Token-Based Authentication for GitHub:\n\nGenerate a New Token on GitHub:\n\nGo to your GitHub settings (click your profile picture in the top right &gt; Settings).\nIn the left sidebar, click on Developer settings.\nClick on Personal access tokens, then Generate new token.\nGive your token a name, set the necessary scopes (permissions). For typical Git operations, you’ll need repo, workflow, and write:packages, read:packages, delete:packages (for package management), and user (for account details).\nClick Generate token at the bottom.\n\nCopy the Generated Token: Once generated, you’ll see the token value. Make sure to copy the token now as you won’t be able to view it again.\n(Optional) Use Token in VS Code: When you push or pull from a GitHub repository, VS Code will prompt for authentication. Instead of your GitHub password, you’ll provide the token you just generated.\nIf you previously saved your credentials and VS Code isn’t prompting for authentication, you might need to update or remove your old credentials.\nFor Mac: If you’re on a Mac and had previously saved your credentials in the Keychain, you can update them:\n\nOpen Keychain Access, which you can find with Spotlight.\nIn Keychain Access, search for github.com.\nFind the internet password entry for github.com and edit or delete it.\n(Optional) The next time you push/pull from VS Code, you’ll be prompted for your username and the new token.\n\nFor Windows: If you’re on Windows and had previously saved your credentials:\n\nGo to the Control Panel &gt; User Accounts &gt; Credential Manager &gt; Windows Credentials.\nFind the credentials related to GitHub and edit or remove them.\n(Optional) The next time you push/pull from VS Code, you’ll be prompted for your username and the new token."
  },
  {
    "objectID": "computing/computing-access.html",
    "href": "computing/computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Duke University Department of Statistical Science, go to the Duke Container Manager website, cmgr.oit.duke.edu/containers.\nIf this is your first time accessing the containers, click on reserve STA313 on the Reservations available menu on the right. You only need to do this once, and when you do, you’ll see this container moved to the My reservations menu on the left.\nNext, click on STA313 under My reservations to access the RStudio instance you’ll use for the course."
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "The short answer is, yes! But you will need to install a specific versions of Python, Conda, and Jupyter Lab for everything to work as expected. You will also need to install the Python libraries we’re using as well as have Git installed on your computer. These are not extremely challenging things to get right, but they are not trivial either, particularly on certain operating systems. Myself and the TA are always happy to provide help with any computational questions when you’re working in the containers we have provided for you. If you’re working on your local setup, we can’t guarantee being able to resolve your issues, though we’re happy to try.\nIf you want to take this path, here is one pathway (but see the computing documentation on another, more guaranteed way):\n\nDownload and install Python 3.12.0: https://www.python.org/downloads/\nDownload and install Miniconda: https://docs.conda.io/projects/miniconda/en/latest/miniconda-install.html\nInstall Jupyter Lab: https://jupyter.org/install\nInstall VSCode: https://code.visualstudio.com/\nInstall Git: https://happygitwithr.com/install-git.html\nInstall any necessary packages in the terminal with pip install ___\n\nAnd I’d like to reiterate again that successful installation of these software is not a learning goal of this course.",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#can-i-use-a-local-install-of-python-and-vscode-instead-of-using-jupyter-lab-online",
    "href": "course-faq.html#can-i-use-a-local-install-of-python-and-vscode-instead-of-using-jupyter-lab-online",
    "title": "FAQ",
    "section": "",
    "text": "The short answer is, yes! But you will need to install a specific versions of Python, Conda, and Jupyter Lab for everything to work as expected. You will also need to install the Python libraries we’re using as well as have Git installed on your computer. These are not extremely challenging things to get right, but they are not trivial either, particularly on certain operating systems. Myself and the TA are always happy to provide help with any computational questions when you’re working in the containers we have provided for you. If you’re working on your local setup, we can’t guarantee being able to resolve your issues, though we’re happy to try.\nIf you want to take this path, here is one pathway (but see the computing documentation on another, more guaranteed way):\n\nDownload and install Python 3.12.0: https://www.python.org/downloads/\nDownload and install Miniconda: https://docs.conda.io/projects/miniconda/en/latest/miniconda-install.html\nInstall Jupyter Lab: https://jupyter.org/install\nInstall VSCode: https://code.visualstudio.com/\nInstall Git: https://happygitwithr.com/install-git.html\nInstall any necessary packages in the terminal with pip install ___\n\nAnd I’d like to reiterate again that successful installation of these software is not a learning goal of this course.",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "project/tips-resources.html",
    "href": "project/tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "The project is very open ended. For instance, in creating a compelling visualization(s) of your data in Python, there is no limit on what tools or packages you may use. You do not need to visualize all of the data at once. A single high quality visualization will receive a much higher grade than a large number of poor quality visualizations.\nBefore you finalize your write up, make sure the printing of code chunks is turned off with the option echo: false. In addition to code chunks, ensure all messages are turned off with the options warning: false and message: false.\nFinally, pay attention to details in your write-up and presentation. Neatness, coherency, and clarity will count."
  },
  {
    "objectID": "project/tips-resources.html#suppress-code-and-warnings",
    "href": "project/tips-resources.html#suppress-code-and-warnings",
    "title": "Project tips + resources",
    "section": "Suppress code and warnings",
    "text": "Suppress code and warnings\n\nInclude the following in the YAML of your index.qmd to suppress all code, warnings, and other messages.\n\nexecute:\n  echo: false\n  warning: false"
  },
  {
    "objectID": "project/tips-resources.html#headers",
    "href": "project/tips-resources.html#headers",
    "title": "Project tips + resources",
    "section": "Headers",
    "text": "Headers\nUse headers to clearly label each section. Make sure there is a space between the previous line and the header. Use appropriate header levels."
  },
  {
    "objectID": "project/tips-resources.html#references",
    "href": "project/tips-resources.html#references",
    "title": "Project tips + resources",
    "section": "References",
    "text": "References\nInclude all references in a section called “References” at the end of the report. This course does not have specific requirements for formatting citations and references. Optional: Use Quarto’s citation support for generating your reference. See Citations & Footnotes on the Quarto documentation for more on that."
  },
  {
    "objectID": "project/tips-resources.html#appendix",
    "href": "project/tips-resources.html#appendix",
    "title": "Project tips + resources",
    "section": "Appendix",
    "text": "Appendix\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”. The items in the appendix should be properly labeled. The appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix. We will not grade your appendix."
  },
  {
    "objectID": "project/tips-resources.html#resize-figures",
    "href": "project/tips-resources.html#resize-figures",
    "title": "Project tips + resources",
    "section": "Resize figures",
    "text": "Resize figures\nResize plots and figures, so you have more space for the narrative. Resize individual figures: Set fig-width and fig-height in chunk options, e.g.,\n#| echo: fenced\n#| label: plot1\n#| fig-height: 3\n#| fig-width: 5\nreplacing plot1 with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig-height and fig-width options in the YAML header as shown below:\nexecute:\n  fig-height: 3\n  fig-width: 5\nReplace the height and width values with values appropriate for your write up."
  },
  {
    "objectID": "project/tips-resources.html#arranging-plots",
    "href": "project/tips-resources.html#arranging-plots",
    "title": "Project tips + resources",
    "section": "Arranging plots",
    "text": "Arranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you’re using {matplotlib} or {seaborn} functions, the subplot_mosaic() function makes it straightforward to arrange plots in a grid.\nMore to be added soon…"
  },
  {
    "objectID": "project/4-writeup-presentation.html",
    "href": "project/4-writeup-presentation.html",
    "title": "Write-up and presentation",
    "section": "",
    "text": "Your written report must be completed in the index.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo: false in the YAML.\nThe mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long (if it were to be printed). There is no minimum page requirement; however, you should comprehensively address all of the analysis in your report.\nTo check how many pages your report is, open it in your browser and go to File &gt; Print &gt; Save as PDF and review the number of pages.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\n\n\n\n\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The exploratory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\n\nThis section includes a brief description of your analysis process. Explain the reasoning for the types of analyses you do, exploratory, inferential, or modeling. If you’ve chosen to do inference, make sure to include a justification for why that inferential approach is appropriate. If you’ve chosen to do modeling, describe the model(s) you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to determine analyses types and addressed any concerns over appropriateness of analyses chosen.\n\n\n\n\nThis is where you will discuss your overall finding and describe the key results from your analysis. The goal is not to interpret every single element of an output shown, but instead to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\nThe analysis results are clearly assesses and interesting findings from the analysis are described. Interpretations are used to to support the key findings and conclusions, rather than merely listing, e.g., the interpretation of every model coefficient.\n\n\n\n\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\nOverall conclusions from analysis are clearly described, and the analysis results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\n\nThis is an assessment of the overall presentation and formatting of the written report.\n\n\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.\n\n\n\n\n\nThe write-up is worth 40 points, broken down as follows:\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion\n6 pts\n\n\nOrganization + formatting\n4 pts"
  },
  {
    "objectID": "project/4-writeup-presentation.html#expectations",
    "href": "project/4-writeup-presentation.html#expectations",
    "title": "Write-up and presentation",
    "section": "",
    "text": "Your written report must be completed in the index.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo: false in the YAML.\nThe mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long (if it were to be printed). There is no minimum page requirement; however, you should comprehensively address all of the analysis in your report.\nTo check how many pages your report is, open it in your browser and go to File &gt; Print &gt; Save as PDF and review the number of pages.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit."
  },
  {
    "objectID": "project/4-writeup-presentation.html#components",
    "href": "project/4-writeup-presentation.html#components",
    "title": "Write-up and presentation",
    "section": "",
    "text": "This section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The exploratory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\n\nThis section includes a brief description of your analysis process. Explain the reasoning for the types of analyses you do, exploratory, inferential, or modeling. If you’ve chosen to do inference, make sure to include a justification for why that inferential approach is appropriate. If you’ve chosen to do modeling, describe the model(s) you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to determine analyses types and addressed any concerns over appropriateness of analyses chosen.\n\n\n\n\nThis is where you will discuss your overall finding and describe the key results from your analysis. The goal is not to interpret every single element of an output shown, but instead to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\nThe analysis results are clearly assesses and interesting findings from the analysis are described. Interpretations are used to to support the key findings and conclusions, rather than merely listing, e.g., the interpretation of every model coefficient.\n\n\n\n\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\nOverall conclusions from analysis are clearly described, and the analysis results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\n\nThis is an assessment of the overall presentation and formatting of the written report.\n\n\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages."
  },
  {
    "objectID": "project/4-writeup-presentation.html#grading",
    "href": "project/4-writeup-presentation.html#grading",
    "title": "Write-up and presentation",
    "section": "",
    "text": "The write-up is worth 40 points, broken down as follows:\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion\n6 pts\n\n\nOrganization + formatting\n4 pts"
  },
  {
    "objectID": "project/4-writeup-presentation.html#slides",
    "href": "project/4-writeup-presentation.html#slides",
    "title": "Write-up and presentation",
    "section": "Slides",
    "text": "Slides\nIn addition to the written report, your team will also create presentation slides and deliver presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nYou can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.). We recommend choosing an option that’s easy to collaborate with, e.g., Google Slides. If you choose this option, save the slides as PDF and upload it to your repo as presentation.pdf.\nYou can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\nThe slide deck should be roughly 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4-5: Inference/modeling/other analysis\nSlide 6: Conclusions + future work"
  },
  {
    "objectID": "project/4-writeup-presentation.html#presentation",
    "href": "project/4-writeup-presentation.html#presentation",
    "title": "Write-up and presentation",
    "section": "Presentation",
    "text": "Presentation\nPresentations will take place in class during the last lab of the semester. The presentation must be no longer than 5 minutes. You will pre-record a video using one of the options below.\nTo pre-record your presentation, you may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Panopto or another video platform (e.g., YouTube), then add a link to your video in your repo README.\nTo create your video with Panopto:\n\nGo to https://arizona.hosted.panopto.com/ and sign in via your NetID\nClick the “+” and select “Upload media”.\nDrag and drop your recorded video.\nOnce you’ve uploaded the video to Panopto, click to share the video and copy the video’s URL. You will need this when you post the video in the discussion forum."
  },
  {
    "objectID": "project/4-writeup-presentation.html#grading-1",
    "href": "project/4-writeup-presentation.html#grading-1",
    "title": "Write-up and presentation",
    "section": "Grading",
    "text": "Grading\nThe presentation is worth 25 points, broken down as follows:\n\n\n\nTotal\n25 pts\n\n\n\n\nSlides\n10 pts\n\n\nPresentation\n15 pts\n\n\n\n\nSlides\nAre the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?\n\n\nPresentation\n\nTime management: Did the team divide the time well amongst themselves or got cut off going over time?\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?\nTeamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together?\nCreativity and critical thought: Is the project carefully thought out? Does it appear that time and effort went into the planning and implementation of the project?\nContent: Including, but not limited to the following:\n\nIs the question well articulated in the presentation?\nCan the question be answered with the data?\nDoes the analysis answer the question?\nAre the conclusion(s) made based on the analysis justifiable?\nAre the limitations carefully considered and articulated?"
  },
  {
    "objectID": "project/2-proposal.html",
    "href": "project/2-proposal.html",
    "title": "Proposal",
    "section": "",
    "text": "The goals of this milestone are as follows:\n\nDiscuss topics you’re interested in investigating and find data sets on those topics.\nIdentify 3 data sets you’re interested in potentially using for the project.\nGet these datasets into Python.\nWrite up reasons and justifications for why you want to work with these datasets.\nReview your team contract.\n\n\n\n\n\n\n\nImportant\n\n\n\nYou must use one of the data sets in the proposal for the final project, unless instructed otherwise when given feedback."
  },
  {
    "objectID": "project/2-proposal.html#criteria-for-datasets",
    "href": "project/2-proposal.html#criteria-for-datasets",
    "title": "Proposal",
    "section": "Criteria for datasets",
    "text": "Criteria for datasets\nThe data sets should meet the following criteria:\n\nAt least 500 observations\nAt least 8 columns\nAt least 6 of the columns must be useful and unique explanatory variables.\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful explanatory variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique explanatory variables.\n\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\nYou can curate one of your datasets via web scraping.\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria.\nIf you set your hearts on a dataset that has fewer observations or variables than what’s suggested here, that might still be ok; use these numbers as guidance for a successful proposal, not as minimum requirements."
  },
  {
    "objectID": "project/2-proposal.html#resources-for-datasets",
    "href": "project/2-proposal.html#resources-for-datasets",
    "title": "Proposal",
    "section": "Resources for datasets",
    "text": "Resources for datasets\nYou can find data wherever you like, but here are some recommendations to get you started. You shouldn’t feel constrained to datasets that are already in a tidy format, you can start with data that needs cleaning and tidying, scrape data off the web, or collect your own data.\n\nAwesome public datasets\nBikeshare data portal\nCDC\nData.gov\nData is Plural\nDurham Open Data Portal\nEdinburgh Open Data\nElection Studies\nEuropean Statistics\nCORGIS: The Collection of Really Great, Interesting, Situated Datasets\nGeneral Social Survey\nGoogle Dataset Search\nHarvard Dataverse\nInternational Monetary Fund\nIPUMS survey data from around the world\nLos Angeles Open Data\nNHS Scotland Open Data\nNYC OpenData\nOpen access to Scotland’s official statistics\nPew Research\nPRISM Data Archive Project\nStatistics Canada\nTidyTuesday\nThe National Bureau of Economic Research\nUCI Machine Learning Repository\nUK Government Data\nUNICEF Data\nUnited Nations Data\nUnited Nations Statistics Division\nUS Census Data\nUS Government Data\nWorld Bank Data\nYouth Risk Behavior Surveillance System (YRBSS)\nFRED Economic Data"
  },
  {
    "objectID": "project/2-proposal.html#introduction-and-data",
    "href": "project/2-proposal.html#introduction-and-data",
    "title": "Proposal",
    "section": "Introduction and data",
    "text": "Introduction and data\nFor each data set:\n\nIdentify the source of the data.\nState when and how it was originally collected (by the original data curator, not necessarily how you found the data).\nWrite a brief description of the observations.\nAddress ethical concerns about the data, if any."
  },
  {
    "objectID": "project/2-proposal.html#research-question",
    "href": "project/2-proposal.html#research-question",
    "title": "Proposal",
    "section": "Research question",
    "text": "Research question\nYour research question should contain at least three variables, and should be a mix of categorical and quantitative variables. When writing a research question, please think about the following:\n\nWhat is your target population?\nIs the question original?\nCan the question be answered?\n\nFor each data set, include the following:\n\nA well formulated research question. (You may include more than one research question if you want to receive feedback on different ideas for your project. However, one per data set is required.)\nStatement on why this question is important.\nA description of the research topic along with a concise statement of your hypotheses on this topic.\nIdentify the types of variables in your research question. Categorical? Quantitative?"
  },
  {
    "objectID": "project/2-proposal.html#glimpse-of-data",
    "href": "project/2-proposal.html#glimpse-of-data",
    "title": "Proposal",
    "section": "Glimpse of data",
    "text": "Glimpse of data\nFor each data set:\n\nPlace the file containing your data in the data folder of the project repo.\nUse the .head() and .info() functions to provide a glimpse of the data set."
  },
  {
    "objectID": "slides/07-wrangling.html#study-tips-for-the-exam",
    "href": "slides/07-wrangling.html#study-tips-for-the-exam",
    "title": "Data wrangling",
    "section": "Study tips for the exam",
    "text": "Study tips for the exam\n\n\nGo over lecture materials and application exercises\nReview labs and feedback you’ve received so far\nDo the exercises at the end of readings from both books\nDo the exam review (to be posted on Friday)"
  },
  {
    "objectID": "slides/07-wrangling.html#frequently-asked-question",
    "href": "slides/07-wrangling.html#frequently-asked-question",
    "title": "Data wrangling",
    "section": "Frequently asked question",
    "text": "Frequently asked question\nIs there a limit to a DataFrame size?\nNo, a DataFrame can be any number of rows or columns. However, when you print it, it will only print the first few rows and the columns that fit across the screen.\nIf you want to see more rows and columns, you can:\n\nOpen it in the data viewer with df.head(n)\nExplicitly print more rows with, e.g., print(df.head(25))\nExplicitly select or rearrange columns"
  },
  {
    "objectID": "slides/07-wrangling.html#options-for-a-dataframe",
    "href": "slides/07-wrangling.html#options-for-a-dataframe",
    "title": "Data wrangling",
    "section": "Options for a DataFrame",
    "text": "Options for a DataFrame\n\nDefaultprint()SubsettingRelocating\n\n\n\nimport pandas as pd\n\ndf = pd.read_csv('data/midwest.csv')\nprint(df)\n\n      PID     county state   area  poptotal   popdensity  popwhite  popblack  \\\n0     561      ADAMS    IL  0.052     66090  1270.961540     63917      1702   \n1     562  ALEXANDER    IL  0.014     10626   759.000000      7054      3496   \n2     563       BOND    IL  0.022     14991   681.409091     14477       429   \n3     564      BOONE    IL  0.017     30806  1812.117650     29344       127   \n4     565      BROWN    IL  0.018      5836   324.222222      5264       547   \n..    ...        ...   ...    ...       ...          ...       ...       ...   \n432  3048   WAUKESHA    WI  0.034    304715  8962.205880    298313      1096   \n433  3049    WAUPACA    WI  0.045     46104  1024.533330     45695        22   \n434  3050   WAUSHARA    WI  0.037     19385   523.918919     19094        29   \n435  3051  WINNEBAGO    WI  0.035    140320  4009.142860    136822       697   \n436  3052       WOOD    WI  0.048     73605  1533.437500     72157        90   \n\n     popamerindian  popasian  ...  percollege  percprof  poppovertyknown  \\\n0               98       249  ...   19.631392  4.355859            63628   \n1               19        48  ...   11.243308  2.870315            10529   \n2               35        16  ...   17.033819  4.488572            14235   \n3               46       150  ...   17.278954  4.197800            30337   \n4               14         5  ...   14.475999  3.367680             4815   \n..             ...       ...  ...         ...       ...              ...   \n432            672      2699  ...   35.396784  7.667090           299802   \n433            125        92  ...   16.549869  3.138596            44412   \n434             70        43  ...   15.064584  2.620907            19163   \n435            685      1728  ...   24.995504  5.659847           133950   \n436            481       722  ...   21.666382  4.583725            72685   \n\n     percpovertyknown  percbelowpoverty  percchildbelowpovert  \\\n0           96.274777         13.151443             18.011717   \n1           99.087145         32.244278             45.826514   \n2           94.956974         12.068844             14.036061   \n3           98.477569          7.209019             11.179536   \n4           82.505140         13.520249             13.022889   \n..                ...               ...                   ...   \n432         98.387674          3.121060              3.785820   \n433         96.330036          8.488697             10.071411   \n434         98.854785         13.786985             20.050708   \n435         95.460376          8.804031             10.592031   \n436         98.750085          8.525831             11.162997   \n\n     percadultpoverty  percelderlypoverty  inmetro  category  \n0           11.009776           12.443812        0       AAR  \n1           27.385647           25.228976        0       LHR  \n2           10.852090           12.697410        0       AAR  \n3            5.536013            6.217047        1       ALU  \n4           11.143211           19.200000        0       AAR  \n..                ...                 ...      ...       ...  \n432          2.590061            4.085479        1       HLU  \n433          6.953799           10.338641        0       AAR  \n434         11.695784           11.804558        0       AAR  \n435          8.660587            6.661094        1       HAU  \n436          7.375656            7.882918        0       AAR  \n\n[437 rows x 28 columns]\n\n\n\n\n\nprint(df.head(13))\n\n    PID     county state   area  poptotal   popdensity  popwhite  popblack  \\\n0   561      ADAMS    IL  0.052     66090  1270.961540     63917      1702   \n1   562  ALEXANDER    IL  0.014     10626   759.000000      7054      3496   \n2   563       BOND    IL  0.022     14991   681.409091     14477       429   \n3   564      BOONE    IL  0.017     30806  1812.117650     29344       127   \n4   565      BROWN    IL  0.018      5836   324.222222      5264       547   \n5   566     BUREAU    IL  0.050     35688   713.760000     35157        50   \n6   567    CALHOUN    IL  0.017      5322   313.058824      5298         1   \n7   568    CARROLL    IL  0.027     16805   622.407407     16519       111   \n8   569       CASS    IL  0.024     13437   559.875000     13384        16   \n9   570  CHAMPAIGN    IL  0.058    173025  2983.189660    146506     16559   \n10  571  CHRISTIAN    IL  0.042     34418   819.476190     34176        82   \n11  572      CLARK    IL  0.030     15921   530.700000     15842        10   \n12  573       CLAY    IL  0.028     14460   516.428571     14403         4   \n\n    popamerindian  popasian  ...  percollege   percprof  poppovertyknown  \\\n0              98       249  ...   19.631392   4.355859            63628   \n1              19        48  ...   11.243308   2.870315            10529   \n2              35        16  ...   17.033819   4.488572            14235   \n3              46       150  ...   17.278954   4.197800            30337   \n4              14         5  ...   14.475999   3.367680             4815   \n5              65       195  ...   18.904624   3.275891            35107   \n6               8        15  ...   11.917388   3.209601             5241   \n7              30        61  ...   16.197121   3.055727            16455   \n8               8        23  ...   14.107649   3.206799            13081   \n9             331      8033  ...   41.295808  17.757448           154934   \n10             51        89  ...   13.567226   3.089998            33788   \n11             26        36  ...   15.110863   2.776225            15615   \n12             17        29  ...   13.683010   2.788432            14248   \n\n    percpovertyknown  percbelowpoverty  percchildbelowpovert  \\\n0          96.274777         13.151443             18.011717   \n1          99.087145         32.244278             45.826514   \n2          94.956974         12.068844             14.036061   \n3          98.477569          7.209019             11.179536   \n4          82.505140         13.520249             13.022889   \n5          98.372002         10.399635             14.158819   \n6          98.478016         15.149781             13.787761   \n7          97.917287         11.710726             17.225462   \n8          97.350599         13.875086             17.994784   \n9          89.544286         15.572437             14.132234   \n10         98.169562         11.708299             16.320612   \n11         98.078010         12.007685             15.321547   \n12         98.533887         16.774284             20.582578   \n\n    percadultpoverty  percelderlypoverty  inmetro  category  \n0          11.009776           12.443812        0       AAR  \n1          27.385647           25.228976        0       LHR  \n2          10.852090           12.697410        0       AAR  \n3           5.536013            6.217047        1       ALU  \n4          11.143211           19.200000        0       AAR  \n5           8.179287           11.008586        0       AAR  \n6          12.932331           21.085271        0       LAR  \n7          10.027037            9.525052        0       AAR  \n8          11.914343           13.660180        0       AAR  \n9          17.562728            8.105017        1       HAU  \n10          9.569700           11.490641        0       AAR  \n11         10.131775           12.595420        0       AAR  \n12         14.464114           17.670078        0       LAR  \n\n[13 rows x 28 columns]\n\n\n\n\n\nselected_columns = df[['county', 'state', 'percbelowpoverty', 'percollege']]\nprint(selected_columns)\n\n        county state  percbelowpoverty  percollege\n0        ADAMS    IL         13.151443   19.631392\n1    ALEXANDER    IL         32.244278   11.243308\n2         BOND    IL         12.068844   17.033819\n3        BOONE    IL          7.209019   17.278954\n4        BROWN    IL         13.520249   14.475999\n..         ...   ...               ...         ...\n432   WAUKESHA    WI          3.121060   35.396784\n433    WAUPACA    WI          8.488697   16.549869\n434   WAUSHARA    WI         13.786985   15.064584\n435  WINNEBAGO    WI          8.804031   24.995504\n436       WOOD    WI          8.525831   21.666382\n\n[437 rows x 4 columns]\n\n\n\n\n\nrelocated_columns = df[['county', 'state', 'percbelowpoverty', 'percollege', *df.columns.difference(['county', 'state', 'percbelowpoverty', 'percollege'])]]\nprint(relocated_columns)\n\n        county state  percbelowpoverty  percollege   PID   area category  \\\n0        ADAMS    IL         13.151443   19.631392   561  0.052      AAR   \n1    ALEXANDER    IL         32.244278   11.243308   562  0.014      LHR   \n2         BOND    IL         12.068844   17.033819   563  0.022      AAR   \n3        BOONE    IL          7.209019   17.278954   564  0.017      ALU   \n4        BROWN    IL         13.520249   14.475999   565  0.018      AAR   \n..         ...   ...               ...         ...   ...    ...      ...   \n432   WAUKESHA    WI          3.121060   35.396784  3048  0.034      HLU   \n433    WAUPACA    WI          8.488697   16.549869  3049  0.045      AAR   \n434   WAUSHARA    WI         13.786985   15.064584  3050  0.037      AAR   \n435  WINNEBAGO    WI          8.804031   24.995504  3051  0.035      HAU   \n436       WOOD    WI          8.525831   21.666382  3052  0.048      AAR   \n\n     inmetro  percadultpoverty  percamerindan  ...  percwhite  popadults  \\\n0          0         11.009776       0.148283  ...  96.712059      43298   \n1          0         27.385647       0.178807  ...  66.384340       6724   \n2          0         10.852090       0.233473  ...  96.571276       9669   \n3          1          5.536013       0.149322  ...  95.254171      19272   \n4          0         11.143211       0.239890  ...  90.198766       3979   \n..       ...               ...            ...  ...        ...        ...   \n432        1          2.590061       0.220534  ...  97.899020     195837   \n433        0          6.953799       0.271126  ...  99.112875      30109   \n434        0         11.695784       0.361104  ...  98.498839      13316   \n435        1          8.660587       0.488170  ...  97.507127      88960   \n436        0          7.375656       0.653488  ...  98.032742      46796   \n\n     popamerindian  popasian  popblack   popdensity  popother  \\\n0               98       249      1702  1270.961540       124   \n1               19        48      3496   759.000000         9   \n2               35        16       429   681.409091        34   \n3               46       150       127  1812.117650      1139   \n4               14         5       547   324.222222         6   \n..             ...       ...       ...          ...       ...   \n432            672      2699      1096  8962.205880      1935   \n433            125        92        22  1024.533330       170   \n434             70        43        29   523.918919       149   \n435            685      1728       697  4009.142860       388   \n436            481       722        90  1533.437500       155   \n\n     poppovertyknown  poptotal  popwhite  \n0              63628     66090     63917  \n1              10529     10626      7054  \n2              14235     14991     14477  \n3              30337     30806     29344  \n4               4815      5836      5264  \n..               ...       ...       ...  \n432           299802    304715    298313  \n433            44412     46104     45695  \n434            19163     19385     19094  \n435           133950    140320    136822  \n436            72685     73605     72157  \n\n[437 rows x 28 columns]"
  },
  {
    "objectID": "slides/07-wrangling.html#why-join",
    "href": "slides/07-wrangling.html#why-join",
    "title": "Data wrangling",
    "section": "Why join?",
    "text": "Why join?\nSuppose we want to answer questions like:\n\nIs there a relationship between\n- number of DS courses taken\n- motivation for taking course\n- …\nand performance in this course?”\n\n\nEach of these would require joining class performance data with an outside data source so we can have all relevant information (columns) in a single data frame."
  },
  {
    "objectID": "slides/07-wrangling.html#setup",
    "href": "slides/07-wrangling.html#setup",
    "title": "Data wrangling",
    "section": "Setup",
    "text": "Setup\nFor the next few slides…\n\n\n\nx = pd.DataFrame({\n    'id': [1, 2, 3],\n    'value_x': ['x1', 'x2', 'x3']\n})\nprint(x)\n\n   id value_x\n0   1      x1\n1   2      x2\n2   3      x3\n\n\n\n\ny = pd.DataFrame({\n    'id': [1, 2, 4],\n    'value_y': ['y1', 'y2', 'y4']\n})\n\nprint(y)\n\n   id value_y\n0   1      y1\n1   2      y2\n2   4      y4"
  },
  {
    "objectID": "slides/07-wrangling.html#left-join",
    "href": "slides/07-wrangling.html#left-join",
    "title": "Data wrangling",
    "section": "Left join",
    "text": "Left join\n\n\n\n\n\nleft_merged = pd.merge(x, y, on='id', how='left')\nprint(left_merged)\n\n   id value_x value_y\n0   1      x1      y1\n1   2      x2      y2\n2   3      x3     NaN"
  },
  {
    "objectID": "slides/07-wrangling.html#right-join",
    "href": "slides/07-wrangling.html#right-join",
    "title": "Data wrangling",
    "section": "Right join",
    "text": "Right join\n\n\n\n\n\nright_merged = pd.merge(x, y, on='id', how='right')\nprint(right_merged)\n\n   id value_x value_y\n0   1      x1      y1\n1   2      x2      y2\n2   4     NaN      y4"
  },
  {
    "objectID": "slides/07-wrangling.html#outer-full-join",
    "href": "slides/07-wrangling.html#outer-full-join",
    "title": "Data wrangling",
    "section": "Outer (full) join",
    "text": "Outer (full) join\n\n\n\n\n\nouter_merged = pd.merge(x, y, on='id', how='outer')\nprint(outer_merged)\n\n   id value_x value_y\n0   1      x1      y1\n1   2      x2      y2\n2   3      x3     NaN\n3   4     NaN      y4"
  },
  {
    "objectID": "slides/07-wrangling.html#inner-join",
    "href": "slides/07-wrangling.html#inner-join",
    "title": "Data wrangling",
    "section": "Inner join",
    "text": "Inner join\n\n\n\n\n\ninner_merged = pd.merge(x, y, on='id', how='inner')\nprint(inner_merged)\n\n   id value_x value_y\n0   1      x1      y1\n1   2      x2      y2"
  },
  {
    "objectID": "slides/07-wrangling.html#semi-join",
    "href": "slides/07-wrangling.html#semi-join",
    "title": "Data wrangling",
    "section": "Semi-join",
    "text": "Semi-join\n\n\n\n\n\nsemi_merged = x[x['id'].isin(y['id'])]\nprint(semi_merged)\n\n   id value_x\n0   1      x1\n1   2      x2"
  },
  {
    "objectID": "slides/07-wrangling.html#anti-join",
    "href": "slides/07-wrangling.html#anti-join",
    "title": "Data wrangling",
    "section": "Anti-join",
    "text": "Anti-join\n\n\n\n\n\nanti_merged = x[~x['id'].isin(y['id'])]\nprint(anti_merged)\n\n   id value_x\n2   3      x3\n\n\n\n\n🤮"
  },
  {
    "objectID": "slides/07-wrangling.html#pivoting-.melt",
    "href": "slides/07-wrangling.html#pivoting-.melt",
    "title": "Data wrangling",
    "section": "Pivoting (.melt())",
    "text": "Pivoting (.melt())\n\n\nData sets can’t be labeled as wide or long, but they can be made wider or longer for a certain analysis that requires a certain format.\nWhen pivoting longer, variable names that turn into values are characters by default. If you need them to be in another format, you need to explicitly make that transformation, which you can do within the melt() function."
  },
  {
    "objectID": "slides/07-wrangling.html#ae-05-majors-wrangling",
    "href": "slides/07-wrangling.html#ae-05-majors-wrangling",
    "title": "Data wrangling",
    "section": "ae-05-majors-wrangling",
    "text": "ae-05-majors-wrangling\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#setup",
    "href": "slides/13-hypothesis-testing.html#setup",
    "title": "Hypothesis testing",
    "section": "Setup",
    "text": "Setup\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\nimport random\n\nsns.set(font_scale=2)\nsns.set_theme(style = \"whitegrid\")"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#how-can-we-answer-questions-using-statistics",
    "href": "slides/13-hypothesis-testing.html#how-can-we-answer-questions-using-statistics",
    "title": "Hypothesis testing",
    "section": "How can we answer questions using statistics?",
    "text": "How can we answer questions using statistics?\n\nStatistical hypothesis testing is the procedure that assesses evidence provided by the data in favor of or against some claim about the population (often about a population parameter or potential associations)"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#the-hypothesis-testing-framework",
    "href": "slides/13-hypothesis-testing.html#the-hypothesis-testing-framework",
    "title": "Hypothesis testing",
    "section": "The hypothesis testing framework",
    "text": "The hypothesis testing framework\n\n\nEi incumbit probatio qui dicit, non qui negat"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#the-hypothesis-testing-framework-1",
    "href": "slides/13-hypothesis-testing.html#the-hypothesis-testing-framework-1",
    "title": "Hypothesis testing",
    "section": "The hypothesis testing framework",
    "text": "The hypothesis testing framework\n\n\nStart with two hypotheses about the population: the null hypothesis and the alternative hypothesis.\nChoose a (representative) sample, collect data, and analyze the data.\nFigure out how likely it is to see data like what we observed, IF the null hypothesis were in fact true.\nIf our data would have been extremely unlikely if the null claim were true, then we reject it and deem the alternative claim worthy of further study. Otherwise, we cannot reject the null claim."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#organ-donation-consultants",
    "href": "slides/13-hypothesis-testing.html#organ-donation-consultants",
    "title": "Hypothesis testing",
    "section": "Organ donation consultants",
    "text": "Organ donation consultants"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#organ-donation-consultants-1",
    "href": "slides/13-hypothesis-testing.html#organ-donation-consultants-1",
    "title": "Hypothesis testing",
    "section": "Organ donation consultants",
    "text": "Organ donation consultants\nOne consultant tried to attract patients by noting that the average complication rate for liver donor surgeries in the US is about 10%, but her clients have only had 3 complications in the 62 liver donor surgeries she has facilitated. She claims this is strong evidence that her work meaningfully contributes to reducing complications (and therefore she should be hired!).\n\n\nIs this a reasonable claim to make?"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#organ-donation-consultants-2",
    "href": "slides/13-hypothesis-testing.html#organ-donation-consultants-2",
    "title": "Hypothesis testing",
    "section": "Organ donation consultants",
    "text": "Organ donation consultants"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#organ-donation-consultants-3",
    "href": "slides/13-hypothesis-testing.html#organ-donation-consultants-3",
    "title": "Hypothesis testing",
    "section": "Organ donation consultants",
    "text": "Organ donation consultants\nOne consultant tried to attract patients by noting that the average complication rate for liver donor surgeries in the US is about 10%, but her clients have only had 3 complications in the 62 liver donor surgeries she has facilitated. She claims this is strong evidence that her work meaningfully contributes to reducing complications (and therefore she should be hired!).\n\n\nIs there sufficient evidence to suggest that her complication rate is lower than the overall US rate?"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#the-hypothesis-testing-framework-2",
    "href": "slides/13-hypothesis-testing.html#the-hypothesis-testing-framework-2",
    "title": "Hypothesis testing",
    "section": "The hypothesis testing framework",
    "text": "The hypothesis testing framework\n\n\nStart with two hypotheses about the population: the null hypothesis and the alternative hypothesis.\nChoose a (representative) sample, collect data, and analyze the data.\nFigure out how likely it is to see data like what we observed, IF the null hypothesis were in fact true.\nIf our data would have been extremely unlikely if the null claim were true, then we reject it and deem the alternative claim worthy of further study. Otherwise, we cannot reject the null claim."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#two-competing-hypotheses",
    "href": "slides/13-hypothesis-testing.html#two-competing-hypotheses",
    "title": "Hypothesis testing",
    "section": "Two competing hypotheses",
    "text": "Two competing hypotheses\nThe null hypothesis (often denoted \\(H_0\\)) states that “nothing unusual is happening” or “there is no relationship,” etc.\n\nOn the other hand, the alternative hypothesis (often denoted \\(H_1\\) or \\(H_A\\)) states the opposite: that there is some sort of relationship.\n\n\n\nIn statistical hypothesis testing we always first assume that the null hypothesis is true and then evaluate the weight of proof we have against this claim."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#defining-the-hypotheses",
    "href": "slides/13-hypothesis-testing.html#defining-the-hypotheses",
    "title": "Hypothesis testing",
    "section": "1. Defining the hypotheses",
    "text": "1. Defining the hypotheses\nThe null and alternative hypotheses are defined for parameters.\n\nWhat will our null and alternative hypotheses be for this example?\n\n\n\n\n\\(H_0\\): the true proportion of complications among her patients is equal to the US population rate\n\\(H_1\\): the true proportion of complications among her patients is less than the US population rate\n\n\n\n\nExpressed in symbols:\n\n\\(H_0: p = 0.10\\)\n\\(H_1: p &lt; 0.10\\)\n\n\n\nwhere \\(p\\) is the true proportion of transplants with complications among her patients."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#collecting-and-summarizing-data",
    "href": "slides/13-hypothesis-testing.html#collecting-and-summarizing-data",
    "title": "Hypothesis testing",
    "section": "2. Collecting and summarizing data",
    "text": "2. Collecting and summarizing data\nWith these two hypotheses, we now take our sample and summarize the data.\nThe choice of summary statistic calculated depends on the type of data. In our example, we use the sample proportion: \\(\\widehat{p} = 3/62 \\approx 0.048\\):"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed\nNext, we calculate the probability of getting data like ours, or more extreme, if \\(H_0\\) were in fact actually true.\n\nThis is a conditional probability:\n\nGiven that \\(H_0\\) is true (i.e., if \\(p\\) were actually 0.10), what would be the probability of observing \\(\\widehat{p} = 3/62\\)?”\n\n\n\n\nThis probability is known as the p-value."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-1",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-1",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed\nLet’s simulate a distribution for \\(\\hat{p}\\) such that the probability of complication for each patient is 0.10 for 62 patients.\nThis null distribution for \\(\\hat{p}\\) represents the distribution of the observed proportions we might expect, if the null hypothesis were true.\n\n\nWhen sampling from the null distribution, what is the expected proportion of complications? What would the expected count be of patients experiencing complications?"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-2",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-2",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-3",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-3",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-4",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-4",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-5",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-5",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-6",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-6",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed\nSupposing that the true proportion of complications is 10%, if we were to take repeated samples of 62 liver transplants, about 11.5% of them would have 3 or fewer complications.\n\nThat is, p = 0.115."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#making-a-conclusion",
    "href": "slides/13-hypothesis-testing.html#making-a-conclusion",
    "title": "Hypothesis testing",
    "section": "4. Making a conclusion",
    "text": "4. Making a conclusion\nIf it is very unlikely to observe our data (or more extreme) if \\(H_0\\) were actually true, then that might give us enough evidence to suggest that it is actually false (and that \\(H_1\\) is true).\n\nWhat is “small enough”?\n\n\n\nWe often consider a numeric cutpoint (the significance level) defined prior to conducting the analysis.\nMany analyses use \\(\\alpha = 0.05\\). This means that if \\(H_0\\) were in fact true, we would expect to make the wrong decision only 5% of the time.\n\n\n\nIf the p-value is less than \\(\\alpha\\), we say the results are statistically significant. In such a case, we would make the decision to reject the null hypothesis."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#what-do-we-conclude-when-p-ge-alpha",
    "href": "slides/13-hypothesis-testing.html#what-do-we-conclude-when-p-ge-alpha",
    "title": "Hypothesis testing",
    "section": "What do we conclude when \\(p \\ge \\alpha\\)?",
    "text": "What do we conclude when \\(p \\ge \\alpha\\)?\nIf the p-value is \\(\\alpha\\) or greater, we say the results are not statistically significant and we fail to reject the null hypothesis.\n\nImportantly, we never “accept” the null hypothesis – we performed the analysis assuming that \\(H_0\\) was true to begin with and assessed the probability of seeing our observed data or more extreme under this assumption."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#making-a-conclusion-1",
    "href": "slides/13-hypothesis-testing.html#making-a-conclusion-1",
    "title": "Hypothesis testing",
    "section": "4. Making a conclusion",
    "text": "4. Making a conclusion\n\nThere is insufficient evidence at \\(\\alpha = 0.05\\) to suggest that the consultant’s complication rate is less than the US average."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#vacation-rentals-in-tucson-az",
    "href": "slides/13-hypothesis-testing.html#vacation-rentals-in-tucson-az",
    "title": "Hypothesis testing",
    "section": "Vacation rentals in Tucson, AZ",
    "text": "Vacation rentals in Tucson, AZ\n\n\nYour friend claims that the mean price per guest per night for Airbnbs in Tucson, AZ is $100. What do you make of this statement?"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#defining-the-hypotheses-1",
    "href": "slides/13-hypothesis-testing.html#defining-the-hypotheses-1",
    "title": "Hypothesis testing",
    "section": "1. Defining the hypotheses",
    "text": "1. Defining the hypotheses\nRemember, the null and alternative hypotheses are defined for parameters, not statistics\n\nWhat will our null and alternative hypotheses be for this example?\n\n\n\n\\(H_0\\): the true mean price per guest is $100 per night\n\\(H_1\\): the true mean price per guest is NOT $100 per night\n\n\n\nExpressed in symbols:\n\n\\(H_0: \\mu = 100\\)\n\\(H_1: \\mu \\neq 100\\)\n\nwhere \\(\\mu\\) is the true population mean price per guest per night among Airbnb listings in Tucson."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#collecting-and-summarizing-data-1",
    "href": "slides/13-hypothesis-testing.html#collecting-and-summarizing-data-1",
    "title": "Hypothesis testing",
    "section": "2. Collecting and summarizing data",
    "text": "2. Collecting and summarizing data\nWith these two hypotheses, we now take our sample and summarize the data. We have a representative of 50 Airbnb listings in the file tucson.csv.\nThe choice of summary statistic calculated depends on the type of data. In our example, we use the sample proportion, \\(\\bar{x} = 116.24\\).\n\n\ntucson = pd.read_csv('data/tucson.csv')\n\nmean_price = tucson['ppg'].mean()\nprint(f\"Sample mean price: {mean_price:.2f}\")\n\nSample mean price: 116.24"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-7",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-7",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed\nWe know that not every representative sample of 50 Airbnb listings in Tucson will have exactly a sample mean of exactly $116.24.\n\nHow might we deal with this variability in the sampling distribution of the mean using only the data that we have from our original sample?\n\n\nWe can take bootstrap samples, formed by sampling with replacement from our original dataset, of the same sample size as our original dataset."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-8",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-8",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed\n\n\n\n\n\n\n\n\n\nMean price per guest per night: 116.24"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-9",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-9",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed\n\n\n\n\n\n\n\n\n\nMean price per guest per night (Bootstrap 1): 115.20"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-10",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-10",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed\n\n\n\n\n\n\n\n\n\nMean price per guest per night (Bootstrap 2): 115.08"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-11",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-11",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed\n\n\n\n\n\n\n\n\n\nMean price per guest per night (Bootstrap 3): 103.20"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-12",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-12",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed\n\n\n\n\n\n\n\n\n\nMean of bootstrap means: 116.24"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#shifting-the-distribution",
    "href": "slides/13-hypothesis-testing.html#shifting-the-distribution",
    "title": "Hypothesis testing",
    "section": "Shifting the distribution",
    "text": "Shifting the distribution\nWe’ve captured the variability in the sample mean among samples of size 50 from Tucson area Airbnbs, but remember that in the hypothesis testing paradigm, we must assess our observed evidence under the assumption that \\(H_0\\) is true.\n\nmean_price = bootstrap_means_df['boot_means'].mean()\nprint(f\"Sample mean price: {mean_price:.2f}\")\n\nSample mean price: 116.24\n\n\n\n\n\nWhere should the bootstrap distribution of means be centered under \\(H_0\\)?"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#shifting-the-distribution-1",
    "href": "slides/13-hypothesis-testing.html#shifting-the-distribution-1",
    "title": "Hypothesis testing",
    "section": "Shifting the distribution",
    "text": "Shifting the distribution\n\n\n\n\n\n\n\n\n\nMean of bootstrap means: 116.24"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#shifting-the-distribution-2",
    "href": "slides/13-hypothesis-testing.html#shifting-the-distribution-2",
    "title": "Hypothesis testing",
    "section": "Shifting the distribution",
    "text": "Shifting the distribution"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-13",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-13",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-14",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-14",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed"
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-15",
    "href": "slides/13-hypothesis-testing.html#assessing-the-evidence-observed-15",
    "title": "Hypothesis testing",
    "section": "3. Assessing the evidence observed",
    "text": "3. Assessing the evidence observed\nSupposing that the true mean price per guest were $100 a night, about 0.16% of bootstrap sample means were as extreme or even more so than our originally observed sample mean price per guest of $116.24.\n\nThat is, p = 0.0016."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#making-a-conclusion-2",
    "href": "slides/13-hypothesis-testing.html#making-a-conclusion-2",
    "title": "Hypothesis testing",
    "section": "4. Making a conclusion",
    "text": "4. Making a conclusion\nIf it is very unlikely to observe our data (or more extreme) if \\(H_0\\) were actually true, then that might give us enough evidence to suggest that it is actually false (and that \\(H_1\\) is true).\n\nThere is sufficient evidence at \\(\\alpha = 0.05\\) to suggest that the mean price per guest per night of Airbnb rentals in Tucson is not $100."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#ok-so-what-isnt-a-p-value",
    "href": "slides/13-hypothesis-testing.html#ok-so-what-isnt-a-p-value",
    "title": "Hypothesis testing",
    "section": "Ok, so what isn’t a p-value?",
    "text": "Ok, so what isn’t a p-value?\n\n“A p-value of 0.05 means the null hypothesis has a probability of only 5% of being true”\n\n\n“A p-value of 0.05 means there is a 95% chance or greater that the null hypothesis is incorrect”\n\n\n\nNO\n\n\n\np-values do not provide information on the probability that the null hypothesis is true given our observed data."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#what-can-go-wrong",
    "href": "slides/13-hypothesis-testing.html#what-can-go-wrong",
    "title": "Hypothesis testing",
    "section": "What can go wrong?",
    "text": "What can go wrong?\nRemember, a p-value is calculated assuming that \\(H_0\\) is true. It cannot be used to tell us how likely that assumption is correct. When we fail to reject the null hypothesis, we are stating that there is insufficient evidence to assert that it is false. This could be because…\n\n\n… \\(H_0\\) actually is true!\n… \\(H_0\\) is false, but we got unlucky and happened to get a sample that didn’t give us enough reason to say that \\(H_0\\) was false.\n\n\n\nEven more bad news, hypothesis testing does NOT give us the tools to determine which one of the two scenarios occurred."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#what-can-go-wrong-1",
    "href": "slides/13-hypothesis-testing.html#what-can-go-wrong-1",
    "title": "Hypothesis testing",
    "section": "What can go wrong?",
    "text": "What can go wrong?\nSuppose we test a certain null hypothesis, which can be either true or false (we never know for sure!). We make one of two decisions given our data: either reject or fail to reject \\(H_0\\).\n\nWe have the following four scenarios:\n\n\n\nDecision\n\\(H_0\\) is true\n\\(H_0\\) is false\n\n\n\n\nFail to reject \\(H_0\\)\nCorrect decision\nType II Error\n\n\nReject \\(H_0\\)\nType I Error\nCorrect decision\n\n\n\n\n\n\\(\\alpha\\) is the probability of making a Type I error.\n\\(\\beta\\) is the probability of making a Type II error.\nThe power of a test is 1 - \\(\\beta\\): the probability that, if the null hypothesis is actually false, we correctly reject it."
  },
  {
    "objectID": "slides/13-hypothesis-testing.html#ae-09",
    "href": "slides/13-hypothesis-testing.html#ae-09",
    "title": "Hypothesis testing",
    "section": "ae-09",
    "text": "ae-09\nWork through the Tucson Airbnb prices data in an exercise on Quantifying uncertainty\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors.html#r-squared-r2",
    "href": "slides/16-linear-model-multiple-predictors.html#r-squared-r2",
    "title": "Linear regression with multiple predictors",
    "section": "R-squared (\\(R^2\\))",
    "text": "R-squared (\\(R^2\\))\n\nR-squared is a statistical measure that represents the proportion of the variance for a dependent variable that’s explained by an independent variable or variables in a regression model.\n\n\\[\nR^2 = 1 - \\frac{RSS}{TSS}\n\\]"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors.html#r2-broken-down",
    "href": "slides/16-linear-model-multiple-predictors.html#r2-broken-down",
    "title": "Linear regression with multiple predictors",
    "section": "\\(R^2\\) broken down",
    "text": "\\(R^2\\) broken down\n\nResidualsMean of observationsSums of squares\\(R^2\\)\n\n\n\n\nResiduals are the differences between the observed values and the predicted values from a regression model.\nIf \\(y_i\\) is an observed value and \\(\\hat{y}_i\\) is the predicted value, the residual \\(e_i\\) is given by:\n\\(e_i = y_i - \\hat{y}_i\\)\n\n\n\n\n\n\nThe mean \\(\\bar{y}\\) is the average of all observed values, calculated as\n\\(\\bar{y}=\\frac{1}{n} \\sum_{i=1}^{n}y_i\\)\nWhere \\(n\\) is the number of observations.\n\n\n\n\n\n\nThese are measures of variability within the data set.\nResidual Sum of Squares (RSS):\n\\(RSS = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\\)\n\n\n\n\nThis measures the total deviation of the predicted values from the observed values.\n\n\n\n\nTotal Sum of Squares (TSS):\n\\(TSS = \\sum_{i=1}^{n} (y_i - \\bar{y})^2\\)\nThis measures the total deviation of the observed values from their mean.\n\n\n\n\n\n\nR-squared is calculated as:\n\\(R^2 = 1 - \\frac{RSS}{TSS}\\)\nThis value ranges from 0 to 1 and indicates how well the independent variables explain the variability of the dependent variable."
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors.html#adjusted-r-squared-r2_adj",
    "href": "slides/16-linear-model-multiple-predictors.html#adjusted-r-squared-r2_adj",
    "title": "Linear regression with multiple predictors",
    "section": "Adjusted R-squared (\\(R^2_{adj}\\))",
    "text": "Adjusted R-squared (\\(R^2_{adj}\\))\n\nFormulaKey pointsDegrees of freedom\n\n\n\\[\nR^2_{adj} = 1 - \\frac{RSS / df_{res}}{TSS / df_{tot}}\n\\]\n\n\n\\(df_{res}\\) represents the degrees of freedom of the residuals, which is the number of observations minus the number of predictors minus one.\n\\(df_{tot}\\)​ represents the degrees of freedom of the total variability, which is the number of observations minus one.\n\n\n\n\n\n\nPenalizes Complexity: Adjusted R-squared decreases when unnecessary predictors are added to the model, discouraging overfitting.\nComparability: It is more reliable than R-squared for comparing models with different numbers of predictors.\nValue Range: Unlike R-squared, adjusted R-squared can be negative if the model is worse than a simple mean model, though it typically ranges from 0 to 1.\n\n\n\n\n\n\n\\(df_{res}\\): Degrees of freedom related to the estimate of the population variance around the model’s predictions.\n\\(df_{tot}\\)​: Degrees of freedom related to the estimate of the population variance around the mean of the observed values."
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors.html#in-pursuit-of-occams-razor",
    "href": "slides/16-linear-model-multiple-predictors.html#in-pursuit-of-occams-razor",
    "title": "Linear regression with multiple predictors",
    "section": "In pursuit of Occam’s Razor",
    "text": "In pursuit of Occam’s Razor\n\n\nOccam’s Razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected.\nModel selection follows this principle.\nWe only want to add another variable to the model if the addition of that variable brings something valuable in terms of predictive power to the model.\nIn other words, we prefer the simplest best model, i.e. parsimonious model.\n\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/11-probability.html#what-weve-done-so-far",
    "href": "slides/11-probability.html#what-weve-done-so-far",
    "title": "Intro to Probability",
    "section": "What we’ve done so far…",
    "text": "What we’ve done so far…\n\nUse visualization techniques to visualize data\n\nUse descriptive statistics to describe and summarize data\nUse data wrangling tools to manipulate data\n…all using the reproducible, shareable tools of Python, Jupyter, and git\n\nThat’s all great, but what we eventually want to do is to quantify uncertainty in order to make principled conclusions about the data"
  },
  {
    "objectID": "slides/11-probability.html#the-statistical-process",
    "href": "slides/11-probability.html#the-statistical-process",
    "title": "Intro to Probability",
    "section": "The statistical process",
    "text": "The statistical process\n\n\nStatistics is a process that converts data into useful information, where practitioners\n\n1️⃣ form a question of interest,\n\n\n2️⃣ collect and summarize data,\n\n\n3️⃣ and interpret the results."
  },
  {
    "objectID": "slides/11-probability.html#the-population-of-interest",
    "href": "slides/11-probability.html#the-population-of-interest",
    "title": "Intro to Probability",
    "section": "The population of interest",
    "text": "The population of interest\nThe population is the group we’d like to learn something about.\n\n\nWhat is the prevalence of diabetes among U.S. adults, and has it changed over time?\nDoes the average amount of caffeine vary by vendor in 12 oz. cups of coffee at U of A coffee shops?\nIs there a relationship between tumor type and five-year mortality among breast cancer patients?\n\n\n\nThe research question of interest is what we want to answer - often relating one or more numerical quantities or summary statistics.\n\n\nIf we had data from every unit in the population, we could just calculate what we wanted and be done!"
  },
  {
    "objectID": "slides/11-probability.html#sampling-from-the-population",
    "href": "slides/11-probability.html#sampling-from-the-population",
    "title": "Intro to Probability",
    "section": "Sampling from the population",
    "text": "Sampling from the population\nUnfortunately, we (usually) have to settle with a sample from the population.\n\nIdeally, the sample is representative (has similar characteristics as the population), allowing us to make conclusions that are generalizable (i.e. applicable) to the broader population of interest.\n\n\n\nWe’ll use probability and statistical inference (more on this later!) to draw conclusions about the population based on our sample."
  },
  {
    "objectID": "slides/11-probability.html#interpretations-of-probability",
    "href": "slides/11-probability.html#interpretations-of-probability",
    "title": "Intro to Probability",
    "section": "Interpretations of probability",
    "text": "Interpretations of probability\n\n“There is a 1 in 3 chance of selecting a white ball”"
  },
  {
    "objectID": "slides/11-probability.html#interpretations-of-probability-1",
    "href": "slides/11-probability.html#interpretations-of-probability-1",
    "title": "Intro to Probability",
    "section": "Interpretations of probability",
    "text": "Interpretations of probability\n\n“There is a 75% chance of rain tomorrow”"
  },
  {
    "objectID": "slides/11-probability.html#interpretations-of-probability-2",
    "href": "slides/11-probability.html#interpretations-of-probability-2",
    "title": "Intro to Probability",
    "section": "Interpretations of probability",
    "text": "Interpretations of probability\n\n“The surgery has a 50% probability of success”"
  },
  {
    "objectID": "slides/11-probability.html#interpretations-of-probability-3",
    "href": "slides/11-probability.html#interpretations-of-probability-3",
    "title": "Intro to Probability",
    "section": "Interpretations of probability",
    "text": "Interpretations of probability\n\nLong-run frequencies vs. degree of belief"
  },
  {
    "objectID": "slides/11-probability.html#what-do-we-need",
    "href": "slides/11-probability.html#what-do-we-need",
    "title": "Intro to Probability",
    "section": "What do we need?",
    "text": "What do we need?\nWe can think of probabilities as objects that model random phenomena. We’ll use three components to talk about probabilities:\n\n1️⃣ Sample space: the set of all possible outcomes\n\n\n2️⃣ Events: Subsets of the sample space, comprise any number of possible outcomes (including none of them!)\n\n\n3️⃣ Probability: Proportion of times an event would occur if we observed the random phenomenon an infinite number of times."
  },
  {
    "objectID": "slides/11-probability.html#sample-spaces",
    "href": "slides/11-probability.html#sample-spaces",
    "title": "Intro to Probability",
    "section": "Sample spaces",
    "text": "Sample spaces\nSample spaces depend on the random phenomenon in question\n\n\nTossing a single fair coin\nSum of rolling two fair six-sided dice\nGuessing the answer on a multiple choice question with choices a, b, c, d.\n\n\n\n\nWhat are the sample spaces for the random phenomena above?"
  },
  {
    "objectID": "slides/11-probability.html#events",
    "href": "slides/11-probability.html#events",
    "title": "Intro to Probability",
    "section": "Events",
    "text": "Events\nEvents are subsets of the sample space that comprise all possible outcomes from that event. These are the “plausibly reasonable” outcomes we may want to calculate the probabilities for:\n\n\nTossing a single fair coin\nSum of rolling two fair six-sided dice\nGuessing the answer on a multiple choice question with choices a, b, c, d.\n\n\n\n\n\nWhat are some examples of events for the random phenomena above?"
  },
  {
    "objectID": "slides/11-probability.html#probabilities",
    "href": "slides/11-probability.html#probabilities",
    "title": "Intro to Probability",
    "section": "Probabilities",
    "text": "Probabilities\nConsider the following possible events and their corresponding probabilities:\n\n\nGetting a head from a single fair coin toss: 0.5\nGetting a prime number sum from rolling two fair six-sided dice: 5/12\nGuessing the correct answer: 1/4\n\n\n\n\nWe’ll talk more about how we calculated these probabilities, but for now remember that probabilities are numbers describing the likelihood of each event’s occurrence, which map events to a number between 0 and 1, inclusive."
  },
  {
    "objectID": "slides/11-probability.html#set-operations",
    "href": "slides/11-probability.html#set-operations",
    "title": "Intro to Probability",
    "section": "Set operations",
    "text": "Set operations\nRemember that events are (sub)sets of the outcome space. For two sets (in this case events) \\(A\\) and \\(B\\), the most common relationships are:\n\n\nIntersection \\((A \\text{ and } B)\\): \\(A\\) and \\(B\\) both occur\nUnion \\((A \\text{ or } B)\\): \\(A\\) or \\(B\\) occurs (including when both occur)\nComplement \\((A^c)\\): \\(A\\) does not occur\n\n\n\n\nTwo sets \\(A\\) and \\(B\\) are said to be disjoint or mutually exclusive if they cannot happen at the same time, i.e. \\(A \\text{ and } B = \\emptyset\\)."
  },
  {
    "objectID": "slides/11-probability.html#combining-set-operations",
    "href": "slides/11-probability.html#combining-set-operations",
    "title": "Intro to Probability",
    "section": "Combining set operations",
    "text": "Combining set operations\n\n\nDeMorgan’s laws\n\n\nComplement of union: \\((A \\text{ or } B)^c = A^c \\text{ and } B^c\\)\nComplement of intersection: \\((A \\text{ and } B)^c = A^c \\text{ or } B^c\\)\n\n\n\nThese can be extended to more than two events"
  },
  {
    "objectID": "slides/11-probability.html#how-do-probabilities-work",
    "href": "slides/11-probability.html#how-do-probabilities-work",
    "title": "Intro to Probability",
    "section": "How do probabilities work?",
    "text": "How do probabilities work?\nKolmogorov axioms\n\n✅ The probability of any event is real number that’s \\(\\geq 0\\)\n\n\n✅ The probability of the entire sample space is 1\n\n\n✅ If \\(A\\) and \\(B\\) are disjoint events, then \\(P(A \\text{ or } B) = P(A) + P(B)\\)\n\n\n\nThe Kolmogorov axioms lead to all probabilities being between 0 and 1 inclusive, and also lead to important rules…"
  },
  {
    "objectID": "slides/11-probability.html#two-important-rules",
    "href": "slides/11-probability.html#two-important-rules",
    "title": "Intro to Probability",
    "section": "Two important rules",
    "text": "Two important rules\nSuppose we have events \\(A\\) and \\(B\\), with probabilities \\(P(A)\\) and \\(P(B)\\) of occurring. Based on the Kolmogorov axioms:\n\n\nComplement Rule: \\(P(A^c) = 1 - P(A)\\)\nInclusion-Exclusion: \\(P(A \\text{ or } B) = P(A) + P(B) - P(A \\text{ and } B)\\)"
  },
  {
    "objectID": "slides/11-probability.html#practicing-with-probabilities",
    "href": "slides/11-probability.html#practicing-with-probabilities",
    "title": "Intro to Probability",
    "section": "Practicing with probabilities",
    "text": "Practicing with probabilities\n\n\n\n\n\n\n\n\n\nDid not die\nDied\n\n\n\n\nDoes not drink coffee\n5438\n1039\n\n\nDrinks coffee occasionally\n29712\n4440\n\n\nDrinks coffee regularly\n24934\n3601\n\n\n\n\n\nSource: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5788283/"
  },
  {
    "objectID": "slides/11-probability.html#practicing-with-probabilities-1",
    "href": "slides/11-probability.html#practicing-with-probabilities-1",
    "title": "Intro to Probability",
    "section": "Practicing with probabilities",
    "text": "Practicing with probabilities\n\n\n\n\nDid not die\nDied\n\n\n\n\nDoes not drink coffee\n5438\n1039\n\n\nDrinks coffee occasionally\n29712\n4440\n\n\nDrinks coffee regularly\n24934\n3601\n\n\n\n\n\nDefine events A = died and B = non-coffee drinker. Calculate the following for a randomly selected person in the cohort:\n\n\n\\(\\small{P(A)}\\)\n\\(\\small{P(B)}\\)\n\\(\\small{P(A \\text{ and } B)}\\)\n\\(\\small{P(A \\text{ or } B)}\\)\n\\(\\small{P(A \\text{ or } B^c)}\\)\n\n\n\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/09-exam-1-review.html#setup",
    "href": "slides/09-exam-1-review.html#setup",
    "title": "Exam 1 review",
    "section": "Setup",
    "text": "Setup\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set(style=\"whitegrid\", font_scale=1.2)"
  },
  {
    "objectID": "slides/09-exam-1-review.html#explicit-vs.-implicit-type-coercion",
    "href": "slides/09-exam-1-review.html#explicit-vs.-implicit-type-coercion",
    "title": "Exam 1 review",
    "section": "Explicit vs. implicit type coercion",
    "text": "Explicit vs. implicit type coercion\n\nExplicit type coercion: You ask Python to change the type of a variable\nImplicit type coercion: Python changes / makes assumptions for you about the type of a variable without you asking for it\n\nThis happens because in a series, you can’t have multiple types of values"
  },
  {
    "objectID": "slides/09-exam-1-review.html#vectors",
    "href": "slides/09-exam-1-review.html#vectors",
    "title": "Exam 1 review",
    "section": "Vectors",
    "text": "Vectors\n\n\nA vector is a collection of values\n\nAtomic vectors can only contain values of the same type\nLists can contain values of different types\n\nWhy do we care? Because each column of a data frame is a vector.\n\n\n\n\ndf = pd.DataFrame({\n    'x': [1, 2, 3],          # numeric (int)\n    'y': ['a', 'b', 'c'],    # character\n    'z': [True, False, True] # boolean\n})\ndf\n\n\n\n\n\n\n\n\nx\ny\nz\n\n\n\n\n0\n1\na\nTrue\n\n\n1\n2\nb\nFalse\n\n\n2\n3\nc\nTrue"
  },
  {
    "objectID": "slides/09-exam-1-review.html#explicit-coercion",
    "href": "slides/09-exam-1-review.html#explicit-coercion",
    "title": "Exam 1 review",
    "section": "Explicit coercion",
    "text": "Explicit coercion\n✅ From numeric to character\n\ndf['x_new'] = df['x'].astype(str)\ndf\n\n\n\n\n\n\n\n\nx\ny\nz\nx_new\n\n\n\n\n0\n1\na\nTrue\n1\n\n\n1\n2\nb\nFalse\n2\n\n\n2\n3\nc\nTrue\n3"
  },
  {
    "objectID": "slides/09-exam-1-review.html#explicit-coercion-1",
    "href": "slides/09-exam-1-review.html#explicit-coercion-1",
    "title": "Exam 1 review",
    "section": "Explicit coercion",
    "text": "Explicit coercion\n❌ From character to numeric\n\ndf['y_new'] = pd.to_numeric(df['y'], errors='coerce')\ndf\n\n\n\n\n\n\n\n\nx\ny\nz\nx_new\ny_new\n\n\n\n\n0\n1\na\nTrue\n1\nNaN\n\n\n1\n2\nb\nFalse\n2\nNaN\n\n\n2\n3\nc\nTrue\n3\nNaN"
  },
  {
    "objectID": "slides/09-exam-1-review.html#implicit-coercion",
    "href": "slides/09-exam-1-review.html#implicit-coercion",
    "title": "Exam 1 review",
    "section": "Implicit coercion",
    "text": "Implicit coercion\n\nWhich of the column types were implicitly coerced?\n\n\ndf = pd.DataFrame({\n    'w': [1, 2, 3],\n    'x': ['a', 'b', 4],\n    'y': ['c', 'd', np.nan],\n    'z': [5, 6, np.nan],\n})\ndf\n\n\n\n\n\n\n\n\nw\nx\ny\nz\n\n\n\n\n0\n1\na\nc\n5.0\n\n\n1\n2\nb\nd\n6.0\n\n\n2\n3\n4\nNaN\nNaN"
  },
  {
    "objectID": "slides/09-exam-1-review.html#collecting-data",
    "href": "slides/09-exam-1-review.html#collecting-data",
    "title": "Exam 1 review",
    "section": "Collecting data",
    "text": "Collecting data\n\nSuppose you conduct a survey and ask students their student ID number and number of credits they’re taking this semester. What is the type of each variable?\n\n\n\nsurvey_raw = pd.DataFrame({\n    'student_id': [273674, 298765, 287129, \"I don't remember\"],\n    'n_credits': [4, 4.5, \"I'm not sure yet\", \"2 - underloading\"]\n})\nsurvey_raw\n\n\n\n\n\n\n\n\nstudent_id\nn_credits\n\n\n\n\n0\n273674\n4\n\n\n1\n298765\n4.5\n\n\n2\n287129\nI'm not sure yet\n\n\n3\nI don't remember\n2 - underloading"
  },
  {
    "objectID": "slides/09-exam-1-review.html#cleaning-data",
    "href": "slides/09-exam-1-review.html#cleaning-data",
    "title": "Exam 1 review",
    "section": "Cleaning data",
    "text": "Cleaning data\n\nsurvey = survey_raw.copy()\nsurvey['student_id'] = survey['student_id'].replace(\"I don't remember\", np.nan)\nsurvey['n_credits'] = survey['n_credits'].replace({\n    \"I'm not sure yet\": np.nan,\n    \"2 - underloading\": \"2\"\n})\nsurvey['n_credits'] = pd.to_numeric(survey['n_credits'])\nsurvey\n\n\n\n\n\n\n\n\nstudent_id\nn_credits\n\n\n\n\n0\n273674.0\n4.0\n\n\n1\n298765.0\n4.5\n\n\n2\n287129.0\nNaN\n\n\n3\nNaN\n2.0"
  },
  {
    "objectID": "slides/09-exam-1-review.html#cleaning-data-alternative",
    "href": "slides/09-exam-1-review.html#cleaning-data-alternative",
    "title": "Exam 1 review",
    "section": "Cleaning data – alternative",
    "text": "Cleaning data – alternative\n\nsurvey = survey_raw.copy()\nsurvey['student_id'] = pd.to_numeric(survey['student_id'], errors='coerce')\nsurvey['n_credits'] = pd.to_numeric(survey['n_credits'], errors='coerce')\nsurvey\n\n\n\n\n\n\n\n\nstudent_id\nn_credits\n\n\n\n\n0\n273674.0\n4.0\n\n\n1\n298765.0\n4.5\n\n\n2\n287129.0\nNaN\n\n\n3\nNaN\nNaN"
  },
  {
    "objectID": "slides/09-exam-1-review.html#recap-type-coercion",
    "href": "slides/09-exam-1-review.html#recap-type-coercion",
    "title": "Exam 1 review",
    "section": "Recap: Type coercion",
    "text": "Recap: Type coercion\n\n\nIf variables in a DataFrame have multiple types of values, Python will coerce them into a single type, which may or may not be what you want.\nIf what Python does by default is not what you want, you can use explicit coercion functions like pd.to_numeric(), astype(), etc., to turn them into the types you want them to be, which will generally also involve cleaning up the features of the data that caused the unwanted implicit coercion in the first place."
  },
  {
    "objectID": "slides/09-exam-1-review.html#loan50-example-dataframe",
    "href": "slides/09-exam-1-review.html#loan50-example-dataframe",
    "title": "Exam 1 review",
    "section": "loan50 example DataFrame",
    "text": "loan50 example DataFrame\n\nloan50 = pd.read_csv(\"data/loan50.csv\")\nloan50.head()\n\n\n\n\n\n\n\n\nstate\nemp_length\nterm\nhomeownership\nannual_income\nverified_income\ndebt_to_income\ntotal_credit_limit\ntotal_credit_utilized\nnum_cc_carrying_balance\nloan_purpose\nloan_amount\ngrade\ninterest_rate\npublic_record_bankrupt\nloan_status\nhas_second_income\ntotal_income\n\n\n\n\n0\nNJ\n3.0\n60\nrent\n59000.0\nNot Verified\n0.557525\n95131\n32894\n8\ndebt_consolidation\n22000\nB\n10.90\n0\nCurrent\nFalse\n59000.0\n\n\n1\nCA\n10.0\n36\nrent\n60000.0\nNot Verified\n1.305683\n51929\n78341\n2\ncredit_card\n6000\nB\n9.92\n1\nCurrent\nFalse\n60000.0\n\n\n2\nSC\nNaN\n36\nmortgage\n75000.0\nVerified\n1.056280\n301373\n79221\n14\ndebt_consolidation\n25000\nE\n26.30\n0\nCurrent\nFalse\n75000.0\n\n\n3\nCA\n0.0\n36\nrent\n75000.0\nNot Verified\n0.574347\n59890\n43076\n10\ncredit_card\n6000\nB\n9.92\n0\nCurrent\nFalse\n75000.0\n\n\n4\nOH\n4.0\n60\nmortgage\n254000.0\nNot Verified\n0.238150\n422619\n60490\n2\nhome_improvement\n25000\nB\n9.43\n0\nCurrent\nFalse\n254000.0"
  },
  {
    "objectID": "slides/09-exam-1-review.html#aesthetic-mappings-1",
    "href": "slides/09-exam-1-review.html#aesthetic-mappings-1",
    "title": "Exam 1 review",
    "section": "Aesthetic mappings",
    "text": "Aesthetic mappings\n\nWhat will the following code result in?\n\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=loan50, x='annual_income', y='interest_rate', hue='homeownership', style='homeownership', palette='colorblind')\nplt.show()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#aesthetic-mappings-2",
    "href": "slides/09-exam-1-review.html#aesthetic-mappings-2",
    "title": "Exam 1 review",
    "section": "Aesthetic mappings",
    "text": "Aesthetic mappings\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=loan50, x='annual_income', y='interest_rate', hue='homeownership', style='homeownership', palette='colorblind')\nplt.show()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#multiple-plot-layers",
    "href": "slides/09-exam-1-review.html#multiple-plot-layers",
    "title": "Exam 1 review",
    "section": "Multiple plot layers",
    "text": "Multiple plot layers\n\nWhat will the following code result in?\n\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=loan50, x='annual_income', y='interest_rate', hue='homeownership', style='homeownership', palette='colorblind')\nsns.lineplot(data=loan50, x='annual_income', y='interest_rate', hue='homeownership', legend=False, palette='colorblind')\nplt.show()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#multiple-plot-layers-1",
    "href": "slides/09-exam-1-review.html#multiple-plot-layers-1",
    "title": "Exam 1 review",
    "section": "Multiple plot layers",
    "text": "Multiple plot layers\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=loan50, x='annual_income', y='interest_rate', hue='homeownership', style='homeownership', palette='colorblind')\nsns.lineplot(data=loan50, x='annual_income', y='interest_rate', hue='homeownership', legend=False, palette='colorblind')\nplt.show()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#mapping-vs.-setting",
    "href": "slides/09-exam-1-review.html#mapping-vs.-setting",
    "title": "Exam 1 review",
    "section": "Mapping vs. setting",
    "text": "Mapping vs. setting\n\nWhat will the following code result in?\n\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=loan50, x='annual_income', y='interest_rate', hue='homeownership', palette='colorblind')\nsns.lineplot(data=loan50, x='annual_income', y='interest_rate', color='red', legend=False)\nplt.show()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#mapping-vs.-setting-1",
    "href": "slides/09-exam-1-review.html#mapping-vs.-setting-1",
    "title": "Exam 1 review",
    "section": "Mapping vs. setting",
    "text": "Mapping vs. setting\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=loan50, x='annual_income', y='interest_rate', hue='homeownership', palette='colorblind')\nsns.lineplot(data=loan50, x='annual_income', y='interest_rate', color='red', legend=False)\nplt.show()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#recap-aesthetic-mappings",
    "href": "slides/09-exam-1-review.html#recap-aesthetic-mappings",
    "title": "Exam 1 review",
    "section": "Recap: Aesthetic mappings",
    "text": "Recap: Aesthetic mappings\n\n\nAesthetic mapping defined at the local level will be used only by the elements they’re defined for.\nSetting colors produces a manual color aesthetic, while mapping assigns colors automatically based on the qualifier."
  },
  {
    "objectID": "slides/09-exam-1-review.html#aside-legends",
    "href": "slides/09-exam-1-review.html#aside-legends",
    "title": "Exam 1 review",
    "section": "Aside: Legends",
    "text": "Aside: Legends\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=loan50, x='annual_income', y='interest_rate', hue='homeownership', style='homeownership')\nplt.legend(title='Home ownership')\nplt.show()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#categorical",
    "href": "slides/09-exam-1-review.html#categorical",
    "title": "Exam 1 review",
    "section": "Categorical",
    "text": "Categorical\n\nCategorical variables — variables that have a fixed and known set of possible values — are used in the pandas library.\n\n\n\nThey are also useful when you want to display character vectors in a non-alphabetical order.\n\n\n\npandas: https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html"
  },
  {
    "objectID": "slides/09-exam-1-review.html#bar-plot",
    "href": "slides/09-exam-1-review.html#bar-plot",
    "title": "Exam 1 review",
    "section": "Bar plot",
    "text": "Bar plot\n\nplt.figure(figsize=(8, 6))\nsns.countplot(data=loan50, x='homeownership')\nplt.show()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#bar-plot---reordered",
    "href": "slides/09-exam-1-review.html#bar-plot---reordered",
    "title": "Exam 1 review",
    "section": "Bar plot - reordered",
    "text": "Bar plot - reordered\n\nloan50['homeownership'] = pd.Categorical(loan50['homeownership'], categories=['mortgage', 'rent', 'own'])\nplt.figure(figsize=(8, 6))\nsns.countplot(data=loan50, x='homeownership')\nplt.show()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#frequency-table",
    "href": "slides/09-exam-1-review.html#frequency-table",
    "title": "Exam 1 review",
    "section": "Frequency table",
    "text": "Frequency table\n\nloan50['homeownership'].value_counts()\n\nhomeownership\nmortgage    26\nrent        21\nown          3\nName: count, dtype: int64"
  },
  {
    "objectID": "slides/09-exam-1-review.html#under-the-hood",
    "href": "slides/09-exam-1-review.html#under-the-hood",
    "title": "Exam 1 review",
    "section": "Under the hood",
    "text": "Under the hood\n\nprint(type(loan50['homeownership']))\n\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n\n\nprint(loan50['homeownership'].dtype)\n\ncategory\n\n\n\n\n\nprint(loan50['homeownership'].cat.categories)\n\nIndex(['mortgage', 'rent', 'own'], dtype='object')\n\n\n\n\n\nprint(loan50['homeownership'])\n\n0         rent\n1         rent\n2     mortgage\n3         rent\n4     mortgage\n5     mortgage\n6         rent\n7     mortgage\n8         rent\n9     mortgage\n10        rent\n11    mortgage\n12        rent\n13    mortgage\n14        rent\n15    mortgage\n16        rent\n17        rent\n18        rent\n19    mortgage\n20    mortgage\n21    mortgage\n22    mortgage\n23        rent\n24    mortgage\n25        rent\n26    mortgage\n27         own\n28    mortgage\n29    mortgage\n30        rent\n31    mortgage\n32    mortgage\n33        rent\n34        rent\n35         own\n36    mortgage\n37        rent\n38    mortgage\n39        rent\n40    mortgage\n41        rent\n42        rent\n43    mortgage\n44    mortgage\n45    mortgage\n46    mortgage\n47        rent\n48         own\n49    mortgage\nName: homeownership, dtype: category\nCategories (3, object): ['mortgage', 'rent', 'own']"
  },
  {
    "objectID": "slides/09-exam-1-review.html#recap-categorical",
    "href": "slides/09-exam-1-review.html#recap-categorical",
    "title": "Exam 1 review",
    "section": "Recap: Categorical",
    "text": "Recap: Categorical\n\n\nThe pandas.Categorical type is useful for dealing with categorical data and their levels.\nFactors and the order of their levels are relevant for displays (tables, plots) and they’ll be relevant for modeling (later in the course).\nCategorical is a data class in pandas."
  },
  {
    "objectID": "slides/09-exam-1-review.html#aside",
    "href": "slides/09-exam-1-review.html#aside",
    "title": "Exam 1 review",
    "section": "Aside: ==",
    "text": "Aside: ==\n\nloan50['homeownership_new'] = loan50['homeownership'].apply(lambda x: \"don't own\" if x == 'rent' else x)\nloan50[['homeownership', 'homeownership_new']].drop_duplicates()\n\n\n\n\n\n\n\n\nhomeownership\nhomeownership_new\n\n\n\n\n0\nrent\ndon't own\n\n\n2\nmortgage\nmortgage\n\n\n27\nown\nown"
  },
  {
    "objectID": "slides/09-exam-1-review.html#aside-filtering",
    "href": "slides/09-exam-1-review.html#aside-filtering",
    "title": "Exam 1 review",
    "section": "Aside: Filtering",
    "text": "Aside: Filtering\n\nloan50['homeownership_new'] = loan50['homeownership'].apply(lambda x: \"don't own\" if x in ['rent', 'mortgage'] else x)\nloan50[['homeownership', 'homeownership_new']].drop_duplicates()\n\n\n\n\n\n\n\n\nhomeownership\nhomeownership_new\n\n\n\n\n0\nrent\ndon't own\n\n\n2\nmortgage\ndon't own\n\n\n27\nown\nown"
  },
  {
    "objectID": "slides/05-visualizing-data.html#setup",
    "href": "slides/05-visualizing-data.html#setup",
    "title": "Visualizing various types of data",
    "section": "Setup",
    "text": "Setup\n\n# Import necessary libraries\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom palmerpenguins import load_penguins\n\n# Load the penguins dataset\npenguins = load_penguins()\n\n# Set theme\nsns.set_theme(style=\"whitegrid\")"
  },
  {
    "objectID": "slides/05-visualizing-data.html#examining-data-visualization",
    "href": "slides/05-visualizing-data.html#examining-data-visualization",
    "title": "Visualizing various types of data",
    "section": "Examining data visualization",
    "text": "Examining data visualization\n\n\nDiscuss the following for the visualization in the #lecture-discussions Slack Channel.\n\n\n\n\nSource: Twitter"
  },
  {
    "objectID": "slides/05-visualizing-data.html#violin-plots",
    "href": "slides/05-visualizing-data.html#violin-plots",
    "title": "Visualizing various types of data",
    "section": "Violin plots",
    "text": "Violin plots\n\n\nCode\nplt.figure(figsize=(8, 6))\nsns.violinplot(x=\"species\", y=\"body_mass_g\", data=penguins)\nplt.title('Violin Plot of Body Mass by Species')\nplt.show()"
  },
  {
    "objectID": "slides/05-visualizing-data.html#multiple-geoms",
    "href": "slides/05-visualizing-data.html#multiple-geoms",
    "title": "Visualizing various types of data",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\n\nCode\nplt.figure(figsize=(8, 6))\nsns.violinplot(x=\"species\", y=\"body_mass_g\", data=penguins)\nsns.stripplot(x=\"species\", y=\"body_mass_g\", data=penguins, jitter=False, color='black')\nplt.title('Violin Plot with Points of Body Mass by Species')\nplt.show()"
  },
  {
    "objectID": "slides/05-visualizing-data.html#multiple-geoms-1",
    "href": "slides/05-visualizing-data.html#multiple-geoms-1",
    "title": "Visualizing various types of data",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\n\nCode\nplt.figure(figsize=(8, 6))\nsns.violinplot(x=\"species\", y=\"body_mass_g\", data=penguins)\nsns.stripplot(x=\"species\", y=\"body_mass_g\", data=penguins, jitter=True, color='black')\nplt.title('Violin Plot with Points of Body Mass by Species')\nplt.show()"
  },
  {
    "objectID": "slides/05-visualizing-data.html#multiple-geoms-aesthetics",
    "href": "slides/05-visualizing-data.html#multiple-geoms-aesthetics",
    "title": "Visualizing various types of data",
    "section": "Multiple geoms + aesthetics",
    "text": "Multiple geoms + aesthetics\n\n\nCode\nplt.figure(figsize=(8, 6))\nsns.violinplot(x=\"species\", y=\"body_mass_g\", data=penguins)\nsns.stripplot(x=\"species\", y=\"body_mass_g\", data=penguins, jitter=True, hue='species')\nplt.title('Violin Plot with Jittered Points and Color by Species')\nplt.legend(title='Species')\nplt.show()"
  },
  {
    "objectID": "slides/05-visualizing-data.html#multiple-geoms-aesthetics-1",
    "href": "slides/05-visualizing-data.html#multiple-geoms-aesthetics-1",
    "title": "Visualizing various types of data",
    "section": "Multiple geoms + aesthetics",
    "text": "Multiple geoms + aesthetics\n\n\nCode\nplt.figure(figsize=(8, 6))\nsns.violinplot(x=\"species\", y=\"body_mass_g\", data=penguins)\nsns.stripplot(x=\"species\", y=\"body_mass_g\", data=penguins, jitter=True, hue='species')\nplt.title('Violin Plot with Jittered Points, Color by Species, and No Legend')\nplt.legend(title='Species').remove()\nplt.show()"
  },
  {
    "objectID": "slides/05-visualizing-data.html#multiple-geoms-aesthetics-2",
    "href": "slides/05-visualizing-data.html#multiple-geoms-aesthetics-2",
    "title": "Visualizing various types of data",
    "section": "Multiple geoms + aesthetics",
    "text": "Multiple geoms + aesthetics\n\n\nCode\nplt.figure(figsize=(8, 6))\nsns.violinplot(x=\"species\", y=\"body_mass_g\", data=penguins, palette='colorblind')\nsns.stripplot(x=\"species\", y=\"body_mass_g\", data=penguins, jitter=True, hue='species', palette='colorblind')\nplt.title('Violin Plot with Jittered Points, Color by Species, No Legend, and Colorblind Palette')\nplt.legend(title='Species').remove()\nplt.show()"
  },
  {
    "objectID": "slides/05-visualizing-data.html#the-way-data-is-displayed-matters",
    "href": "slides/05-visualizing-data.html#the-way-data-is-displayed-matters",
    "title": "Visualizing various types of data",
    "section": "The way data is displayed matters",
    "text": "The way data is displayed matters\n\nWhat do these three plots show?\n\n\n\n\n\n\n\n\nSource: #barbarplots"
  },
  {
    "objectID": "slides/05-visualizing-data.html#visualizing-penguins",
    "href": "slides/05-visualizing-data.html#visualizing-penguins",
    "title": "Visualizing various types of data",
    "section": "Visualizing penguins",
    "text": "Visualizing penguins\n\n\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom palmerpenguins import load_penguins\n\npenguins = load_penguins()\n\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtwork by @allison_horst."
  },
  {
    "objectID": "slides/05-visualizing-data.html#univariate-analysis-1",
    "href": "slides/05-visualizing-data.html#univariate-analysis-1",
    "title": "Visualizing various types of data",
    "section": "Univariate analysis",
    "text": "Univariate analysis\nAnalyzing a single variable:\n\nNumerical: histogram, box plot, density plot, etc.\nCategorical: bar plot, pie chart, etc."
  },
  {
    "objectID": "slides/05-visualizing-data.html#histogram",
    "href": "slides/05-visualizing-data.html#histogram",
    "title": "Visualizing various types of data",
    "section": "Histogram",
    "text": "Histogram\n\n\nCode\nplt.figure(figsize=(8, 6))\nsns.histplot(penguins['body_mass_g'], bins=30)\nplt.title('Histogram of Penguin Body Mass')\nplt.xlabel('Body Mass (g)')\nplt.ylabel('Count')\nplt.show()"
  },
  {
    "objectID": "slides/05-visualizing-data.html#boxplot",
    "href": "slides/05-visualizing-data.html#boxplot",
    "title": "Visualizing various types of data",
    "section": "Boxplot",
    "text": "Boxplot\n\n\nCode\nplt.figure(figsize=(8, 6))\nsns.boxplot(y=penguins['body_mass_g'])\nplt.title('Boxplot of Penguin Body Mass')\nplt.ylabel('Body Mass (g)')\nplt.show()"
  },
  {
    "objectID": "slides/05-visualizing-data.html#density-plot",
    "href": "slides/05-visualizing-data.html#density-plot",
    "title": "Visualizing various types of data",
    "section": "Density plot",
    "text": "Density plot\n\n\nCode\nplt.figure(figsize=(10, 6))\nsns.kdeplot(penguins['body_mass_g'], fill=True)\nplt.title('Density Plot of Penguin Body Mass')\nplt.xlabel('Body Mass (g)')\nplt.ylabel('Density')\nplt.show()"
  },
  {
    "objectID": "slides/05-visualizing-data.html#bivariate-analysis-1",
    "href": "slides/05-visualizing-data.html#bivariate-analysis-1",
    "title": "Visualizing various types of data",
    "section": "Bivariate analysis",
    "text": "Bivariate analysis\nAnalyzing the relationship between two variables:\n\nNumerical + numerical: scatterplot\nNumerical + categorical: side-by-side box plots, violin plots, etc.\nCategorical + categorical: stacked bar plots\nUsing an aesthetic (e.g., fill, color, shape, etc.) or facets to represent the second variable in any plot"
  },
  {
    "objectID": "slides/05-visualizing-data.html#side-by-side-box-plots",
    "href": "slides/05-visualizing-data.html#side-by-side-box-plots",
    "title": "Visualizing various types of data",
    "section": "Side-by-side box plots",
    "text": "Side-by-side box plots\n\n\nCode\nplt.figure(figsize=(8, 6))\nsns.boxplot(x=\"species\", y=\"body_mass_g\", data=penguins)\nplt.title('Side-by-side Box Plots of Body Mass by Species')\nplt.xlabel('Species')\nplt.ylabel('Body Mass (g)')\nplt.show()"
  },
  {
    "objectID": "slides/05-visualizing-data.html#density-plots",
    "href": "slides/05-visualizing-data.html#density-plots",
    "title": "Visualizing various types of data",
    "section": "Density plots",
    "text": "Density plots\n\n\nCode\nplt.figure(figsize=(8, 6))\nsns.kdeplot(data=penguins, x=\"body_mass_g\", hue=\"species\", fill=True)\nplt.title('Density Plot of Body Mass by Species')\nplt.xlabel('Body Mass (g)')\nplt.ylabel('Density')\nplt.show()"
  },
  {
    "objectID": "slides/05-visualizing-data.html#bechdel-test",
    "href": "slides/05-visualizing-data.html#bechdel-test",
    "title": "Visualizing various types of data",
    "section": "Bechdel Test",
    "text": "Bechdel Test\n\n\n\nThe Bechdel test also known as the Bechdel-Wallace test, is a measure of the representation of women in film and other fiction. The test asks whether a work features at least two female characters who have a conversation about something other than a man. Some versions of the test also require that those two female characters have names."
  },
  {
    "objectID": "slides/05-visualizing-data.html#load-bechdel-test-data",
    "href": "slides/05-visualizing-data.html#load-bechdel-test-data",
    "title": "Visualizing various types of data",
    "section": "Load Bechdel test data",
    "text": "Load Bechdel test data\nLoad the Bechdel test data with pd.read_csv()\n\nbechdel = pd.read_csv(\"data/bechdel.csv\")\n\nlist() the .columns names of the bechdel data:\n\nlist(bechdel.columns)\n\n['title', 'year', 'gross_2013', 'budget_2013', 'roi', 'binary', 'clean_test']"
  },
  {
    "objectID": "slides/05-visualizing-data.html#roi-by-test-result",
    "href": "slides/05-visualizing-data.html#roi-by-test-result",
    "title": "Visualizing various types of data",
    "section": "ROI by test result",
    "text": "ROI by test result\n\nWhat about this plot makes it difficult to evaluate how ROI varies by Bechdel test result?\n\n\n\nCode\nplt.figure(figsize=(8, 4))\nsns.stripplot(x='roi', y='clean_test', hue='binary', data=bechdel)\nplt.title('ROI by Bechdel Test Result')\nplt.xlabel('ROI')\nplt.ylabel('Bechdel Test Result')\nplt.legend(title='Binary')\nplt.show()"
  },
  {
    "objectID": "slides/05-visualizing-data.html#movies-with-high-roi",
    "href": "slides/05-visualizing-data.html#movies-with-high-roi",
    "title": "Visualizing various types of data",
    "section": "Movies with high ROI",
    "text": "Movies with high ROI\n\nWhat are the movies with highest ROI?\n\n\nhigh_roi_movies = bechdel[bechdel['roi'] &gt; 400][['title', 'roi', 'budget_2013', 'gross_2013', 'year', 'clean_test']]\nprint(high_roi_movies)\n\n                        title         roi  budget_2013   gross_2013  year  \\\n703       Paranormal Activity  671.336857       505595  339424558.0  2007   \n1319  The Blair Witch Project  648.065333       839077  543776715.0  1999   \n1575              El Mariachi  583.285665        11622    6778946.0  1992   \n\n     clean_test  \n703     dubious  \n1319         ok  \n1575    nowomen"
  },
  {
    "objectID": "slides/05-visualizing-data.html#roi-by-test-result-1",
    "href": "slides/05-visualizing-data.html#roi-by-test-result-1",
    "title": "Visualizing various types of data",
    "section": "ROI by test result",
    "text": "ROI by test result\n\nZoom in: What about this plot makes it difficult to evaluate how ROI varies by Bechdel test result?\n\n\n\nCode\nplt.figure(figsize=(8, 4))\nsns.boxplot(x='roi', y='clean_test', hue='binary', data=bechdel)\nplt.xlim(0, 15)\nplt.title('Zoomed in ROI by Bechdel Test Result')\nplt.xlabel('ROI')\nplt.ylabel('Bechdel Test Result')\nplt.legend(title='Binary')\nplt.show()"
  },
  {
    "objectID": "slides/05-visualizing-data.html#sneak-preview",
    "href": "slides/05-visualizing-data.html#sneak-preview",
    "title": "Visualizing various types of data",
    "section": "Sneak preview…",
    "text": "Sneak preview…\n \n\nto next week’s data wrangling pipelines…"
  },
  {
    "objectID": "slides/05-visualizing-data.html#median-roi",
    "href": "slides/05-visualizing-data.html#median-roi",
    "title": "Visualizing various types of data",
    "section": "Median ROI",
    "text": "Median ROI\n\nmedian_roi = bechdel['roi'].median()\nprint(f\"Median ROI: {median_roi}\")\n\nMedian ROI: 3.9051317558839456"
  },
  {
    "objectID": "slides/05-visualizing-data.html#median-roi-by-test-result",
    "href": "slides/05-visualizing-data.html#median-roi-by-test-result",
    "title": "Visualizing various types of data",
    "section": "Median ROI by test result",
    "text": "Median ROI by test result\n\nmedian_roi_by_test = bechdel.groupby('clean_test')['roi'].median().reset_index()\nprint(median_roi_by_test)\n\n  clean_test       roi\n0    dubious  3.795816\n1        men  3.964457\n2     notalk  3.688260\n3    nowomen  3.265901\n4         ok  4.211049"
  },
  {
    "objectID": "slides/05-visualizing-data.html#roi-by-test-result-with-median-line",
    "href": "slides/05-visualizing-data.html#roi-by-test-result-with-median-line",
    "title": "Visualizing various types of data",
    "section": "ROI by test result with median line",
    "text": "ROI by test result with median line\n\nWhat does this plot say about return-on-investment on movies that pass the Bechdel test?\n\n\n\nCode\nplt.figure(figsize=(8, 4))\nsns.boxplot(x='roi', y='clean_test', hue='binary', data=bechdel)\nplt.axvline(x=4.21, color='red', linestyle='--')\nplt.xlim(0, 15)\nplt.title('ROI by Bechdel Test Result with Median Line')\nplt.xlabel('ROI')\nplt.ylabel('Bechdel Test Result')\nplt.legend(title='Binary')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/06-preprocessing.html#setup",
    "href": "slides/06-preprocessing.html#setup",
    "title": "Data preprocessing",
    "section": "Setup",
    "text": "Setup\n\n# Import all required libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler\nfrom sklearn.impute import SimpleImputer\nimport statsmodels.api as sm\nimport scipy.stats as stats\n\n# Increase font size of all Seaborn plot elements\nsns.set(font_scale = 1.25)\n\n# Set Seaborn theme\nsns.set_theme(style = \"whitegrid\")"
  },
  {
    "objectID": "slides/06-preprocessing.html#data-preprocessing-1",
    "href": "slides/06-preprocessing.html#data-preprocessing-1",
    "title": "Data preprocessing",
    "section": "Data preprocessing",
    "text": "Data preprocessing\n\nData preprocessing refers to the manipulation, filtration, or augmentation of data before it is analyzed. It is a crucial step in the data science process.\n\n\nIt’s essentially data cleaning."
  },
  {
    "objectID": "slides/06-preprocessing.html#dataset",
    "href": "slides/06-preprocessing.html#dataset",
    "title": "Data preprocessing",
    "section": "Dataset",
    "text": "Dataset\nHuman Freedom Index\nThe Human Freedom Index is a report that attempts to summarize the idea of “freedom” through variables for many countries around the globe."
  },
  {
    "objectID": "slides/06-preprocessing.html#question",
    "href": "slides/06-preprocessing.html#question",
    "title": "Data preprocessing",
    "section": "Question",
    "text": "Question\nWhat trends are there within human freedom indices in different regions?"
  },
  {
    "objectID": "slides/06-preprocessing.html#dataset-human-freedom-index",
    "href": "slides/06-preprocessing.html#dataset-human-freedom-index",
    "title": "Data preprocessing",
    "section": "Dataset: Human Freedom Index",
    "text": "Dataset: Human Freedom Index\n\nhfi = pd.read_csv(\"data/hfi.csv\")\nhfi.head()\n\n\n\n\n\n\n\n\nyear\nISO_code\ncountries\nregion\npf_rol_procedural\npf_rol_civil\npf_rol_criminal\npf_rol\npf_ss_homicide\npf_ss_disappearances_disap\n...\nef_regulation_business_bribes\nef_regulation_business_licensing\nef_regulation_business_compliance\nef_regulation_business\nef_regulation\nef_score\nef_rank\nhf_score\nhf_rank\nhf_quartile\n\n\n\n\n0\n2016\nALB\nAlbania\nEastern Europe\n6.661503\n4.547244\n4.666508\n5.291752\n8.920429\n10.0\n...\n4.050196\n7.324582\n7.074366\n6.705863\n6.906901\n7.54\n34.0\n7.568140\n48.0\n2.0\n\n\n1\n2016\nDZA\nAlgeria\nMiddle East & North Africa\nNaN\nNaN\nNaN\n3.819566\n9.456254\n10.0\n...\n3.765515\n8.523503\n7.029528\n5.676956\n5.268992\n4.99\n159.0\n5.135886\n155.0\n4.0\n\n\n2\n2016\nAGO\nAngola\nSub-Saharan Africa\nNaN\nNaN\nNaN\n3.451814\n8.060260\n5.0\n...\n1.945540\n8.096776\n6.782923\n4.930271\n5.518500\n5.17\n155.0\n5.640662\n142.0\n4.0\n\n\n3\n2016\nARG\nArgentina\nLatin America & the Caribbean\n7.098483\n5.791960\n4.343930\n5.744791\n7.622974\n10.0\n...\n3.260044\n5.253411\n6.508295\n5.535831\n5.369019\n4.84\n160.0\n6.469848\n107.0\n3.0\n\n\n4\n2016\nARM\nArmenia\nCaucasus & Central Asia\nNaN\nNaN\nNaN\n5.003205\n8.808750\n10.0\n...\n4.575152\n9.319612\n6.491481\n6.797530\n7.378069\n7.57\n29.0\n7.241402\n57.0\n2.0\n\n\n\n\n5 rows × 123 columns"
  },
  {
    "objectID": "slides/06-preprocessing.html#understanding-the-data",
    "href": "slides/06-preprocessing.html#understanding-the-data",
    "title": "Data preprocessing",
    "section": "Understanding the data",
    "text": "Understanding the data\n\n.info().describe()\n\n\n\nhfi.info(verbose = True)\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1458 entries, 0 to 1457\nData columns (total 123 columns):\n #    Column                              Dtype  \n---   ------                              -----  \n 0    year                                int64  \n 1    ISO_code                            object \n 2    countries                           object \n 3    region                              object \n 4    pf_rol_procedural                   float64\n 5    pf_rol_civil                        float64\n 6    pf_rol_criminal                     float64\n 7    pf_rol                              float64\n 8    pf_ss_homicide                      float64\n 9    pf_ss_disappearances_disap          float64\n 10   pf_ss_disappearances_violent        float64\n 11   pf_ss_disappearances_organized      float64\n 12   pf_ss_disappearances_fatalities     float64\n 13   pf_ss_disappearances_injuries       float64\n 14   pf_ss_disappearances                float64\n 15   pf_ss_women_fgm                     float64\n 16   pf_ss_women_missing                 float64\n 17   pf_ss_women_inheritance_widows      float64\n 18   pf_ss_women_inheritance_daughters   float64\n 19   pf_ss_women_inheritance             float64\n 20   pf_ss_women                         float64\n 21   pf_ss                               float64\n 22   pf_movement_domestic                float64\n 23   pf_movement_foreign                 float64\n 24   pf_movement_women                   float64\n 25   pf_movement                         float64\n 26   pf_religion_estop_establish         float64\n 27   pf_religion_estop_operate           float64\n 28   pf_religion_estop                   float64\n 29   pf_religion_harassment              float64\n 30   pf_religion_restrictions            float64\n 31   pf_religion                         float64\n 32   pf_association_association          float64\n 33   pf_association_assembly             float64\n 34   pf_association_political_establish  float64\n 35   pf_association_political_operate    float64\n 36   pf_association_political            float64\n 37   pf_association_prof_establish       float64\n 38   pf_association_prof_operate         float64\n 39   pf_association_prof                 float64\n 40   pf_association_sport_establish      float64\n 41   pf_association_sport_operate        float64\n 42   pf_association_sport                float64\n 43   pf_association                      float64\n 44   pf_expression_killed                float64\n 45   pf_expression_jailed                float64\n 46   pf_expression_influence             float64\n 47   pf_expression_control               float64\n 48   pf_expression_cable                 float64\n 49   pf_expression_newspapers            float64\n 50   pf_expression_internet              float64\n 51   pf_expression                       float64\n 52   pf_identity_legal                   float64\n 53   pf_identity_parental_marriage       float64\n 54   pf_identity_parental_divorce        float64\n 55   pf_identity_parental                float64\n 56   pf_identity_sex_male                float64\n 57   pf_identity_sex_female              float64\n 58   pf_identity_sex                     float64\n 59   pf_identity_divorce                 float64\n 60   pf_identity                         float64\n 61   pf_score                            float64\n 62   pf_rank                             float64\n 63   ef_government_consumption           float64\n 64   ef_government_transfers             float64\n 65   ef_government_enterprises           float64\n 66   ef_government_tax_income            float64\n 67   ef_government_tax_payroll           float64\n 68   ef_government_tax                   float64\n 69   ef_government                       float64\n 70   ef_legal_judicial                   float64\n 71   ef_legal_courts                     float64\n 72   ef_legal_protection                 float64\n 73   ef_legal_military                   float64\n 74   ef_legal_integrity                  float64\n 75   ef_legal_enforcement                float64\n 76   ef_legal_restrictions               float64\n 77   ef_legal_police                     float64\n 78   ef_legal_crime                      float64\n 79   ef_legal_gender                     float64\n 80   ef_legal                            float64\n 81   ef_money_growth                     float64\n 82   ef_money_sd                         float64\n 83   ef_money_inflation                  float64\n 84   ef_money_currency                   float64\n 85   ef_money                            float64\n 86   ef_trade_tariffs_revenue            float64\n 87   ef_trade_tariffs_mean               float64\n 88   ef_trade_tariffs_sd                 float64\n 89   ef_trade_tariffs                    float64\n 90   ef_trade_regulatory_nontariff       float64\n 91   ef_trade_regulatory_compliance      float64\n 92   ef_trade_regulatory                 float64\n 93   ef_trade_black                      float64\n 94   ef_trade_movement_foreign           float64\n 95   ef_trade_movement_capital           float64\n 96   ef_trade_movement_visit             float64\n 97   ef_trade_movement                   float64\n 98   ef_trade                            float64\n 99   ef_regulation_credit_ownership      float64\n 100  ef_regulation_credit_private        float64\n 101  ef_regulation_credit_interest       float64\n 102  ef_regulation_credit                float64\n 103  ef_regulation_labor_minwage         float64\n 104  ef_regulation_labor_firing          float64\n 105  ef_regulation_labor_bargain         float64\n 106  ef_regulation_labor_hours           float64\n 107  ef_regulation_labor_dismissal       float64\n 108  ef_regulation_labor_conscription    float64\n 109  ef_regulation_labor                 float64\n 110  ef_regulation_business_adm          float64\n 111  ef_regulation_business_bureaucracy  float64\n 112  ef_regulation_business_start        float64\n 113  ef_regulation_business_bribes       float64\n 114  ef_regulation_business_licensing    float64\n 115  ef_regulation_business_compliance   float64\n 116  ef_regulation_business              float64\n 117  ef_regulation                       float64\n 118  ef_score                            float64\n 119  ef_rank                             float64\n 120  hf_score                            float64\n 121  hf_rank                             float64\n 122  hf_quartile                         float64\ndtypes: float64(119), int64(1), object(3)\nmemory usage: 1.4+ MB\n\n\n\n\n\nhfi.describe()\n\n\n\n\n\n\n\n\nyear\npf_rol_procedural\npf_rol_civil\npf_rol_criminal\npf_rol\npf_ss_homicide\npf_ss_disappearances_disap\npf_ss_disappearances_violent\npf_ss_disappearances_organized\npf_ss_disappearances_fatalities\n...\nef_regulation_business_bribes\nef_regulation_business_licensing\nef_regulation_business_compliance\nef_regulation_business\nef_regulation\nef_score\nef_rank\nhf_score\nhf_rank\nhf_quartile\n\n\n\n\ncount\n1458.000000\n880.000000\n880.000000\n880.000000\n1378.000000\n1378.000000\n1369.000000\n1378.000000\n1279.000000\n1378.000000\n...\n1283.000000\n1357.000000\n1368.000000\n1374.000000\n1378.000000\n1378.000000\n1378.000000\n1378.000000\n1378.000000\n1378.000000\n\n\nmean\n2012.000000\n5.589355\n5.474770\n5.044070\n5.309641\n7.412980\n8.341855\n9.519458\n6.772869\n9.584972\n...\n4.886192\n7.698494\n6.981858\n6.317668\n7.019782\n6.785610\n76.973149\n6.993444\n77.007983\n2.490566\n\n\nstd\n2.582875\n2.080957\n1.428494\n1.724886\n1.529310\n2.832947\n3.225902\n1.744673\n2.768983\n1.559826\n...\n1.889168\n1.728507\n1.979200\n1.230988\n1.027625\n0.883601\n44.540142\n1.025811\n44.506549\n1.119698\n\n\nmin\n2008.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n2.009841\n2.483540\n2.880000\n1.000000\n3.765827\n1.000000\n1.000000\n\n\n25%\n2010.000000\n4.133333\n4.549550\n3.789724\n4.131746\n6.386978\n10.000000\n10.000000\n5.000000\n9.942607\n...\n3.433786\n6.874687\n6.368178\n5.591851\n6.429498\n6.250000\n38.000000\n6.336685\n39.000000\n1.000000\n\n\n50%\n2012.000000\n5.300000\n5.300000\n4.575189\n4.910797\n8.638278\n10.000000\n10.000000\n7.500000\n10.000000\n...\n4.418371\n8.074161\n7.466692\n6.265234\n7.082075\n6.900000\n77.000000\n6.923840\n76.000000\n2.000000\n\n\n75%\n2014.000000\n7.389499\n6.410975\n6.400000\n6.513178\n9.454402\n10.000000\n10.000000\n10.000000\n10.000000\n...\n6.227978\n8.991882\n8.209310\n7.139718\n7.720955\n7.410000\n115.000000\n7.894660\n115.000000\n3.000000\n\n\nmax\n2016.000000\n9.700000\n8.773533\n8.719848\n8.723094\n9.926568\n10.000000\n10.000000\n10.000000\n10.000000\n...\n9.623811\n9.999638\n9.865488\n9.272600\n9.439828\n9.190000\n162.000000\n9.126313\n162.000000\n4.000000\n\n\n\n\n8 rows × 120 columns"
  },
  {
    "objectID": "slides/06-preprocessing.html#identifying-missing-values",
    "href": "slides/06-preprocessing.html#identifying-missing-values",
    "title": "Data preprocessing",
    "section": "Identifying missing values",
    "text": "Identifying missing values\n\nhfi.isna().sum()\n\nyear                   0\nISO_code               0\ncountries              0\nregion                 0\npf_rol_procedural    578\n                    ... \nef_score              80\nef_rank               80\nhf_score              80\nhf_rank               80\nhf_quartile           80\nLength: 123, dtype: int64\n\n\n\n\nA lot of missing values 🙃"
  },
  {
    "objectID": "slides/06-preprocessing.html#handling-missing-data",
    "href": "slides/06-preprocessing.html#handling-missing-data",
    "title": "Data preprocessing",
    "section": "Handling missing data",
    "text": "Handling missing data\nOptions\n\n\nDo nothing…\nRemove them\nImputate\n\n\n\nWe will use the hf_score from hfi: 80 missing values"
  },
  {
    "objectID": "slides/06-preprocessing.html#imputation",
    "href": "slides/06-preprocessing.html#imputation",
    "title": "Data preprocessing",
    "section": "Imputation",
    "text": "Imputation\n\nIn statistics, imputation is the process of replacing missing data with substituted values.\n\n\n\nMean imputation\nMedian imputation\nMode imputation\nSeveral other methods"
  },
  {
    "objectID": "slides/06-preprocessing.html#mean-imputation",
    "href": "slides/06-preprocessing.html#mean-imputation",
    "title": "Data preprocessing",
    "section": "Mean imputation",
    "text": "Mean imputation\n\nDefinitionVisualCode\n\n\nHow it Works: Replace missing values with the arithmetic mean of the non-missing values in the same variable.\n\nPros:\n\n\nEasy and fast.\nWorks well with small numerical datasets\n\n\nCons:\n\n\nIt only works on the column level.\nWill give poor results on encoded categorical features.\nNot very accurate.\nDoesn’t account for the uncertainty in the imputations.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhfi_copy = hfi.copy()\n\nmean_imputer = SimpleImputer(strategy = 'mean')\nhfi_copy['mean_hf_score'] = mean_imputer.fit_transform(hfi_copy[['hf_score']])\n\nmean_plot = sns.kdeplot(data = hfi_copy, x = 'hf_score', linewidth = 2, label = \"Original\")\nmean_plot = sns.kdeplot(data = hfi_copy, x = 'mean_hf_score', linewidth = 2, label = \"Mean Imputed\")\n\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "slides/06-preprocessing.html#median-imputation",
    "href": "slides/06-preprocessing.html#median-imputation",
    "title": "Data preprocessing",
    "section": "Median imputation",
    "text": "Median imputation\n\nDefinitionVisualCode\n\n\nHow it Works: Replace missing values with the arithmetic median of the non-missing values in the same variable.\n\nPros (same as mean):\n\n\nEasy and fast.\nWorks well with small numerical datasets\n\n\nCons (same as mean):\n\n\nIt only works on the column level.\nWill give poor results on encoded categorical features.\nNot very accurate.\nDoesn’t account for the uncertainty in the imputations.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhfi_copy = hfi.copy()\n\nmedian_imputer = SimpleImputer(strategy = 'median')\nhfi_copy['median_hf_score'] = median_imputer.fit_transform(hfi_copy[['hf_score']])\n\nmedian_plot = sns.kdeplot(data = hfi_copy, x = 'hf_score', linewidth = 2, label = \"Original\")\nmedian_plot = sns.kdeplot(data = hfi_copy, x = 'median_hf_score', linewidth = 2, label = \"Median Imputed\")\n\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "slides/06-preprocessing.html#mode-imputation",
    "href": "slides/06-preprocessing.html#mode-imputation",
    "title": "Data preprocessing",
    "section": "Mode imputation",
    "text": "Mode imputation\n\nDefinitionVisualCode\n\n\nHow it Works: Replace missing values with the mode of the non-missing values in the same variable.\n\nPros\n\n\nEasy and fast.\nWorks well with categorical features.\n\n\nCons:\n\n\nDoesn’t factor the correlations between features.\nCan introduce bias in the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhfi_copy = hfi.copy()\n\nmode_imputer = SimpleImputer(strategy = 'most_frequent')\nhfi_copy['mode_hf_score'] = mode_imputer.fit_transform(hfi_copy[['hf_score']])\n\nmode_plot = sns.kdeplot(data = hfi_copy, x = 'hf_score', linewidth = 2, label = \"Original\")\nmode_plot = sns.kdeplot(data = hfi_copy, x = 'mode_hf_score', linewidth = 2, label = \"Mode Imputated\")\n\nplt.legend()\n\nplt.show()"
  },
  {
    "objectID": "slides/06-preprocessing.html#logical-operators",
    "href": "slides/06-preprocessing.html#logical-operators",
    "title": "Data preprocessing",
    "section": "Logical operators",
    "text": "Logical operators\n\n\n\noperator\ndefinition\n\n\n\n\n&lt;\nis less than?\n\n\n&lt;=\nis less than or equal to?\n\n\n&gt;\nis greater than?\n\n\n&gt;=\nis greater than or equal to?\n\n\n==\nis exactly equal to?\n\n\n!=\nis not equal to?"
  },
  {
    "objectID": "slides/06-preprocessing.html#logical-operators-cont.",
    "href": "slides/06-preprocessing.html#logical-operators-cont.",
    "title": "Data preprocessing",
    "section": "Logical operators cont.",
    "text": "Logical operators cont.\n\n\n\n\n\n\n\noperator\ndefinition\n\n\n\n\nx and y\nis x AND y?\n\n\nx or y\nis x OR y?\n\n\nx is None\nis x None?\n\n\nx is not None\nis x not None?\n\n\nx in y\nis x in y?\n\n\nx not in y\nis x not in y?\n\n\nnot x\nis not x? (only makes sense if x is True or False)"
  },
  {
    "objectID": "slides/06-preprocessing.html#looking-at-our-data",
    "href": "slides/06-preprocessing.html#looking-at-our-data",
    "title": "Data preprocessing",
    "section": "Looking at our data",
    "text": "Looking at our data\n\nhfi_copy = hfi\nhfi_copy.info(verbose=True)\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1458 entries, 0 to 1457\nData columns (total 126 columns):\n #    Column                              Dtype  \n---   ------                              -----  \n 0    year                                int64  \n 1    ISO_code                            object \n 2    countries                           object \n 3    region                              object \n 4    pf_rol_procedural                   float64\n 5    pf_rol_civil                        float64\n 6    pf_rol_criminal                     float64\n 7    pf_rol                              float64\n 8    pf_ss_homicide                      float64\n 9    pf_ss_disappearances_disap          float64\n 10   pf_ss_disappearances_violent        float64\n 11   pf_ss_disappearances_organized      float64\n 12   pf_ss_disappearances_fatalities     float64\n 13   pf_ss_disappearances_injuries       float64\n 14   pf_ss_disappearances                float64\n 15   pf_ss_women_fgm                     float64\n 16   pf_ss_women_missing                 float64\n 17   pf_ss_women_inheritance_widows      float64\n 18   pf_ss_women_inheritance_daughters   float64\n 19   pf_ss_women_inheritance             float64\n 20   pf_ss_women                         float64\n 21   pf_ss                               float64\n 22   pf_movement_domestic                float64\n 23   pf_movement_foreign                 float64\n 24   pf_movement_women                   float64\n 25   pf_movement                         float64\n 26   pf_religion_estop_establish         float64\n 27   pf_religion_estop_operate           float64\n 28   pf_religion_estop                   float64\n 29   pf_religion_harassment              float64\n 30   pf_religion_restrictions            float64\n 31   pf_religion                         float64\n 32   pf_association_association          float64\n 33   pf_association_assembly             float64\n 34   pf_association_political_establish  float64\n 35   pf_association_political_operate    float64\n 36   pf_association_political            float64\n 37   pf_association_prof_establish       float64\n 38   pf_association_prof_operate         float64\n 39   pf_association_prof                 float64\n 40   pf_association_sport_establish      float64\n 41   pf_association_sport_operate        float64\n 42   pf_association_sport                float64\n 43   pf_association                      float64\n 44   pf_expression_killed                float64\n 45   pf_expression_jailed                float64\n 46   pf_expression_influence             float64\n 47   pf_expression_control               float64\n 48   pf_expression_cable                 float64\n 49   pf_expression_newspapers            float64\n 50   pf_expression_internet              float64\n 51   pf_expression                       float64\n 52   pf_identity_legal                   float64\n 53   pf_identity_parental_marriage       float64\n 54   pf_identity_parental_divorce        float64\n 55   pf_identity_parental                float64\n 56   pf_identity_sex_male                float64\n 57   pf_identity_sex_female              float64\n 58   pf_identity_sex                     float64\n 59   pf_identity_divorce                 float64\n 60   pf_identity                         float64\n 61   pf_score                            float64\n 62   pf_rank                             float64\n 63   ef_government_consumption           float64\n 64   ef_government_transfers             float64\n 65   ef_government_enterprises           float64\n 66   ef_government_tax_income            float64\n 67   ef_government_tax_payroll           float64\n 68   ef_government_tax                   float64\n 69   ef_government                       float64\n 70   ef_legal_judicial                   float64\n 71   ef_legal_courts                     float64\n 72   ef_legal_protection                 float64\n 73   ef_legal_military                   float64\n 74   ef_legal_integrity                  float64\n 75   ef_legal_enforcement                float64\n 76   ef_legal_restrictions               float64\n 77   ef_legal_police                     float64\n 78   ef_legal_crime                      float64\n 79   ef_legal_gender                     float64\n 80   ef_legal                            float64\n 81   ef_money_growth                     float64\n 82   ef_money_sd                         float64\n 83   ef_money_inflation                  float64\n 84   ef_money_currency                   float64\n 85   ef_money                            float64\n 86   ef_trade_tariffs_revenue            float64\n 87   ef_trade_tariffs_mean               float64\n 88   ef_trade_tariffs_sd                 float64\n 89   ef_trade_tariffs                    float64\n 90   ef_trade_regulatory_nontariff       float64\n 91   ef_trade_regulatory_compliance      float64\n 92   ef_trade_regulatory                 float64\n 93   ef_trade_black                      float64\n 94   ef_trade_movement_foreign           float64\n 95   ef_trade_movement_capital           float64\n 96   ef_trade_movement_visit             float64\n 97   ef_trade_movement                   float64\n 98   ef_trade                            float64\n 99   ef_regulation_credit_ownership      float64\n 100  ef_regulation_credit_private        float64\n 101  ef_regulation_credit_interest       float64\n 102  ef_regulation_credit                float64\n 103  ef_regulation_labor_minwage         float64\n 104  ef_regulation_labor_firing          float64\n 105  ef_regulation_labor_bargain         float64\n 106  ef_regulation_labor_hours           float64\n 107  ef_regulation_labor_dismissal       float64\n 108  ef_regulation_labor_conscription    float64\n 109  ef_regulation_labor                 float64\n 110  ef_regulation_business_adm          float64\n 111  ef_regulation_business_bureaucracy  float64\n 112  ef_regulation_business_start        float64\n 113  ef_regulation_business_bribes       float64\n 114  ef_regulation_business_licensing    float64\n 115  ef_regulation_business_compliance   float64\n 116  ef_regulation_business              float64\n 117  ef_regulation                       float64\n 118  ef_score                            float64\n 119  ef_rank                             float64\n 120  hf_score                            float64\n 121  hf_rank                             float64\n 122  hf_quartile                         float64\n 123  mean_hf_score                       float64\n 124  median_hf_score                     float64\n 125  mode_hf_score                       float64\ndtypes: float64(122), int64(1), object(3)\nmemory usage: 1.4+ MB"
  },
  {
    "objectID": "slides/06-preprocessing.html#converting-year-to-datetime",
    "href": "slides/06-preprocessing.html#converting-year-to-datetime",
    "title": "Data preprocessing",
    "section": "Converting year to Datetime",
    "text": "Converting year to Datetime\n\nhfi_copy['year'] = pd.to_datetime(hfi_copy['year'], format='%Y')\nprint(hfi_copy.info(verbose=True))\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1458 entries, 0 to 1457\nData columns (total 126 columns):\n #    Column                              Dtype         \n---   ------                              -----         \n 0    year                                datetime64[ns]\n 1    ISO_code                            object        \n 2    countries                           object        \n 3    region                              object        \n 4    pf_rol_procedural                   float64       \n 5    pf_rol_civil                        float64       \n 6    pf_rol_criminal                     float64       \n 7    pf_rol                              float64       \n 8    pf_ss_homicide                      float64       \n 9    pf_ss_disappearances_disap          float64       \n 10   pf_ss_disappearances_violent        float64       \n 11   pf_ss_disappearances_organized      float64       \n 12   pf_ss_disappearances_fatalities     float64       \n 13   pf_ss_disappearances_injuries       float64       \n 14   pf_ss_disappearances                float64       \n 15   pf_ss_women_fgm                     float64       \n 16   pf_ss_women_missing                 float64       \n 17   pf_ss_women_inheritance_widows      float64       \n 18   pf_ss_women_inheritance_daughters   float64       \n 19   pf_ss_women_inheritance             float64       \n 20   pf_ss_women                         float64       \n 21   pf_ss                               float64       \n 22   pf_movement_domestic                float64       \n 23   pf_movement_foreign                 float64       \n 24   pf_movement_women                   float64       \n 25   pf_movement                         float64       \n 26   pf_religion_estop_establish         float64       \n 27   pf_religion_estop_operate           float64       \n 28   pf_religion_estop                   float64       \n 29   pf_religion_harassment              float64       \n 30   pf_religion_restrictions            float64       \n 31   pf_religion                         float64       \n 32   pf_association_association          float64       \n 33   pf_association_assembly             float64       \n 34   pf_association_political_establish  float64       \n 35   pf_association_political_operate    float64       \n 36   pf_association_political            float64       \n 37   pf_association_prof_establish       float64       \n 38   pf_association_prof_operate         float64       \n 39   pf_association_prof                 float64       \n 40   pf_association_sport_establish      float64       \n 41   pf_association_sport_operate        float64       \n 42   pf_association_sport                float64       \n 43   pf_association                      float64       \n 44   pf_expression_killed                float64       \n 45   pf_expression_jailed                float64       \n 46   pf_expression_influence             float64       \n 47   pf_expression_control               float64       \n 48   pf_expression_cable                 float64       \n 49   pf_expression_newspapers            float64       \n 50   pf_expression_internet              float64       \n 51   pf_expression                       float64       \n 52   pf_identity_legal                   float64       \n 53   pf_identity_parental_marriage       float64       \n 54   pf_identity_parental_divorce        float64       \n 55   pf_identity_parental                float64       \n 56   pf_identity_sex_male                float64       \n 57   pf_identity_sex_female              float64       \n 58   pf_identity_sex                     float64       \n 59   pf_identity_divorce                 float64       \n 60   pf_identity                         float64       \n 61   pf_score                            float64       \n 62   pf_rank                             float64       \n 63   ef_government_consumption           float64       \n 64   ef_government_transfers             float64       \n 65   ef_government_enterprises           float64       \n 66   ef_government_tax_income            float64       \n 67   ef_government_tax_payroll           float64       \n 68   ef_government_tax                   float64       \n 69   ef_government                       float64       \n 70   ef_legal_judicial                   float64       \n 71   ef_legal_courts                     float64       \n 72   ef_legal_protection                 float64       \n 73   ef_legal_military                   float64       \n 74   ef_legal_integrity                  float64       \n 75   ef_legal_enforcement                float64       \n 76   ef_legal_restrictions               float64       \n 77   ef_legal_police                     float64       \n 78   ef_legal_crime                      float64       \n 79   ef_legal_gender                     float64       \n 80   ef_legal                            float64       \n 81   ef_money_growth                     float64       \n 82   ef_money_sd                         float64       \n 83   ef_money_inflation                  float64       \n 84   ef_money_currency                   float64       \n 85   ef_money                            float64       \n 86   ef_trade_tariffs_revenue            float64       \n 87   ef_trade_tariffs_mean               float64       \n 88   ef_trade_tariffs_sd                 float64       \n 89   ef_trade_tariffs                    float64       \n 90   ef_trade_regulatory_nontariff       float64       \n 91   ef_trade_regulatory_compliance      float64       \n 92   ef_trade_regulatory                 float64       \n 93   ef_trade_black                      float64       \n 94   ef_trade_movement_foreign           float64       \n 95   ef_trade_movement_capital           float64       \n 96   ef_trade_movement_visit             float64       \n 97   ef_trade_movement                   float64       \n 98   ef_trade                            float64       \n 99   ef_regulation_credit_ownership      float64       \n 100  ef_regulation_credit_private        float64       \n 101  ef_regulation_credit_interest       float64       \n 102  ef_regulation_credit                float64       \n 103  ef_regulation_labor_minwage         float64       \n 104  ef_regulation_labor_firing          float64       \n 105  ef_regulation_labor_bargain         float64       \n 106  ef_regulation_labor_hours           float64       \n 107  ef_regulation_labor_dismissal       float64       \n 108  ef_regulation_labor_conscription    float64       \n 109  ef_regulation_labor                 float64       \n 110  ef_regulation_business_adm          float64       \n 111  ef_regulation_business_bureaucracy  float64       \n 112  ef_regulation_business_start        float64       \n 113  ef_regulation_business_bribes       float64       \n 114  ef_regulation_business_licensing    float64       \n 115  ef_regulation_business_compliance   float64       \n 116  ef_regulation_business              float64       \n 117  ef_regulation                       float64       \n 118  ef_score                            float64       \n 119  ef_rank                             float64       \n 120  hf_score                            float64       \n 121  hf_rank                             float64       \n 122  hf_quartile                         float64       \n 123  mean_hf_score                       float64       \n 124  median_hf_score                     float64       \n 125  mode_hf_score                       float64       \ndtypes: datetime64[ns](1), float64(122), object(3)\nmemory usage: 1.4+ MB\nNone"
  },
  {
    "objectID": "slides/06-preprocessing.html#converting-iso_code-countries-and-region-to-categorical",
    "href": "slides/06-preprocessing.html#converting-iso_code-countries-and-region-to-categorical",
    "title": "Data preprocessing",
    "section": "Converting ISO_code, countries, and region to Categorical",
    "text": "Converting ISO_code, countries, and region to Categorical\n\nhfi_copy['ISO_code'] = hfi_copy['ISO_code'].astype('category')\nhfi_copy['countries'] = hfi_copy['countries'].astype('category')\nhfi_copy['region'] = hfi_copy['region'].astype('category')\nprint(hfi_copy.info(verbose=True))\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1458 entries, 0 to 1457\nData columns (total 126 columns):\n #    Column                              Dtype         \n---   ------                              -----         \n 0    year                                datetime64[ns]\n 1    ISO_code                            category      \n 2    countries                           category      \n 3    region                              category      \n 4    pf_rol_procedural                   float64       \n 5    pf_rol_civil                        float64       \n 6    pf_rol_criminal                     float64       \n 7    pf_rol                              float64       \n 8    pf_ss_homicide                      float64       \n 9    pf_ss_disappearances_disap          float64       \n 10   pf_ss_disappearances_violent        float64       \n 11   pf_ss_disappearances_organized      float64       \n 12   pf_ss_disappearances_fatalities     float64       \n 13   pf_ss_disappearances_injuries       float64       \n 14   pf_ss_disappearances                float64       \n 15   pf_ss_women_fgm                     float64       \n 16   pf_ss_women_missing                 float64       \n 17   pf_ss_women_inheritance_widows      float64       \n 18   pf_ss_women_inheritance_daughters   float64       \n 19   pf_ss_women_inheritance             float64       \n 20   pf_ss_women                         float64       \n 21   pf_ss                               float64       \n 22   pf_movement_domestic                float64       \n 23   pf_movement_foreign                 float64       \n 24   pf_movement_women                   float64       \n 25   pf_movement                         float64       \n 26   pf_religion_estop_establish         float64       \n 27   pf_religion_estop_operate           float64       \n 28   pf_religion_estop                   float64       \n 29   pf_religion_harassment              float64       \n 30   pf_religion_restrictions            float64       \n 31   pf_religion                         float64       \n 32   pf_association_association          float64       \n 33   pf_association_assembly             float64       \n 34   pf_association_political_establish  float64       \n 35   pf_association_political_operate    float64       \n 36   pf_association_political            float64       \n 37   pf_association_prof_establish       float64       \n 38   pf_association_prof_operate         float64       \n 39   pf_association_prof                 float64       \n 40   pf_association_sport_establish      float64       \n 41   pf_association_sport_operate        float64       \n 42   pf_association_sport                float64       \n 43   pf_association                      float64       \n 44   pf_expression_killed                float64       \n 45   pf_expression_jailed                float64       \n 46   pf_expression_influence             float64       \n 47   pf_expression_control               float64       \n 48   pf_expression_cable                 float64       \n 49   pf_expression_newspapers            float64       \n 50   pf_expression_internet              float64       \n 51   pf_expression                       float64       \n 52   pf_identity_legal                   float64       \n 53   pf_identity_parental_marriage       float64       \n 54   pf_identity_parental_divorce        float64       \n 55   pf_identity_parental                float64       \n 56   pf_identity_sex_male                float64       \n 57   pf_identity_sex_female              float64       \n 58   pf_identity_sex                     float64       \n 59   pf_identity_divorce                 float64       \n 60   pf_identity                         float64       \n 61   pf_score                            float64       \n 62   pf_rank                             float64       \n 63   ef_government_consumption           float64       \n 64   ef_government_transfers             float64       \n 65   ef_government_enterprises           float64       \n 66   ef_government_tax_income            float64       \n 67   ef_government_tax_payroll           float64       \n 68   ef_government_tax                   float64       \n 69   ef_government                       float64       \n 70   ef_legal_judicial                   float64       \n 71   ef_legal_courts                     float64       \n 72   ef_legal_protection                 float64       \n 73   ef_legal_military                   float64       \n 74   ef_legal_integrity                  float64       \n 75   ef_legal_enforcement                float64       \n 76   ef_legal_restrictions               float64       \n 77   ef_legal_police                     float64       \n 78   ef_legal_crime                      float64       \n 79   ef_legal_gender                     float64       \n 80   ef_legal                            float64       \n 81   ef_money_growth                     float64       \n 82   ef_money_sd                         float64       \n 83   ef_money_inflation                  float64       \n 84   ef_money_currency                   float64       \n 85   ef_money                            float64       \n 86   ef_trade_tariffs_revenue            float64       \n 87   ef_trade_tariffs_mean               float64       \n 88   ef_trade_tariffs_sd                 float64       \n 89   ef_trade_tariffs                    float64       \n 90   ef_trade_regulatory_nontariff       float64       \n 91   ef_trade_regulatory_compliance      float64       \n 92   ef_trade_regulatory                 float64       \n 93   ef_trade_black                      float64       \n 94   ef_trade_movement_foreign           float64       \n 95   ef_trade_movement_capital           float64       \n 96   ef_trade_movement_visit             float64       \n 97   ef_trade_movement                   float64       \n 98   ef_trade                            float64       \n 99   ef_regulation_credit_ownership      float64       \n 100  ef_regulation_credit_private        float64       \n 101  ef_regulation_credit_interest       float64       \n 102  ef_regulation_credit                float64       \n 103  ef_regulation_labor_minwage         float64       \n 104  ef_regulation_labor_firing          float64       \n 105  ef_regulation_labor_bargain         float64       \n 106  ef_regulation_labor_hours           float64       \n 107  ef_regulation_labor_dismissal       float64       \n 108  ef_regulation_labor_conscription    float64       \n 109  ef_regulation_labor                 float64       \n 110  ef_regulation_business_adm          float64       \n 111  ef_regulation_business_bureaucracy  float64       \n 112  ef_regulation_business_start        float64       \n 113  ef_regulation_business_bribes       float64       \n 114  ef_regulation_business_licensing    float64       \n 115  ef_regulation_business_compliance   float64       \n 116  ef_regulation_business              float64       \n 117  ef_regulation                       float64       \n 118  ef_score                            float64       \n 119  ef_rank                             float64       \n 120  hf_score                            float64       \n 121  hf_rank                             float64       \n 122  hf_quartile                         float64       \n 123  mean_hf_score                       float64       \n 124  median_hf_score                     float64       \n 125  mode_hf_score                       float64       \ndtypes: category(3), datetime64[ns](1), float64(122)\nmemory usage: 1.4 MB\nNone"
  },
  {
    "objectID": "slides/06-preprocessing.html#creating-a-boolean-column-from-hf_score",
    "href": "slides/06-preprocessing.html#creating-a-boolean-column-from-hf_score",
    "title": "Data preprocessing",
    "section": "Creating a boolean column from hf_score",
    "text": "Creating a boolean column from hf_score\nLet’s say we want to know whether countries are “free” or not.\n\nthreshold = 8.5\nhfi_copy['hf_score_above_threshold'] = hfi_copy['hf_score'] &gt; threshold"
  },
  {
    "objectID": "slides/06-preprocessing.html#filter-out-true-values",
    "href": "slides/06-preprocessing.html#filter-out-true-values",
    "title": "Data preprocessing",
    "section": "Filter out True values",
    "text": "Filter out True values\n\nfiltered_hfi_copy = hfi_copy[hfi_copy['hf_score_above_threshold'] == True][['hf_score_above_threshold', 'countries']]\n\nprint(filtered_hfi_copy[['hf_score_above_threshold', 'countries']])\n\n      hf_score_above_threshold       countries\n5                         True       Australia\n27                        True          Canada\n41                        True         Denmark\n63                        True       Hong Kong\n70                        True         Ireland\n...                        ...             ...\n1359                      True       Hong Kong\n1403                      True     New Zealand\n1407                      True          Norway\n1436                      True     Switzerland\n1450                      True  United Kingdom\n\n[83 rows x 2 columns]\n\n\n\n\nThat’s a lot of data… 🤔"
  },
  {
    "objectID": "slides/06-preprocessing.html#filter-out-true-values-for-newest-year",
    "href": "slides/06-preprocessing.html#filter-out-true-values-for-newest-year",
    "title": "Data preprocessing",
    "section": "Filter out True values for newest year",
    "text": "Filter out True values for newest year\n\nnewest_year = hfi_copy['year'].max()\nfiltered_hfi_copy = hfi_copy[(hfi_copy['year'] == newest_year) & (hfi_copy['hf_score_above_threshold'] == True)]\n\nresult = filtered_hfi_copy[['hf_score_above_threshold', 'countries']]\n\nprint(result)\n\n     hf_score_above_threshold    countries\n5                        True    Australia\n27                       True       Canada\n41                       True      Denmark\n63                       True    Hong Kong\n70                       True      Ireland\n106                      True  Netherlands\n107                      True  New Zealand\n140                      True  Switzerland"
  },
  {
    "objectID": "slides/06-preprocessing.html#filtering-categories",
    "href": "slides/06-preprocessing.html#filtering-categories",
    "title": "Data preprocessing",
    "section": "Filtering categories",
    "text": "Filtering categories\n\noptions = ['United States', 'India', 'Canada', 'China']\nfiltered_hfi = hfi[hfi['countries'].isin(options)]\nfiltered_hfi['countries'] = filtered_hfi['countries'].cat.remove_unused_categories()\nunique_countries = filtered_hfi['countries'].unique()\nprint(unique_countries)\n\n['Canada', 'China', 'India', 'United States']\nCategories (4, object): ['Canada', 'China', 'India', 'United States']"
  },
  {
    "objectID": "slides/06-preprocessing.html#normalizing",
    "href": "slides/06-preprocessing.html#normalizing",
    "title": "Data preprocessing",
    "section": "Normalizing",
    "text": "Normalizing\n\nStandard deviationZ-scoreMin-maxMaximum absolute\n\n\n\n\nMean: 5\nStandard Deviation: 2\n\n\n\n\n\n\n\n\n\n\n\n\nhfi_copy = hfi.copy()\n\nscaler = StandardScaler()\nhfi_copy[['ef_score_scale', 'pf_score_scale']] = scaler.fit_transform(hfi_copy[['ef_score', 'pf_score']])\n\nhfi_copy[['ef_score_scale', 'pf_score_scale']].describe()\n\n\n\n\n\n\n\n\nef_score_scale\npf_score_scale\n\n\n\n\ncount\n1.378000e+03\n1.378000e+03\n\n\nmean\n4.524683e-16\n2.062533e-17\n\n\nstd\n1.000363e+00\n1.000363e+00\n\n\nmin\n-4.421711e+00\n-3.663087e+00\n\n\n25%\n-6.063870e-01\n-7.303950e-01\n\n\n50%\n1.295064e-01\n-8.926277e-03\n\n\n75%\n7.068997e-01\n9.081441e-01\n\n\nmax\n2.722116e+00\n1.722056e+00\n\n\n\n\n\n\n\n\n\n\nmin_max_scaler = MinMaxScaler()\nhfi_copy[['ef_score_minmax', 'pf_score_minmax']] = min_max_scaler.fit_transform(hfi_copy[['ef_score', 'pf_score']])\n\nhfi_copy[['ef_score_minmax', 'pf_score_minmax']].describe()\n\n\n\n\n\n\n\n\nef_score_minmax\npf_score_minmax\n\n\n\n\ncount\n1378.000000\n1378.000000\n\n\nmean\n0.618956\n0.680221\n\n\nstd\n0.140032\n0.185764\n\n\nmin\n0.000000\n0.000000\n\n\n25%\n0.534073\n0.544589\n\n\n50%\n0.637084\n0.678563\n\n\n75%\n0.717908\n0.848860\n\n\nmax\n1.000000\n1.000000\n\n\n\n\n\n\n\n\n\n\nmax_abs_scaler = MaxAbsScaler()\nhfi_copy[['ef_score_maxabs', 'pf_score_maxabs']] = max_abs_scaler.fit_transform(hfi_copy[['ef_score', 'pf_score']])\n\nhfi_copy[['ef_score_maxabs', 'pf_score_maxabs']].describe()\n\n\n\n\n\n\n\n\nef_score_maxabs\npf_score_maxabs\n\n\n\n\ncount\n1378.000000\n1378.000000\n\n\nmean\n0.738369\n0.752630\n\n\nstd\n0.096148\n0.143700\n\n\nmin\n0.313384\n0.226434\n\n\n25%\n0.680087\n0.647710\n\n\n50%\n0.750816\n0.751348\n\n\n75%\n0.806311\n0.883083\n\n\nmax\n1.000000\n1.000000"
  },
  {
    "objectID": "slides/06-preprocessing.html#visual-comparison",
    "href": "slides/06-preprocessing.html#visual-comparison",
    "title": "Data preprocessing",
    "section": "Visual comparison",
    "text": "Visual comparison"
  },
  {
    "objectID": "slides/06-preprocessing.html#pros-cons-standardscaler",
    "href": "slides/06-preprocessing.html#pros-cons-standardscaler",
    "title": "Data preprocessing",
    "section": "Pros + cons (StandardScaler)",
    "text": "Pros + cons (StandardScaler)\nPros:\n\n\nNormalization of Variance: Centers data around zero with a standard deviation of one, suitable for algorithms assuming normally distributed data (e.g., linear regression, logistic regression, neural networks).\nPreserves Relationships: Maintains ratios and differences between data points.\n\n\nCons:\n\n\nSensitive to Outliers: Outliers can distort scaled values.\nAssumes Normality: Assumes data follows a Gaussian distribution."
  },
  {
    "objectID": "slides/06-preprocessing.html#pros-cons-maxabsscaler",
    "href": "slides/06-preprocessing.html#pros-cons-maxabsscaler",
    "title": "Data preprocessing",
    "section": "Pros + cons (MaxAbsScaler)",
    "text": "Pros + cons (MaxAbsScaler)\nPros:\n\n\nOutlier Resistant: Less sensitive to outliers, scales based on the absolute maximum value.\nPreserves Sparsity: Does not center data, preserving the sparsity pattern.\n\n\nCons:\n\n\nScale Limitation: Scales to the range [-1, 1], which may not suit all algorithms.\nNot Zero-Centered: May be a limitation for algorithms preferring zero-centered data."
  },
  {
    "objectID": "slides/06-preprocessing.html#pros-cons-minmaxscaler",
    "href": "slides/06-preprocessing.html#pros-cons-minmaxscaler",
    "title": "Data preprocessing",
    "section": "Pros + cons (MinMaxScaler)",
    "text": "Pros + cons (MinMaxScaler)\nPros:\n\n\nFixed Range: Scales data to a fixed range (usually [0, 1]), beneficial for algorithms sensitive to feature scales (e.g., neural networks, k-nearest neighbors).\nPreserves Relationships: Maintains relationships between data points.\n\n\nCons:\n\n\nSensitive to Outliers: Outliers can skew scaled values.\nRange Dependence: Scaling depends on the min and max values in the training data, which may not generalize well to new data."
  },
  {
    "objectID": "slides/06-preprocessing.html#normality-test-q-q-plot",
    "href": "slides/06-preprocessing.html#normality-test-q-q-plot",
    "title": "Data preprocessing",
    "section": "Normality test: Q-Q plot",
    "text": "Normality test: Q-Q plot\n\nQ-Q PlotIssues\n\n\n\n\nCode\nhfi_clean = hfi_copy.dropna(subset = ['pf_score'])\n\nsns.set_style(\"white\")\n\nfig, (ax1, ax2) = plt.subplots(ncols = 2, nrows = 1)\n\nsns.kdeplot(data = hfi_clean, x = \"hf_score\", linewidth = 5, ax = ax1)\nax1.set_title('Human Freedom Score')\n\nsm.qqplot(hfi_clean['hf_score'], line = 's', ax = ax2, dist = stats.norm, fit = True)\nax2.set_title('Human Freedom Score Q-Q plot')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThere were some issues in our plots:\n\n\nLeft Tail: Points deviate downwards from the line, indicating more extreme low values than a normal distribution (negative skewness).\nCentral Section: Points align closely with the line, suggesting the central data is similar to a normal distribution.\nRight Tail: Points curve upwards, showing potential for extreme high values (positive skewness)."
  },
  {
    "objectID": "slides/06-preprocessing.html#correcting-skew",
    "href": "slides/06-preprocessing.html#correcting-skew",
    "title": "Data preprocessing",
    "section": "Correcting skew",
    "text": "Correcting skew\n\nSquare-root transformation. \\(\\sqrt x\\) Used for moderately right-skew (positive skew)\n\n\nCannot handle negative values (but can handle zeros)\n\n\n\n\nLog transformation. \\(log(x + 1)\\) Used for substantial right-skew (positive skew)\n\n\nCannot handle negative or zero values\n\n\n\n\nSquared transformation. \\(x^2\\) Used for moderately left-skew (negative skew)\n\n\nEffective when lower values are densely packed together"
  },
  {
    "objectID": "slides/06-preprocessing.html#comparing-transformations",
    "href": "slides/06-preprocessing.html#comparing-transformations",
    "title": "Data preprocessing",
    "section": "Comparing transformations",
    "text": "Comparing transformations\n\nOriginalSquare-rootLogSquared\n\n\n\n\n\n\n\n\n\n\n\n\nModerate negative skew, no zeros or negative values\n\n\n\n\n\nCode\nhfi_clean['hf_score_sqrt'] = np.sqrt(hfi_clean['hf_score'])\n\ncol = hfi_clean['hf_score_sqrt']\n\nfig, (ax1, ax2) = plt.subplots(ncols = 2, nrows = 1)\n\nsns.kdeplot(col, linewidth = 5, ax = ax1)\nax1.set_title('Square-root Density plot')    \n\nsm.qqplot(col, line = 's', ax = ax2)\nax2.set_title('Square-root Q-Q plot')    \nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nhfi_clean['hf_score_log'] = np.log(hfi_clean['hf_score'] + 1)\n\ncol = hfi_clean['hf_score_log']\n\nfig, (ax1, ax2) = plt.subplots(ncols = 2, nrows = 1)\n\nsns.kdeplot(col, linewidth = 5, ax = ax1)\nax1.set_title('Log Density plot')    \n\nsm.qqplot(col, line = 's', ax = ax2)\nax2.set_title('Log Q-Q plot')    \nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nhfi_clean['hf_score_square'] = pow(hfi_clean.hf_score, 2)\n\ncol = hfi_clean['hf_score_square']\n\nfig, (ax1, ax2) = plt.subplots(ncols = 2, nrows = 1)\n\nsns.kdeplot(col, linewidth = 5, ax = ax1)\nax1.set_title('Squared Density plot')    \n\nsm.qqplot(col, line = 's', ax = ax2)\nax2.set_title('Squared Q-Q plot')    \nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "slides/06-preprocessing.html#what-did-we-learn",
    "href": "slides/06-preprocessing.html#what-did-we-learn",
    "title": "Data preprocessing",
    "section": "What did we learn?",
    "text": "What did we learn?\n\n\nNegative skew excluded all but Squared transformation\n… thus, Squared transformation was the best\nThe data is bimodal, so no transformation is perfect"
  },
  {
    "objectID": "slides/06-preprocessing.html#answering-our-question",
    "href": "slides/06-preprocessing.html#answering-our-question",
    "title": "Data preprocessing",
    "section": "Answering our question",
    "text": "Answering our question\nWhat trends are there within human freedom indices in different regions?\n\n\n\n\n\n\n\n\n\n\nProbably…\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/23-linear-algebra-II.html#eigenvalues-and-eigenvectors",
    "href": "slides/23-linear-algebra-II.html#eigenvalues-and-eigenvectors",
    "title": "Linear algebra II",
    "section": "Eigenvalues and Eigenvectors",
    "text": "Eigenvalues and Eigenvectors\n\n\n\nEigenvalues and eigenvectors decompose a matrix into its fundamental components.\nEigenvalue equation: \\(\\mathbf{A} \\mathbf{v} = \\lambda \\mathbf{v}\\)"
  },
  {
    "objectID": "slides/23-linear-algebra-II.html#calculating-eigenvalues-and-eigenvectors",
    "href": "slides/23-linear-algebra-II.html#calculating-eigenvalues-and-eigenvectors",
    "title": "Linear algebra II",
    "section": "Calculating Eigenvalues and Eigenvectors",
    "text": "Calculating Eigenvalues and Eigenvectors\n\nWe will be using Python for this…\n\n\n\nimport numpy as np\nfrom numpy.linalg import eig\nA = np.array([[1, 2], [4, 5]])\neigenvals, eigenvecs = eig(A)\nprint(\"EIGENVALUES:\", eigenvals)\nprint(\"EIGENVECTORS:\", eigenvecs)\n\nEIGENVALUES: [-0.46410162  6.46410162]\nEIGENVECTORS: [[-0.80689822 -0.34372377]\n [ 0.59069049 -0.9390708 ]]"
  },
  {
    "objectID": "slides/23-linear-algebra-II.html#eigen-decomposition",
    "href": "slides/23-linear-algebra-II.html#eigen-decomposition",
    "title": "Linear algebra II",
    "section": "Eigen decomposition",
    "text": "Eigen decomposition\n\nDecomposition formula: \\(\\mathbf{A} = \\mathbf{Q} \\mathbf{L} \\mathbf{Q}^{-1}\\)\n\\(\\mathbf{Q}\\) is the matrix of eigenvectors, \\(\\mathbf{L}\\) is the diagonal matrix of eigenvalues, and \\(\\mathbf{Q}^{-1}\\) is the inverse of \\(\\mathbf{Q}\\)"
  },
  {
    "objectID": "slides/23-linear-algebra-II.html#recomposing-matrices",
    "href": "slides/23-linear-algebra-II.html#recomposing-matrices",
    "title": "Linear algebra II",
    "section": "Recomposing matrices",
    "text": "Recomposing matrices\n\nfrom numpy import diag\nfrom numpy.linalg import inv\nQ = eigenvecs\nL = diag(eigenvals)\nR = inv(Q)\nB = Q @ L @ R\nprint(B)\n\n[[1. 2.]\n [4. 5.]]"
  },
  {
    "objectID": "slides/23-linear-algebra-II.html#applications-in-data-science-and-machine-learning",
    "href": "slides/23-linear-algebra-II.html#applications-in-data-science-and-machine-learning",
    "title": "Linear algebra II",
    "section": "Applications in Data Science and Machine Learning",
    "text": "Applications in Data Science and Machine Learning\n\nPrincipal Component Analysis (PCA): Reduces dimensionality while preserving variance.\nEigenvalues in system stability: Determine stability in control systems and differential equations."
  },
  {
    "objectID": "slides/23-linear-algebra-II.html#special-types-of-matrices",
    "href": "slides/23-linear-algebra-II.html#special-types-of-matrices",
    "title": "Linear algebra II",
    "section": "Special Types of Matrices",
    "text": "Special Types of Matrices\n\n\n\nIdentity Matrix: Diagonal of 1s, other elements are 0s.\n\\[\n\\mathbf{I} = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\]\n\n\n\nDiagonal Matrix: Non-zero elements only on the diagonal.\n\\[\n\\mathbf{D} = \\begin{bmatrix}\n4 & 0 & 0 \\\\\n0 & 5 & 0 \\\\\n0 & 0 & 6\n\\end{bmatrix}\n\\]\n\n\n\nTriangular Matrix: Triangular shape of non-zero elements (upper \\(\\mathbf{U}\\), lower \\(\\mathbf{L}\\)).\n\\[\n\\mathbf{U} = \\begin{bmatrix}1 & 2 & 3 \\\\0 & 4 & 5 \\\\0 & 0 & 6\\end{bmatrix} \\\\ \\mathbf{L} = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n2 & 3 & 0 \\\\\n4 & 5 & 6\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/23-linear-algebra-II.html#ae-16-pca",
    "href": "slides/23-linear-algebra-II.html#ae-16-pca",
    "title": "Linear algebra II",
    "section": "ae-16-pca",
    "text": "ae-16-pca\nPrincipal Component Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/08-web-scraping.html#setup",
    "href": "slides/08-web-scraping.html#setup",
    "title": "Web scraping",
    "section": "Setup",
    "text": "Setup\n\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom afinn import Afinn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport numpy as np\nimport ssl\ntry:\n    _create_unverified_https_context = ssl._create_unverified_context\nexcept AttributeError:\n    pass\nelse:\n    ssl._create_default_https_context = _create_unverified_https_context\n\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('punkt_tab')\n\nsns.set_style(\"whitegrid\")"
  },
  {
    "objectID": "slides/08-web-scraping.html#before-continuing",
    "href": "slides/08-web-scraping.html#before-continuing",
    "title": "Web scraping",
    "section": "Before continuing…",
    "text": "Before continuing…\n\n\nIf you haven’t yet done so: Install a Chrome browser and the SelectorGadget extension:\n\nChrome\nSelectorGadget\n\nGo to your ae repo, commit any remaining changes, push, and then pull for today’s application exercise."
  },
  {
    "objectID": "slides/08-web-scraping.html#reading-the-arizona-daily-wildcat",
    "href": "slides/08-web-scraping.html#reading-the-arizona-daily-wildcat",
    "title": "Web scraping",
    "section": "Reading The Arizona Daily Wildcat",
    "text": "Reading The Arizona Daily Wildcat\n\nHow often do you read The Arizona Daily Wildcat?\n\nEvery day\n3-5 times a week\nOnce a week\nRarely"
  },
  {
    "objectID": "slides/08-web-scraping.html#reading-the-arizona-daily-wildcat-1",
    "href": "slides/08-web-scraping.html#reading-the-arizona-daily-wildcat-1",
    "title": "Web scraping",
    "section": "Reading The Arizona Daily Wildcat",
    "text": "Reading The Arizona Daily Wildcat\n\nWhat do you think is the most common word in the titles of The Arizona Daily Wildcat opinion pieces?"
  },
  {
    "objectID": "slides/08-web-scraping.html#analyzing-the-arizona-daily-wildcat",
    "href": "slides/08-web-scraping.html#analyzing-the-arizona-daily-wildcat",
    "title": "Web scraping",
    "section": "Analyzing The Arizona Daily Wildcat",
    "text": "Analyzing The Arizona Daily Wildcat"
  },
  {
    "objectID": "slides/08-web-scraping.html#analyzing-the-arizona-daily-wildcat-1",
    "href": "slides/08-web-scraping.html#analyzing-the-arizona-daily-wildcat-1",
    "title": "Web scraping",
    "section": "Analyzing The Arizona Daily Wildcat",
    "text": "Analyzing The Arizona Daily Wildcat"
  },
  {
    "objectID": "slides/08-web-scraping.html#all-of-this-analysis-is-done-in-python",
    "href": "slides/08-web-scraping.html#all-of-this-analysis-is-done-in-python",
    "title": "Web scraping",
    "section": "All of this analysis is done in Python!",
    "text": "All of this analysis is done in Python!\n\n(mostly) with tools you already know!"
  },
  {
    "objectID": "slides/08-web-scraping.html#common-works-in-the-arizona-daily-wildcat-titles",
    "href": "slides/08-web-scraping.html#common-works-in-the-arizona-daily-wildcat-titles",
    "title": "Web scraping",
    "section": "Common works in The Arizona Daily Wildcat titles",
    "text": "Common works in The Arizona Daily Wildcat titles\nCode for the earlier plot:\n\nstop_words = set(stopwords.words('english'))\nwildcat['tokens'] = wildcat['title'].apply(lambda x: [word.lower() for word in word_tokenize(x) if word.isalpha() and word.lower() not in stop_words])\n\nword_counts = Counter(word for title in wildcat['tokens'] for word in title)\ncommon_words = pd.DataFrame(word_counts.most_common(20), columns=['word', 'count'])\n\nplt.figure(figsize=(10, 5))\nsns.barplot(x='count', y='word', data=common_words, palette='viridis')\nplt.xlabel('Number of mentions')\nplt.ylabel('Word')\nplt.title('Arizona Daily Wildcat - Opinion pieces\\nCommon words in the most recent opinion pieces')\nplt.show()"
  },
  {
    "objectID": "slides/08-web-scraping.html#avg-sentiment-scores-of-titles",
    "href": "slides/08-web-scraping.html#avg-sentiment-scores-of-titles",
    "title": "Web scraping",
    "section": "Avg sentiment scores of titles",
    "text": "Avg sentiment scores of titles\nCode for the earlier plot:\n\nstop_words = set(stopwords.words('english'))\nwildcat['tokens'] = wildcat['title'].apply(lambda x: [word.lower() for word in word_tokenize(x) if word.isalpha() and word.lower() not in stop_words])\n\nafinn = Afinn()\n\nwildcat['sentiment'] = wildcat['title'].apply(lambda x: afinn.score(x))\nauthor_sentiment = wildcat.groupby(['author', 'title'])['sentiment'].sum().reset_index()\n\nauthor_summary = author_sentiment.groupby('author').agg(n_articles=('title', 'count'), avg_sentiment=('sentiment', 'mean')).reset_index()\nauthor_summary = author_summary[(author_summary['n_articles'] &gt; 1) & (author_summary['author'].notna())]\n\ntop_positive = author_summary.nlargest(10, 'avg_sentiment')\ntop_negative = author_summary.nsmallest(10, 'avg_sentiment')\ntop_authors = pd.concat([top_positive, top_negative])\n\ntop_authors['neg_pos'] = np.where(top_authors['avg_sentiment'] &lt; 0, 'neg', 'pos')\ntop_authors['label_position'] = np.where(top_authors['neg_pos'] == 'neg', 0.25, -0.25)\ntop_authors = top_authors.sort_values(by='avg_sentiment', ascending=True)\n\nplt.figure(figsize=(8, 6))\nsns.barplot(x='avg_sentiment', y='author', data=top_authors, hue='neg_pos', dodge=False, palette={'neg': '#4d4009', 'pos': '#FF4B91'})\nplt.xlabel('negative  ←     Average sentiment score (AFINN)     →  positive')\nplt.ylabel(None)\nplt.title('The Arizona Daily Wildcat - Opinion pieces\\nAverage sentiment scores of titles by author')\nplt.legend([], [], frameon=False)\nplt.xlim(-5, 5)\nplt.grid(False)\nplt.gca().invert_yaxis()\nplt.show()"
  },
  {
    "objectID": "slides/08-web-scraping.html#where-is-this-data-coming-from",
    "href": "slides/08-web-scraping.html#where-is-this-data-coming-from",
    "title": "Web scraping",
    "section": "Where is this data coming from?",
    "text": "Where is this data coming from?\nhttps://wildcat.arizona.edu/category/opinions/"
  },
  {
    "objectID": "slides/08-web-scraping.html#where-is-this-data-coming-from-1",
    "href": "slides/08-web-scraping.html#where-is-this-data-coming-from-1",
    "title": "Web scraping",
    "section": "Where is this data coming from?",
    "text": "Where is this data coming from?\n\n\n\n\n\n\n\n\n\nprint(wildcat)\n\n                                                 title            author  \\\n0    BOOK REVIEW: ‘Fresh Fruit, Broken Bodies’ by D...    Andres F. Diaz   \n1    OPINION: The first presidential debate lacked ...       Luke Lawson   \n2    OPINION: College WBB favorites and sleeper pic...  Melisa Guzeloglu   \n3    OPINION: College MBB favorites and sleeper pic...   Nathaniel Levin   \n4    EDITORIAL: A desk altered but opinions thrive ...   Editor-in-Chief   \n..                                                 ...               ...   \n995                      Here’s how to best help Nepal    Hailey Dickson   \n996                        Adderall abuse not harmless    Maddie Pickens   \n997                     Court rule is legitimate judge   Jacob Winkelman   \n998                 Letters to the editor: May 4, 2015  Gabriel Schivone   \n999            Capability imperfectly captured by TCEs    Maddie Pickens   \n\n               date  abstract   column  \\\n0     July 22, 2024       NaN  Opinion   \n1      July 3, 2024       NaN  Opinion   \n2    March 15, 2024       NaN  Opinion   \n3    March 15, 2024       NaN  Opinion   \n4    March 15, 2024       NaN  Opinion   \n..              ...       ...      ...   \n995     May 5, 2015       NaN  Opinion   \n996     May 5, 2015       NaN  Opinion   \n997     May 4, 2015       NaN  Opinion   \n998     May 4, 2015       NaN  Opinion   \n999     May 4, 2015       NaN  Opinion   \n\n                                                   url  \\\n0    https://wildcat.arizona.edu/155604/opinions/bo...   \n1    https://wildcat.arizona.edu/155594/opinions/op...   \n2    https://wildcat.arizona.edu/154146/opinions/s-...   \n3    https://wildcat.arizona.edu/154116/opinions/s-...   \n4    https://wildcat.arizona.edu/154126/opinions/ed...   \n..                                                 ...   \n995  https://wildcat.arizona.edu/123054/opinions/he...   \n996  https://wildcat.arizona.edu/102511/opinions/ad...   \n997  https://wildcat.arizona.edu/127949/opinions/co...   \n998  https://wildcat.arizona.edu/142548/opinions/le...   \n999  https://wildcat.arizona.edu/100073/opinions/ca...   \n\n                                                tokens  sentiment  \n0    [book, review, fresh, fruit, broken, bodies, s...        0.0  \n1    [opinion, first, presidential, debate, lacked,...        0.0  \n2    [opinion, college, wbb, favorites, sleeper, pi...       -1.0  \n3    [opinion, college, mbb, favorites, sleeper, pi...       -1.0  \n4    [editorial, desk, altered, opinions, thrive, w...        0.0  \n..                                                 ...        ...  \n995                                [best, help, nepal]        5.0  \n996                        [adderall, abuse, harmless]       -3.0  \n997                   [court, rule, legitimate, judge]        0.0  \n998                             [letters, editor, may]        0.0  \n999          [capability, imperfectly, captured, tces]        1.0  \n\n[1000 rows x 8 columns]"
  },
  {
    "objectID": "slides/08-web-scraping.html#scraping-the-web-what-why",
    "href": "slides/08-web-scraping.html#scraping-the-web-what-why",
    "title": "Web scraping",
    "section": "Scraping the web: what? why?",
    "text": "Scraping the web: what? why?\n\nIncreasing amount of data is available on the web\nThese data are provided in an unstructured format: you can always copy&paste, but it’s time-consuming and prone to errors\nWeb scraping is the process of extracting this information automatically and transform it into a structured dataset\nTwo different scenarios:\n\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy).\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files."
  },
  {
    "objectID": "slides/08-web-scraping.html#hypertext-markup-language",
    "href": "slides/08-web-scraping.html#hypertext-markup-language",
    "title": "Web scraping",
    "section": "Hypertext Markup Language",
    "text": "Hypertext Markup Language\nMost of the data on the web is still largely available as HTML - while it is structured (hierarchical) it often is not available in a form useful for analysis (flat / tidy).\n\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is a title&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;\n    &lt;br/&gt;\n    &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n    &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n    &lt;div class=\"contact\"&gt;\n      &lt;div class=\"home\"&gt;555-555-1234&lt;/div&gt;\n      &lt;div class=\"home\"&gt;555-555-2345&lt;/div&gt;\n      &lt;div class=\"work\"&gt;555-555-9999&lt;/div&gt;\n      &lt;div class=\"fax\"&gt;555-555-8888&lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;"
  },
  {
    "objectID": "slides/08-web-scraping.html#beautifulsoup",
    "href": "slides/08-web-scraping.html#beautifulsoup",
    "title": "Web scraping",
    "section": "BeautifulSoup",
    "text": "BeautifulSoup\n\n\n\nThe BeautifulSoup package makes basic processing and manipulation of HTML data straight forward\nbeautiful-soup-4.readthedocs.io\n\n\nfrom bs4 import BeautifulSoup"
  },
  {
    "objectID": "slides/08-web-scraping.html#beautifulsoup-1",
    "href": "slides/08-web-scraping.html#beautifulsoup-1",
    "title": "Web scraping",
    "section": "BeautifulSoup",
    "text": "BeautifulSoup\nCore functions:\n\nrequests.get(url) - send an HTTP GET request to a URL\nBeautifulSoup(html, 'html.parser') - parse HTML data from a string\nsoup.select('selector') - select specified elements from the HTML document using CSS selectors\nelement.get_text() - extract text content from an element\nelement['attribute'] - extract attribute value from an element"
  },
  {
    "objectID": "slides/08-web-scraping.html#html-beautifulsoup-requests",
    "href": "slides/08-web-scraping.html#html-beautifulsoup-requests",
    "title": "Web scraping",
    "section": "HTML, BeautifulSoup, & requests",
    "text": "HTML, BeautifulSoup, & requests\n\nhtml = '''\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is a title&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;\n    &lt;br/&gt;\n    &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n    &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n    &lt;div class=\"contact\"&gt;\n      &lt;div class=\"home\"&gt;555-555-1234&lt;/div&gt;\n      &lt;div class=\"home\"&gt;555-555-2345&lt;/div&gt;\n      &lt;div class=\"work\"&gt;555-555-9999&lt;/div&gt;\n      &lt;div class=\"fax\"&gt;555-555-8888&lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n'''\n\n\n\nsoup = BeautifulSoup(html, 'html.parser')"
  },
  {
    "objectID": "slides/08-web-scraping.html#selecting-elements",
    "href": "slides/08-web-scraping.html#selecting-elements",
    "title": "Web scraping",
    "section": "Selecting elements",
    "text": "Selecting elements\n\np_elements = soup.select('p')\nprint(p_elements)\n\n[&lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;]\n\n\n\n\np_text = [p.get_text() for p in p_elements]\nprint(p_text)\n\n['Hello world!']\n\n\n\n\n\np_names = [p.name for p in p_elements]\nprint(p_names)\n\n['p']\n\n\n\n\n\np_attrs = [p.attrs for p in p_elements]\nprint(p_attrs)\n\n[{'align': 'center'}]\n\n\n\n\n\np_align = [p['align'] for p in p_elements if 'align' in p.attrs]\nprint(p_align)\n\n['center']"
  },
  {
    "objectID": "slides/08-web-scraping.html#more-selecting-tags",
    "href": "slides/08-web-scraping.html#more-selecting-tags",
    "title": "Web scraping",
    "section": "More selecting tags",
    "text": "More selecting tags\n\n\ndiv_elements = soup.select('div')\nprint(div_elements)\n\n[&lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;, &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;, &lt;div class=\"contact\"&gt;\n&lt;div class=\"home\"&gt;555-555-1234&lt;/div&gt;\n&lt;div class=\"home\"&gt;555-555-2345&lt;/div&gt;\n&lt;div class=\"work\"&gt;555-555-9999&lt;/div&gt;\n&lt;div class=\"fax\"&gt;555-555-8888&lt;/div&gt;\n&lt;/div&gt;, &lt;div class=\"home\"&gt;555-555-1234&lt;/div&gt;, &lt;div class=\"home\"&gt;555-555-2345&lt;/div&gt;, &lt;div class=\"work\"&gt;555-555-9999&lt;/div&gt;, &lt;div class=\"fax\"&gt;555-555-8888&lt;/div&gt;]\n\n\n\n\n\n\ndiv_text = [div.get_text() for div in div_elements]\nprint(div_text)\n\n['John', 'Doe', '\\n555-555-1234\\n555-555-2345\\n555-555-9999\\n555-555-8888\\n', '555-555-1234', '555-555-2345', '555-555-9999', '555-555-8888']"
  },
  {
    "objectID": "slides/08-web-scraping.html#css-selectors",
    "href": "slides/08-web-scraping.html#css-selectors",
    "title": "Web scraping",
    "section": "CSS selectors",
    "text": "CSS selectors\n\nWe will use a tool called SelectorGadget to help us identify the HTML elements of interest by constructing a CSS selector which can be used to subset the HTML document.\nSome examples of basic selector syntax is below,\n\n\n\n\n\n\n\n\n\n\nSelector\nExample\nDescription\n\n\n\n\n.class\n.title\nSelect all elements with class=“title”\n\n\n#id\n#name\nSelect all elements with id=“name”\n\n\nelement\np\nSelect all &lt;p&gt; elements\n\n\nelement element\ndiv p\nSelect all &lt;p&gt; elements inside a &lt;div&gt; element\n\n\nelement&gt;element\ndiv &gt; p\nSelect all &lt;p&gt; elements with &lt;div&gt; as a parent\n\n\n[attribute]\n[class]\nSelect all elements with a class attribute\n\n\n[attribute=value]\n[class=title]\nSelect all elements with class=“title”"
  },
  {
    "objectID": "slides/08-web-scraping.html#css-classes-and-ids",
    "href": "slides/08-web-scraping.html#css-classes-and-ids",
    "title": "Web scraping",
    "section": "CSS classes and ids",
    "text": "CSS classes and ids\n\nname_elements = soup.select('.name')\nprint(name_elements)\n\n[&lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;, &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;]\n\n\n\n\nfirst_name = soup.select('#first')\nprint(first_name)\n\n[&lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;]"
  },
  {
    "objectID": "slides/08-web-scraping.html#text-with-get_text",
    "href": "slides/08-web-scraping.html#text-with-get_text",
    "title": "Web scraping",
    "section": "Text with get_text()",
    "text": "Text with get_text()\n\nhtml = '''\n&lt;p&gt;  \n  This is the first sentence in the paragraph.\n  This is the second sentence that should be on the same line as the first sentence.&lt;br&gt;This third sentence should start on a new line.\n&lt;/p&gt;\n'''\n\n\n\nsoup = BeautifulSoup(html, 'html.parser')\ntext = soup.get_text()\nprint(text)\n\n\n  \n  This is the first sentence in the paragraph.\n  This is the second sentence that should be on the same line as the first sentence.This third sentence should start on a new line."
  },
  {
    "objectID": "slides/08-web-scraping.html#html-tables-with-read_html",
    "href": "slides/08-web-scraping.html#html-tables-with-read_html",
    "title": "Web scraping",
    "section": "HTML tables with read_html()",
    "text": "HTML tables with read_html()\n\nhtml_table = '''\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is a title&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;table&gt;\n      &lt;tr&gt; &lt;th&gt;a&lt;/th&gt; &lt;th&gt;b&lt;/th&gt; &lt;th&gt;c&lt;/th&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;td&gt;5&lt;/td&gt; &lt;/tr&gt;\n    &lt;/table&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n'''\n\n\n\nsoup = BeautifulSoup(html_table, 'html.parser')\ntable = pd.read_html(str(soup.select('table')[0]))[0]\nprint(table)\n\n   a  b  c\n0  1  2  3\n1  2  3  4\n2  3  4  5"
  },
  {
    "objectID": "slides/08-web-scraping.html#selectorgadget",
    "href": "slides/08-web-scraping.html#selectorgadget",
    "title": "Web scraping",
    "section": "SelectorGadget",
    "text": "SelectorGadget\nSelectorGadget (selectorgadget.com) is a javascript based tool that helps you interactively build an appropriate CSS selector for the content you are interested in."
  },
  {
    "objectID": "slides/08-web-scraping.html#opinion-articles-in-the-arizona-daily-wildcat",
    "href": "slides/08-web-scraping.html#opinion-articles-in-the-arizona-daily-wildcat",
    "title": "Web scraping",
    "section": "Opinion articles in The Arizona Daily Wildcat",
    "text": "Opinion articles in The Arizona Daily Wildcat\nGo to https://wildcat.arizona.edu/category/opinions/.\n\nHow many articles are on the page?"
  },
  {
    "objectID": "slides/08-web-scraping.html#goal",
    "href": "slides/08-web-scraping.html#goal",
    "title": "Web scraping",
    "section": "Goal",
    "text": "Goal\n\n\n\nScrape data and organize it in a tabular format in Python\nPerform light text parsing to clean data\nSummarize and visualze the data"
  },
  {
    "objectID": "slides/08-web-scraping.html#ae-06",
    "href": "slides/08-web-scraping.html#ae-06",
    "title": "Web scraping",
    "section": "ae-06",
    "text": "ae-06\n\n\nOpen a new window in VS Code (File &gt; New Window) and open the project called ae.\nIf there are any uncommitted files, commit them, and then click Pull.\nOpen the file called wildcat-scrape.py and follow along."
  },
  {
    "objectID": "slides/08-web-scraping.html#recap",
    "href": "slides/08-web-scraping.html#recap",
    "title": "Web scraping",
    "section": "Recap",
    "text": "Recap\n\nUse the SelectorGadget identify tags for elements you want to grab\nUse BeautifulSoup to first read the whole page (into Python) and then parse the object you’ve read in to the elements you’re interested in\nPut the components together in a data frame and analyze it like you analyze any other data"
  },
  {
    "objectID": "slides/08-web-scraping.html#a-new-python-workflow",
    "href": "slides/08-web-scraping.html#a-new-python-workflow",
    "title": "Web scraping",
    "section": "A new Python workflow",
    "text": "A new Python workflow\n\nWhen working in a Jupyter notebook, your analysis is re-run each time you execute the notebook\nIf web scraping in a notebook, you’d be re-scraping the data each time you run the notebook, which is undesirable (and not nice)!\nAn alternative workflow:\n\nUse a Python script to save your code\nSaving interim data scraped using the code in the script as CSV or pickle files\nUse the saved data in your analysis in your notebook"
  },
  {
    "objectID": "slides/08-web-scraping.html#ethics-can-you-vs-should-you",
    "href": "slides/08-web-scraping.html#ethics-can-you-vs-should-you",
    "title": "Web scraping",
    "section": "Ethics: “Can you?” vs “Should you?”",
    "text": "Ethics: “Can you?” vs “Should you?”\n\n\n\n\n\n\n\nSource: Brian Resnick, Researchers just released profile data on 70,000 OkCupid users without permission, Vox."
  },
  {
    "objectID": "slides/08-web-scraping.html#can-you-vs-should-you",
    "href": "slides/08-web-scraping.html#can-you-vs-should-you",
    "title": "Web scraping",
    "section": "“Can you?” vs “Should you?”",
    "text": "“Can you?” vs “Should you?”"
  },
  {
    "objectID": "slides/08-web-scraping.html#challenges-unreliable-formatting",
    "href": "slides/08-web-scraping.html#challenges-unreliable-formatting",
    "title": "Web scraping",
    "section": "Challenges: Unreliable formatting",
    "text": "Challenges: Unreliable formatting\n\n\n\n\n\n\n\nalumni.arizona.edu/celebrate-arizona/notable-alumni"
  },
  {
    "objectID": "slides/08-web-scraping.html#challenges-data-broken-into-many-pages",
    "href": "slides/08-web-scraping.html#challenges-data-broken-into-many-pages",
    "title": "Web scraping",
    "section": "Challenges: Data broken into many pages",
    "text": "Challenges: Data broken into many pages"
  },
  {
    "objectID": "slides/08-web-scraping.html#workflow-screen-scraping-vs.-apis",
    "href": "slides/08-web-scraping.html#workflow-screen-scraping-vs.-apis",
    "title": "Web scraping",
    "section": "Workflow: Screen scraping vs. APIs",
    "text": "Workflow: Screen scraping vs. APIs\nTwo different scenarios for web scraping:\n\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy)\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/14-sampling-inference.html#setup",
    "href": "slides/14-sampling-inference.html#setup",
    "title": "Sampling distributions + inference",
    "section": "Setup",
    "text": "Setup\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats \nimport seaborn as sns\n\nnp.random.seed(1)"
  },
  {
    "objectID": "slides/14-sampling-inference.html#variability-of-sample-statistics",
    "href": "slides/14-sampling-inference.html#variability-of-sample-statistics",
    "title": "Sampling distributions + inference",
    "section": "Variability of sample statistics",
    "text": "Variability of sample statistics\n\n\nWe’ve seen that each sample from the population yields a slightly different sample statistic (sample mean, sample proportion, etc.)\nPreviously we’ve quantified this value via simulation\nToday we talk about some of the theory underlying sampling distributions, particularly as they relate to sample means."
  },
  {
    "objectID": "slides/14-sampling-inference.html#statistical-inference",
    "href": "slides/14-sampling-inference.html#statistical-inference",
    "title": "Sampling distributions + inference",
    "section": "Statistical inference",
    "text": "Statistical inference\n\n\nStatistical inference is the act of generalizing from a sample in order to make conclusions regarding a population.\nWe are interested in population parameters, which we do not observe. Instead, we must calculate statistics from our sample in order to learn about them.\nAs part of this process, we must quantify the degree of uncertainty in our sample statistic."
  },
  {
    "objectID": "slides/14-sampling-inference.html#sampling-distribution-of-the-mean",
    "href": "slides/14-sampling-inference.html#sampling-distribution-of-the-mean",
    "title": "Sampling distributions + inference",
    "section": "Sampling distribution of the mean",
    "text": "Sampling distribution of the mean\nSuppose we’re interested in the mean resting heart rate of students at U of A, and are able to do the following:\n\n\nTake a random sample of size \\(n\\) from this population, and calculate the mean resting heart rate in this sample, \\(\\bar{X}_1\\)\nPut the sample back, take a second random sample of size \\(n\\), and calculate the mean resting heart rate from this new sample, \\(\\bar{X}_2\\)\nPut the sample back, take a third random sample of size \\(n\\), and calculate the mean resting heart rate from this sample, too…\n\n\n\n…and so on."
  },
  {
    "objectID": "slides/14-sampling-inference.html#sampling-distribution-of-the-mean-1",
    "href": "slides/14-sampling-inference.html#sampling-distribution-of-the-mean-1",
    "title": "Sampling distributions + inference",
    "section": "Sampling distribution of the mean",
    "text": "Sampling distribution of the mean\nAfter repeating this many times, we have a data set that has the sample means from the population: \\(\\bar{X}_1\\), \\(\\bar{X}_2\\), \\(\\cdots\\), \\(\\bar{X}_K\\) (assuming we took \\(K\\) total samples).\n\n\nCan we say anything about the distribution of these sample means (that is, the sampling distribution of the mean?)\n\n\n\n(Keep in mind, we don’t know what the underlying distribution of mean resting heart rate of U of A students looks like!)"
  },
  {
    "objectID": "slides/14-sampling-inference.html#the-central-limit-theorem",
    "href": "slides/14-sampling-inference.html#the-central-limit-theorem",
    "title": "Sampling distributions + inference",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\nA quick caveat…\n\nFor now, let’s assume we know the underlying standard deviation, \\(\\sigma\\), from our distribution"
  },
  {
    "objectID": "slides/14-sampling-inference.html#the-central-limit-theorem-1",
    "href": "slides/14-sampling-inference.html#the-central-limit-theorem-1",
    "title": "Sampling distributions + inference",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\nFor a population with a well-defined mean \\(\\mu\\) and standard deviation \\(\\sigma\\), these three properties hold for the distribution of sample mean \\(\\bar{X}\\), assuming certain conditions hold:\n\n\nThe mean of the sampling distribution of the mean is identical to the population mean \\(\\mu\\).\nThe standard deviation of the distribution of the sample means is \\(\\sigma/\\sqrt{n}\\).\n\n\nThis is called the standard error (SE) of the mean.\n\n\nFor \\(n\\) large enough, the shape of the sampling distribution of means is approximately normally distributed."
  },
  {
    "objectID": "slides/14-sampling-inference.html#the-normal-gaussian-distribution",
    "href": "slides/14-sampling-inference.html#the-normal-gaussian-distribution",
    "title": "Sampling distributions + inference",
    "section": "The normal (Gaussian) distribution",
    "text": "The normal (Gaussian) distribution\nThe normal distribution is unimodal and symmetric and is described by its density function:\n\nIf a random variable \\(X\\) follows the normal distribution, then \\[f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left\\{ -\\frac{1}{2}\\frac{(x - \\mu)^2}{\\sigma^2} \\right\\}\\] where \\(\\mu\\) is the mean and \\(\\sigma^2\\) is the variance \\((\\sigma \\text{ is the standard deviation})\\)\n\n\n\n\n\n\n\n\nWarning\n\n\nWe often write \\(N(\\mu, \\sigma)\\) to describe this distribution."
  },
  {
    "objectID": "slides/14-sampling-inference.html#the-normal-distribution-graphically",
    "href": "slides/14-sampling-inference.html#the-normal-distribution-graphically",
    "title": "Sampling distributions + inference",
    "section": "The normal distribution (graphically)",
    "text": "The normal distribution (graphically)"
  },
  {
    "objectID": "slides/14-sampling-inference.html#wait-any-distribution",
    "href": "slides/14-sampling-inference.html#wait-any-distribution",
    "title": "Sampling distributions + inference",
    "section": "Wait, any distribution?",
    "text": "Wait, any distribution?\nThe central limit theorem tells us that sample means are normally distributed, if we have enough data and certain assumptions hold.\n\nThis is true even if our original variables are not normally distributed.\n\n\nClick here to see an interactive demonstration of this idea."
  },
  {
    "objectID": "slides/14-sampling-inference.html#conditions-for-clt",
    "href": "slides/14-sampling-inference.html#conditions-for-clt",
    "title": "Sampling distributions + inference",
    "section": "Conditions for CLT",
    "text": "Conditions for CLT\nWe need to check two conditions for CLT to hold: independence, sample size/distribution.\n\n✅ Independence: The sampled observations must be independent. This is difficult to check, but the following are useful guidelines:\n\n\nthe sample must be randomly taken\nif sampling without replacement, sample size must be less than 10% of the population size\n\n\n\n\nIf samples are independent, then by definition one sample’s value does not “influence” another sample’s value."
  },
  {
    "objectID": "slides/14-sampling-inference.html#conditions-for-clt-1",
    "href": "slides/14-sampling-inference.html#conditions-for-clt-1",
    "title": "Sampling distributions + inference",
    "section": "Conditions for CLT",
    "text": "Conditions for CLT\n✅ Sample size / distribution:\n\n\nif data are numerical, usually n &gt; 30 is considered a large enough sample for the CLT to apply\nif we know for sure that the underlying data are normally distributed, then the distribution of sample means will also be exactly normal, regardless of the sample size\nif data are categorical, at least 10 successes and 10 failures."
  },
  {
    "objectID": "slides/14-sampling-inference.html#underlying-population-not-observed-in-real-life",
    "href": "slides/14-sampling-inference.html#underlying-population-not-observed-in-real-life",
    "title": "Sampling distributions + inference",
    "section": "Underlying population (not observed in real life!)",
    "text": "Underlying population (not observed in real life!)\n\nrs_pop = pd.DataFrame({'x': np.random.beta(a=1, b=5, size=100000) * 100})\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe true population parameters\n\n\n(16.6681176684249, 14.070251294281247)"
  },
  {
    "objectID": "slides/14-sampling-inference.html#sampling-from-the-population---1",
    "href": "slides/14-sampling-inference.html#sampling-from-the-population---1",
    "title": "Sampling distributions + inference",
    "section": "Sampling from the population - 1",
    "text": "Sampling from the population - 1\n\nnp.random.seed(1)\nsamp_1 = rs_pop.sample(n=50)\nsamp_1_mean = samp_1['x'].mean()\n\n\n\nsamp_1_mean\n\n15.459323508748778"
  },
  {
    "objectID": "slides/14-sampling-inference.html#sampling-from-the-population---2",
    "href": "slides/14-sampling-inference.html#sampling-from-the-population---2",
    "title": "Sampling distributions + inference",
    "section": "Sampling from the population - 2",
    "text": "Sampling from the population - 2\n\nnp.random.seed(2)\nsamp_2 = rs_pop.sample(n=50)\nsamp_2_mean = samp_2['x'].mean()\n\n\n\nsamp_2_mean\n\n16.54881766128449"
  },
  {
    "objectID": "slides/14-sampling-inference.html#sampling-from-the-population---3",
    "href": "slides/14-sampling-inference.html#sampling-from-the-population---3",
    "title": "Sampling distributions + inference",
    "section": "Sampling from the population - 3",
    "text": "Sampling from the population - 3\n\nnp.random.seed(3)\nsamp_3 = rs_pop.sample(n=50)\nsamp_3_mean = samp_3['x'].mean()\n\n\n\nsamp_3_mean\n\n18.232335628488613\n\n\n\nkeep repeating…"
  },
  {
    "objectID": "slides/14-sampling-inference.html#sampling-distribution",
    "href": "slides/14-sampling-inference.html#sampling-distribution",
    "title": "Sampling distributions + inference",
    "section": "Sampling distribution",
    "text": "Sampling distribution\n\nnp.random.seed(92620)\nsampling_means = [rs_pop.sample(n=50, replace=True)['x'].mean() for _ in range(5000)]\n\nsampling_df = pd.DataFrame({'xbar': sampling_means})\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe sample statistics\n\n\n(16.71372258467488, 1.9996839510659443)"
  },
  {
    "objectID": "slides/14-sampling-inference.html#section",
    "href": "slides/14-sampling-inference.html#section",
    "title": "Sampling distributions + inference",
    "section": "",
    "text": "Compare the shapes, centers, and spreads of these distributions:\n\n\n\nThe true population\n\n\n\n\n\n\n\n\n\n\nThe sample statistics"
  },
  {
    "objectID": "slides/14-sampling-inference.html#recap",
    "href": "slides/14-sampling-inference.html#recap",
    "title": "Sampling distributions + inference",
    "section": "Recap",
    "text": "Recap\n\n\nIf certain assumptions are satisfied, regardless of the shape of the population distribution, the sampling distribution of the mean follows an approximately normal distribution.\nThe center of the sampling distribution is at the center of the population distribution.\nThe sampling distribution is less variable than the population distribution (and we can quantify by how much).\n\n\n\n\nWhat is the standard error, and how are the standard error and sample size related? What does that say about how the spread of the sampling distribution changes as \\(n\\) increases?"
  },
  {
    "objectID": "slides/14-sampling-inference.html#why-do-we-care",
    "href": "slides/14-sampling-inference.html#why-do-we-care",
    "title": "Sampling distributions + inference",
    "section": "Why do we care?",
    "text": "Why do we care?\nKnowing the distribution of the sample statistic \\(\\bar{X}\\) can help us\n\n\nEstimate a population parameter as point estimate \\(\\boldsymbol{\\pm}\\) margin of error\nThe margin of error is comprised of a measure of how confident we want to be and how variable the sample statistic is\n\n\n\nTest for a population parameter by evaluating how likely it is to obtain to observed sample statistic when assuming that the null hypothesis is true\n\nThis probability will depend on how variable the sampling distribution is"
  },
  {
    "objectID": "slides/14-sampling-inference.html#inference-based-on-the-clt-1",
    "href": "slides/14-sampling-inference.html#inference-based-on-the-clt-1",
    "title": "Sampling distributions + inference",
    "section": "Inference based on the CLT",
    "text": "Inference based on the CLT\nIf necessary conditions are met, we can also use inference methods based on the CLT. Suppose we know the true population standard deviation, \\(\\sigma\\).\n\nThen the CLT tells us that \\(\\bar{X}\\) approximately has the distribution \\(N\\left(\\mu, \\sigma/\\sqrt{n}\\right)\\).\nThat is,\n\\[Z = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim N(0, 1)\\]"
  },
  {
    "objectID": "slides/14-sampling-inference.html#t-distribution",
    "href": "slides/14-sampling-inference.html#t-distribution",
    "title": "Sampling distributions + inference",
    "section": "T distribution",
    "text": "T distribution\nIn practice, we never know the true value of \\(\\sigma\\), and so we estimate it from our data with \\(s\\).\nWe can make the following test statistic for testing a single sample’s population mean, which has a t-distribution with n-1 degrees of freedom:\n\n\n\\[ T = \\frac{\\bar{X} - \\mu}{s/\\sqrt{n}} \\sim t_{n-1}\\]"
  },
  {
    "objectID": "slides/14-sampling-inference.html#t-distribution-1",
    "href": "slides/14-sampling-inference.html#t-distribution-1",
    "title": "Sampling distributions + inference",
    "section": "T distribution",
    "text": "T distribution\n\n\nThe t-distribution is also unimodal and symmetric, and is centered at 0\nIt has thicker tails than the normal distribution\n\nThis is to make up for additional variability introduced by using \\(s\\) instead of \\(\\sigma\\) in calculation of the SE\n\nIt is defined by the degrees of freedom"
  },
  {
    "objectID": "slides/14-sampling-inference.html#t-vs-z-distributions",
    "href": "slides/14-sampling-inference.html#t-vs-z-distributions",
    "title": "Sampling distributions + inference",
    "section": "T vs Z distributions",
    "text": "T vs Z distributions"
  },
  {
    "objectID": "slides/14-sampling-inference.html#t-distribution-2",
    "href": "slides/14-sampling-inference.html#t-distribution-2",
    "title": "Sampling distributions + inference",
    "section": "T distribution",
    "text": "T distribution\n\n\nFinding probabilities under the t curve:\n\n# P(t &lt; -1.96) for df = 9\np_less = stats.t.cdf(-1.96, df=9)\np_less\n\n0.04082220273020832\n\n\n\n\n# P(t &gt; -1.96) for df = 9\np_greater = stats.t.sf(-1.96, df=9)\np_greater\n\n0.9591777972697917\n\n\n\nFinding cutoff values under the t curve:\n\n# Find Q1 (25th percentile) for df = 9\nq1 = stats.t.ppf(0.25, df=9)\nq1\n\n-0.7027221467513188\n\n\n\n\n# Find Q3 (75th percentile) for df = 9\nq3 = stats.t.ppf(0.75, df=9)\nq3\n\n0.7027221467513188"
  },
  {
    "objectID": "slides/14-sampling-inference.html#confidence-interval-for-a-mean",
    "href": "slides/14-sampling-inference.html#confidence-interval-for-a-mean",
    "title": "Sampling distributions + inference",
    "section": "Confidence interval for a mean",
    "text": "Confidence interval for a mean\n\n\n\n\n\n\nWarning\n\n\nGeneral form of the confidence interval\n\\[point~estimate \\pm critical~value \\times SE\\]\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nConfidence interval for the mean\n\\[\\bar{x} \\pm t^*_{n-1} \\times \\frac{s}{\\sqrt{n}}\\]"
  },
  {
    "objectID": "slides/14-sampling-inference.html#durham-nc-resident-satisfaction",
    "href": "slides/14-sampling-inference.html#durham-nc-resident-satisfaction",
    "title": "Sampling distributions + inference",
    "section": "Durham NC Resident Satisfaction",
    "text": "Durham NC Resident Satisfaction\ndurham_survey contains resident responses to a survey given by the City of Durham in 2018. These are a randomly selected, representative sample of Durham residents.\nQuestions were rated 1 - 5, with 1 being “highly dissatisfied” and 5 being “highly satisfied.”"
  },
  {
    "objectID": "slides/14-sampling-inference.html#exploratory-data-analysis",
    "href": "slides/14-sampling-inference.html#exploratory-data-analysis",
    "title": "Sampling distributions + inference",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\n\n\ndurham = pd.read_csv(\"data/durham_survey.csv\")\ndurham_filtered = durham[durham['quality_library'] != 9]\n\n\nsummary_stats = durham_filtered['quality_library'].agg(['mean', 'median', 'std', 'count']).rename({\n    'mean': 'x_bar',\n    'median': 'med',\n    'std': 'sd',\n    'count': 'n'\n})\nprint(summary_stats)\n\nx_bar      3.96929\nmed        4.00000\nsd         0.90033\nn        521.00000\nName: quality_library, dtype: float64"
  },
  {
    "objectID": "slides/14-sampling-inference.html#calculate-95-confidence-interval",
    "href": "slides/14-sampling-inference.html#calculate-95-confidence-interval",
    "title": "Sampling distributions + inference",
    "section": "Calculate 95% confidence interval",
    "text": "Calculate 95% confidence interval\n\\[\\bar{x} \\pm t^*_{n-1} \\times \\frac{s}{\\sqrt{n}}\\]\n\n\npoint_est = summary_stats['x_bar'] # Point estimate\nse = summary_stats['sd'] / (summary_stats['n'] ** 0.5) # SE\ndf = summary_stats['n'] - 1 # Degrees of freedom\n\n\n\n\nt_star = stats.t.ppf(0.975, df) # Critical value \n\n\n\n\n# Confidence interval\nCI = point_est + np.array([-1, 1]) * t_star * se\nCI_rounded = np.round(CI, 2)\nCI_rounded\n\narray([3.89, 4.05])"
  },
  {
    "objectID": "slides/14-sampling-inference.html#interpret-95-confidence-interval",
    "href": "slides/14-sampling-inference.html#interpret-95-confidence-interval",
    "title": "Sampling distributions + inference",
    "section": "Interpret 95% confidence interval",
    "text": "Interpret 95% confidence interval\nThe 95% confidence interval is 3.89 to 4.05.\n\n\nInterpret this interval in context of the data.\n\n\n\nWe are 95% confident that the true mean rating for Durham residents’ satisfaction with the library system is between 3.89 and 4.05.\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#what-is-numpy",
    "href": "slides/03-numpy-pandas.html#what-is-numpy",
    "title": "Intro to Numpy + Pandas",
    "section": "What is NumPy?",
    "text": "What is NumPy?\n\n\nNumPy = Numerical Python\nFoundational package for scientific computing\nHigh-performance multidimensional arrays\nTools for working with arrays\n\n\n\nStart with\npip install numpy"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#why-numpy-for-data-science",
    "href": "slides/03-numpy-pandas.html#why-numpy-for-data-science",
    "title": "Intro to Numpy + Pandas",
    "section": "Why NumPy for data science?",
    "text": "Why NumPy for data science?\n\n\nEssential for data processing, manipulation, and analysis.\nUnderpins advanced data science algorithms implemented in Python.\nFast and memory-efficient with powerful data structures."
  },
  {
    "objectID": "slides/03-numpy-pandas.html#creating-arrays",
    "href": "slides/03-numpy-pandas.html#creating-arrays",
    "title": "Intro to Numpy + Pandas",
    "section": "Creating arrays",
    "text": "Creating arrays\n\nCodeOutput\n\n\n\nimport numpy as np\n\n# Creating a simple NumPy array\narr = np.array([1, 2, 3, 4])\n\n# Multidimensional array\nmulti_arr = np.array([[1, 2, 3], [4, 5, 6]])\n\n# Range of values\nrange_arr = np.arange(10)\n\n# Array of zeros\nzeros_arr = np.zeros((3, 3))\n\n# Array of ones\nones_arr = np.ones((2, 2))\n\n# Identity matrix\nidentity_matrix = np.eye(3)\n\n\n\n\n\narr: [1 2 3 4] \n\nmulti_arr: [[1 2 3]\n [4 5 6]] \n\nrange_arr: [0 1 2 3 4 5 6 7 8 9] \n\nzeros_arr: [[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]] \n\nones_arr: [[1. 1.]\n [1. 1.]] \n\nidentity_matrix: [[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#array-attributes",
    "href": "slides/03-numpy-pandas.html#array-attributes",
    "title": "Intro to Numpy + Pandas",
    "section": "Array attributes",
    "text": "Array attributes\n\n# Array dimensions\nprint(\"Dimensions:\", multi_arr.ndim)\n\n# Shape of array\nprint(\"Shape:\", multi_arr.shape)\n\n# Size of array\nprint(\"Size:\", multi_arr.size)\n\n# Data type of array elements\nprint(\"Data Type:\", multi_arr.dtype)\n\nDimensions: 2\nShape: (2, 3)\nSize: 6\nData Type: int64"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#arithmetic-operations",
    "href": "slides/03-numpy-pandas.html#arithmetic-operations",
    "title": "Intro to Numpy + Pandas",
    "section": "Arithmetic operations",
    "text": "Arithmetic operations\n\n# Element-wise addition\naddition = arr + 2\n\n# Element-wise subtraction\nsubtraction = arr - 2\n\n# Element-wise multiplication\nmultiplication = arr * 2\n\n# Element-wise division\ndivision = arr / 2\n\n\n\naddition: [3 4 5 6] \n\nsubtraction: [-1  0  1  2] \n\nmultiplication: [2 4 6 8] \n\ndivision: [0.5 1.  1.5 2. ]"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#aside",
    "href": "slides/03-numpy-pandas.html#aside",
    "title": "Intro to Numpy + Pandas",
    "section": "Aside",
    "text": "Aside\nWhy do my outputs look than different than Python?\n\nPythonMy slides\n\n\n\nprint(addition)\nprint(subtraction)\nprint(multiplication)\nprint(division)\n\n[3 4 5 6]\n[-1  0  1  2]\n[2 4 6 8]\n[0.5 1.  1.5 2. ]\n\n\n\n\n\nprint(\"addition:\", addition, \"\\n\")\n\nprint(\"subtraction:\", subtraction, \"\\n\")\n\nprint(\"multiplication:\", multiplication, \"\\n\")\n\nprint(\"division:\", division, \"\\n\")\n\naddition: [3 4 5 6] \n\nsubtraction: [-1  0  1  2] \n\nmultiplication: [2 4 6 8] \n\ndivision: [0.5 1.  1.5 2. ]"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#statistical-operations",
    "href": "slides/03-numpy-pandas.html#statistical-operations",
    "title": "Intro to Numpy + Pandas",
    "section": "Statistical operations",
    "text": "Statistical operations\n\n# Sum of elements\ntotal = arr.sum()\n\n# Mean of elements\nmean_value = arr.mean()\n\n# Standard deviation\nstd_dev = arr.std()\n\n# Correlation coefficient\ncorr = np.corrcoef(multi_arr)\n\n\n\ntotal: 10 \n\nmean_value: 2.5 \n\nstd_dev: 1.118033988749895 \n\ncorr: [[1. 1.]\n [1. 1.]]"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#reshaping-and-transposing",
    "href": "slides/03-numpy-pandas.html#reshaping-and-transposing",
    "title": "Intro to Numpy + Pandas",
    "section": "Reshaping and transposing",
    "text": "Reshaping and transposing\n\n# Reshaping an array\nreshaped = np.reshape(range_arr, (2, 5))\n\n# Transpose of an array\ntransposed = multi_arr.T\n\n\n\nrange_arr: [0 1 2 3 4 5 6 7 8 9] \n\nreshaped: [[0 1 2 3 4]\n [5 6 7 8 9]] \n\nmulti_arr: [[1 2 3]\n [4 5 6]] \n\ntransposed: [[1 4]\n [2 5]\n [3 6]]"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#indexing-and-slicing",
    "href": "slides/03-numpy-pandas.html#indexing-and-slicing",
    "title": "Intro to Numpy + Pandas",
    "section": "Indexing and slicing",
    "text": "Indexing and slicing\n\n# Accessing a specific element\nelement = multi_arr[0, 1]\n\n# Slicing a row\nrow = multi_arr[1, :]\n\n# Slicing a column\ncolumn = multi_arr[:, 2]\n\n\n\nmulti_arr: [[1 2 3]\n [4 5 6]] \n\nelement: [[1 2 3]\n [4 5 6]] \n\nrow: [4 5 6] \n\ncolumn: [3 6]"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#broadcasting",
    "href": "slides/03-numpy-pandas.html#broadcasting",
    "title": "Intro to Numpy + Pandas",
    "section": "Broadcasting",
    "text": "Broadcasting\n\n# Broadcasting allows arithmetic operations on arrays of different sizes\nbroadcasted_addition = multi_arr + np.array([1, 0, 1])\n\n\n\nmulti_arr: [[1 2 3]\n [4 5 6]] \n\nbroadcasted_addition: [[2 2 4]\n [5 5 7]]"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#matrix-operations",
    "href": "slides/03-numpy-pandas.html#matrix-operations",
    "title": "Intro to Numpy + Pandas",
    "section": "Matrix operations",
    "text": "Matrix operations\nDot product: take two equal-length sequences and return a single number\n2 • (1, 2, 3) = 2x1 = 2; 2x2 = 4; 2x3 = 6\nMatrix multiplication:\n(1, 2, 3) • (7, 9, 11) = (1×7 + 2×9 + 3×11) = 58\n\n# Dot product\ndot_product = np.dot(arr, arr)\n\n# Matrix multiplication\nmatrix_mul = np.dot(multi_arr, identity_matrix)\n\n\n\ndot_product: 30 \n\nmatrix_mul: [[1. 2. 3.]\n [4. 5. 6.]]"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#eigenvalues-and-eigenvectors",
    "href": "slides/03-numpy-pandas.html#eigenvalues-and-eigenvectors",
    "title": "Intro to Numpy + Pandas",
    "section": "Eigenvalues and Eigenvectors",
    "text": "Eigenvalues and Eigenvectors\n\n# Eigenvalues and eigenvectors\neigenvalues, eigenvectors = np.linalg.eig(identity_matrix)\n\n\n\neigenvalues: [1. 1. 1.] \n\neigenvectors: [[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#numpy-for-data-science",
    "href": "slides/03-numpy-pandas.html#numpy-for-data-science",
    "title": "Intro to Numpy + Pandas",
    "section": "NumPy for data science",
    "text": "NumPy for data science\n\nApplication in Algorithms\n\nNumPy arrays are used in various data science algorithms like clustering, classification, and neural networks.\n\n\n\nPerformance\n\nNumPy operations are implemented in C, which makes them much faster than standard Python."
  },
  {
    "objectID": "slides/03-numpy-pandas.html#conclusion",
    "href": "slides/03-numpy-pandas.html#conclusion",
    "title": "Intro to Numpy + Pandas",
    "section": "Conclusion",
    "text": "Conclusion\n\n\nNumPy is integral to data science and analysis in Python.\nIt provides efficient and fast operations for array and matrix manipulation.\nUnderstanding NumPy is crucial for implementing and customizing data science algorithms."
  },
  {
    "objectID": "slides/03-numpy-pandas.html#what-is-pandas",
    "href": "slides/03-numpy-pandas.html#what-is-pandas",
    "title": "Intro to Numpy + Pandas",
    "section": "What is Pandas?",
    "text": "What is Pandas?\n\n\nHigh-Performance Library: Pandas is a Python library for fast data manipulation.\nCore Structures: It introduces DataFrame and Series for data handling.\nData Processing: Ideal for cleaning and analyzing datasets.\nVersatile I/O: Offers extensive file format compatibility for data I/O."
  },
  {
    "objectID": "slides/03-numpy-pandas.html#why-pandas-for-data-mining",
    "href": "slides/03-numpy-pandas.html#why-pandas-for-data-mining",
    "title": "Intro to Numpy + Pandas",
    "section": "Why Pandas for data mining?",
    "text": "Why Pandas for data mining?\n\n\nStreamlines Data Prep: Optimizes data manipulation for mining readiness.\nBuilt-in Analysis: Includes essential tools for quick data exploration.\nHandles Large Data: Efficiently processes and analyzes big datasets."
  },
  {
    "objectID": "slides/03-numpy-pandas.html#series",
    "href": "slides/03-numpy-pandas.html#series",
    "title": "Intro to Numpy + Pandas",
    "section": "Series",
    "text": "Series\nOne-dimensional array-like object containing a sequence of values with an associated array of labels, its index.\n\nimport pandas as pd\n\n# Creating a Series\nser = pd.Series([4, 7, -5, 3], index=['d', 'b', 'a', 'c'])\n\n# Accessing elements\nprint(\"a:\", ser['a'])\n\na: -5"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#dataframe",
    "href": "slides/03-numpy-pandas.html#dataframe",
    "title": "Intro to Numpy + Pandas",
    "section": "DataFrame",
    "text": "DataFrame\nA rectangular table of data with an ordered collection of columns\n\n# Creating a DataFrame\ndata = {\n    'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n    'year': [2000, 2001, 2002, 2001, 2002],\n    'pop': [1.5, 1.7, 3.6, 2.4, 2.9]\n}\nframe = pd.DataFrame(data)\n\n# Selecting columns\nprint(frame['state'])\n\n0      Ohio\n1      Ohio\n2      Ohio\n3    Nevada\n4    Nevada\nName: state, dtype: object"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#index-objects",
    "href": "slides/03-numpy-pandas.html#index-objects",
    "title": "Intro to Numpy + Pandas",
    "section": "Index objects",
    "text": "Index objects\nImmutable, can’t be modified by a user\n\n# Index objects\nobj = pd.Series(range(3), index=['a', 'b', 'c'])\nindex = obj.index\n\nprint(index)\n\nIndex(['a', 'b', 'c'], dtype='object')"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#case-study-average-rent-costs",
    "href": "slides/03-numpy-pandas.html#case-study-average-rent-costs",
    "title": "Intro to Numpy + Pandas",
    "section": "Case study: average rent costs",
    "text": "Case study: average rent costs\n\n\n\n\n\n💰📈\n\n\nSource: Zillow Public Access Data"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#first-why-.csvs",
    "href": "slides/03-numpy-pandas.html#first-why-.csvs",
    "title": "Intro to Numpy + Pandas",
    "section": "First, why .CSVs?",
    "text": "First, why .CSVs?\n\n\nMore reproducible - can see changes on GitHub\nSimple file structure\nStandardized\nNon-proprietary (e.g., Excel)"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#reading-in-.csv-files",
    "href": "slides/03-numpy-pandas.html#reading-in-.csv-files",
    "title": "Intro to Numpy + Pandas",
    "section": "Reading in .CSV files",
    "text": "Reading in .CSV files\n\n# Loading data from CSV\ndf = pd.read_csv('data/rent_avg.csv')\n\ndf\n\n\n\n\n\n\n\n\nRegionID\nSizeRank\nRegionName\nRegionType\nStateName\n1/31/15\n2/28/15\n3/31/15\n4/30/15\n5/31/15\n...\n2/28/23\n3/31/23\n4/30/23\n5/31/23\n6/30/23\n7/31/23\n8/31/23\n9/30/23\n10/31/23\n11/30/23\n\n\n\n\n0\n102001\n0\nUnited States\ncountry\nNaN\n1266.059583\n1272.748070\n1281.390109\n1291.808026\n1301.544232\n...\n2072.346516\n2084.944938\n2100.570959\n2113.158286\n2123.032953\n2132.040398\n2141.677753\n2147.835795\n2148.939168\n2147.563754\n\n\n1\n394913\n1\nNew York, NY\nmsa\nNY\n2233.133615\n2255.035180\n2272.077073\n2291.645864\n2297.479956\n...\n3336.961840\n3402.179034\n3470.949450\n3492.930681\n3502.786897\n3503.650740\n3509.480232\n3493.537322\n3460.942251\n3445.696877\n\n\n2\n753899\n2\nLos Angeles, CA\nmsa\nCA\n2571.296547\n2586.050819\n2604.348963\n2616.104497\n2637.303435\n...\n4073.810818\n4100.234089\n4134.999768\n4148.832674\n4182.522537\n4202.376930\n4230.003153\n4224.038689\n4213.465460\n4209.636932\n\n\n3\n394463\n3\nChicago, IL\nmsa\nIL\n1504.096116\n1510.879827\n1522.416987\n1534.343702\n1547.516576\n...\n2112.639599\n2123.617285\n2145.692631\n2163.843271\n2183.541315\n2196.506806\n2213.427631\n2225.237153\n2225.798038\n2221.960828\n\n\n4\n394514\n4\nDallas, TX\nmsa\nTX\n1363.557414\n1371.136919\n1381.114797\n1394.643185\n1408.025840\n...\n2222.442779\n2229.474165\n2239.462332\n2253.004851\n2267.408242\n2280.056798\n2285.063932\n2284.569053\n2274.785931\n2277.403767\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n467\n753871\n811\nBreckenridge, CO\nmsa\nCO\nNaN\nNaN\nNaN\nNaN\nNaN\n...\n3848.649613\n4327.112762\n4414.482838\n4438.619592\n4535.664564\n4599.237795\n4558.170264\n4667.043338\n4671.081209\n4472.222222\n\n\n468\n394751\n821\nKirksville, MO\nmsa\nMO\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1000.733430\n981.701456\n951.458333\n\n\n469\n753923\n849\nThe Dalles, OR\nmsa\nOR\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1757.739178\n1788.943167\n1885.904065\n1838.888889\n\n\n470\n394584\n863\nFallon, NV\nmsa\nNV\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1295.000000\n\n\n471\n394996\n915\nPortales, NM\nmsa\nNM\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\n1122.195307\n1101.628147\n1057.654564\n1071.572024\n1046.671512\n1099.305556\n\n\n\n\n472 rows × 112 columns"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#inspecting-data",
    "href": "slides/03-numpy-pandas.html#inspecting-data",
    "title": "Intro to Numpy + Pandas",
    "section": "Inspecting data",
    "text": "Inspecting data\nAny issues?\n\nHeadTailData typesDescribeStatsUnique values\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\nRegionID\nSizeRank\nRegionName\nRegionType\nStateName\n1/31/15\n2/28/15\n3/31/15\n4/30/15\n5/31/15\n...\n2/28/23\n3/31/23\n4/30/23\n5/31/23\n6/30/23\n7/31/23\n8/31/23\n9/30/23\n10/31/23\n11/30/23\n\n\n\n\n0\n102001\n0\nUnited States\ncountry\nNaN\n1266.059583\n1272.748070\n1281.390109\n1291.808026\n1301.544232\n...\n2072.346516\n2084.944938\n2100.570959\n2113.158286\n2123.032953\n2132.040398\n2141.677753\n2147.835795\n2148.939168\n2147.563754\n\n\n1\n394913\n1\nNew York, NY\nmsa\nNY\n2233.133615\n2255.035180\n2272.077073\n2291.645864\n2297.479956\n...\n3336.961840\n3402.179034\n3470.949450\n3492.930681\n3502.786897\n3503.650740\n3509.480232\n3493.537322\n3460.942251\n3445.696877\n\n\n2\n753899\n2\nLos Angeles, CA\nmsa\nCA\n2571.296547\n2586.050819\n2604.348963\n2616.104497\n2637.303435\n...\n4073.810818\n4100.234089\n4134.999768\n4148.832674\n4182.522537\n4202.376930\n4230.003153\n4224.038689\n4213.465460\n4209.636932\n\n\n3\n394463\n3\nChicago, IL\nmsa\nIL\n1504.096116\n1510.879827\n1522.416987\n1534.343702\n1547.516576\n...\n2112.639599\n2123.617285\n2145.692631\n2163.843271\n2183.541315\n2196.506806\n2213.427631\n2225.237153\n2225.798038\n2221.960828\n\n\n4\n394514\n4\nDallas, TX\nmsa\nTX\n1363.557414\n1371.136919\n1381.114797\n1394.643185\n1408.025840\n...\n2222.442779\n2229.474165\n2239.462332\n2253.004851\n2267.408242\n2280.056798\n2285.063932\n2284.569053\n2274.785931\n2277.403767\n\n\n\n\n5 rows × 112 columns\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\nRegionID\nSizeRank\nRegionName\nRegionType\nStateName\n1/31/15\n2/28/15\n3/31/15\n4/30/15\n5/31/15\n...\n2/28/23\n3/31/23\n4/30/23\n5/31/23\n6/30/23\n7/31/23\n8/31/23\n9/30/23\n10/31/23\n11/30/23\n\n\n\n\n467\n753871\n811\nBreckenridge, CO\nmsa\nCO\nNaN\nNaN\nNaN\nNaN\nNaN\n...\n3848.649613\n4327.112762\n4414.482838\n4438.619592\n4535.664564\n4599.237795\n4558.170264\n4667.043338\n4671.081209\n4472.222222\n\n\n468\n394751\n821\nKirksville, MO\nmsa\nMO\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1000.733430\n981.701456\n951.458333\n\n\n469\n753923\n849\nThe Dalles, OR\nmsa\nOR\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1757.739178\n1788.943167\n1885.904065\n1838.888889\n\n\n470\n394584\n863\nFallon, NV\nmsa\nNV\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1295.000000\n\n\n471\n394996\n915\nPortales, NM\nmsa\nNM\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\n1122.195307\n1101.628147\n1057.654564\n1071.572024\n1046.671512\n1099.305556\n\n\n\n\n5 rows × 112 columns\n\n\n\n\n\n\ndf.dtypes\n\nRegionID        int64\nSizeRank        int64\nRegionName     object\nRegionType     object\nStateName      object\n               ...   \n7/31/23       float64\n8/31/23       float64\n9/30/23       float64\n10/31/23      float64\n11/30/23      float64\nLength: 112, dtype: object\n\n\n\n\n\ndf.describe()\n\n\n\n\n\n\n\n\nRegionID\nSizeRank\n1/31/15\n2/28/15\n3/31/15\n4/30/15\n5/31/15\n6/30/15\n7/31/15\n8/31/15\n...\n2/28/23\n3/31/23\n4/30/23\n5/31/23\n6/30/23\n7/31/23\n8/31/23\n9/30/23\n10/31/23\n11/30/23\n\n\n\n\ncount\n472.000000\n472.000000\n170.000000\n173.000000\n177.000000\n179.000000\n179.000000\n178.000000\n179.000000\n180.000000\n...\n346.000000\n361.000000\n372.000000\n384.000000\n406.000000\n411.000000\n415.000000\n425.000000\n445.000000\n472.000000\n\n\nmean\n415298.207627\n273.686441\n1239.825620\n1240.669841\n1251.146830\n1266.885696\n1276.013223\n1284.256611\n1290.350280\n1291.137595\n...\n1903.384062\n1898.742328\n1908.427805\n1906.267933\n1886.896644\n1892.888767\n1897.265795\n1891.438391\n1877.721153\n1851.628367\n\n\nstd\n89315.652491\n192.924182\n413.889910\n413.782914\n417.808376\n430.279161\n436.704575\n443.645583\n446.426265\n448.112021\n...\n1004.878275\n984.054607\n993.950964\n981.101384\n943.047137\n925.105623\n936.407031\n974.805502\n973.269750\n935.988332\n\n\nmin\n102001.000000\n0.000000\n618.854999\n621.850858\n634.040448\n633.276802\n623.165150\n624.515366\n625.812267\n645.063429\n...\n675.528618\n753.200396\n723.441350\n745.512901\n748.650235\n727.708028\n724.647895\n726.496330\n743.350970\n752.666667\n\n\n25%\n394560.500000\n118.750000\n982.245085\n986.598979\n993.390743\n998.496778\n999.149213\n999.166349\n1002.455958\n1006.227359\n...\n1411.767065\n1409.322755\n1426.260589\n1418.156725\n1410.428037\n1418.889164\n1417.539001\n1414.537646\n1406.329003\n1397.858135\n\n\n50%\n394805.500000\n241.500000\n1119.640946\n1128.291306\n1140.587934\n1149.357569\n1154.063529\n1160.902744\n1167.827881\n1173.401059\n...\n1725.072590\n1707.075023\n1707.509644\n1701.364516\n1700.414955\n1706.087275\n1716.116918\n1708.640942\n1696.614785\n1675.149130\n\n\n75%\n395063.500000\n393.250000\n1338.069919\n1342.565444\n1365.299281\n1379.799386\n1396.227619\n1395.909341\n1407.885537\n1406.385945\n...\n2153.244218\n2139.535628\n2167.521817\n2157.862768\n2130.928236\n2153.958642\n2174.036097\n2151.869189\n2148.939168\n2118.656793\n\n\nmax\n845167.000000\n915.000000\n3079.176287\n3096.936684\n3120.952116\n3176.462957\n3249.296472\n3318.678095\n3347.010915\n3354.373564\n...\n15718.660650\n15404.494040\n15781.904020\n15583.894210\n14849.608200\n14344.093470\n14754.112810\n16015.296260\n16415.672810\n15918.888890\n\n\n\n\n8 rows × 109 columns\n\n\n\n\n\nWe can also extract specific summary stats\n\nmin_value = df['11/30/23'].min()\nmax_value = df['11/30/23'].max()\nmean_value = df['11/30/23'].mean()\nmed_value = df['11/30/23'].median()\nstd_value = df['11/30/23'].std()\ncount_value = df['11/30/23'].count()\n\n\n\nmin: 752.6666667\nmax: 15918.88889\nmean: 1851.6283666211866\nmedian: 1675.1491305\nst. dev: 935.9883320322535\nN: 472\n\n\n\n\n\npd.unique(df['StateName'])\n\narray([nan, 'NY', 'CA', 'IL', 'TX', 'VA', 'PA', 'FL', 'GA', 'MA', 'AZ',\n       'MI', 'WA', 'MN', 'CO', 'MD', 'MO', 'NC', 'OR', 'OH', 'NV', 'IN',\n       'TN', 'RI', 'WI', 'OK', 'KY', 'LA', 'UT', 'CT', 'AL', 'HI', 'NE',\n       'SC', 'NM', 'ID', 'AR', 'IA', 'KS', 'MS', 'ME', 'NH', 'DE', 'AK',\n       'NJ', 'SD', 'WV', 'ND', 'VT', 'MT', 'WY'], dtype=object)"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#melting",
    "href": "slides/03-numpy-pandas.html#melting",
    "title": "Intro to Numpy + Pandas",
    "section": "Melting",
    "text": "Melting\nJumping ahead slightly…\n\ndf2 = df.melt(id_vars = df.columns[0:5], var_name = \"date\", value_name = \"avg_price\")\ndf2.head()\n\n\n\n\n\n\n\n\nRegionID\nSizeRank\nRegionName\nRegionType\nStateName\ndate\navg_price\n\n\n\n\n0\n102001\n0\nUnited States\ncountry\nNaN\n1/31/15\n1266.059583\n\n\n1\n394913\n1\nNew York, NY\nmsa\nNY\n1/31/15\n2233.133615\n\n\n2\n753899\n2\nLos Angeles, CA\nmsa\nCA\n1/31/15\n2571.296547\n\n\n3\n394463\n3\nChicago, IL\nmsa\nIL\n1/31/15\n1504.096116\n\n\n4\n394514\n4\nDallas, TX\nmsa\nTX\n1/31/15\n1363.557414"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#convert-to-datetime",
    "href": "slides/03-numpy-pandas.html#convert-to-datetime",
    "title": "Intro to Numpy + Pandas",
    "section": "Convert to datetime",
    "text": "Convert to datetime\n\ndf2['date'] = pd.to_datetime(df2['date'])\ndf2.head()\n\n\n\n\n\n\n\n\nRegionID\nSizeRank\nRegionName\nRegionType\nStateName\ndate\navg_price\n\n\n\n\n0\n102001\n0\nUnited States\ncountry\nNaN\n2015-01-31\n1266.059583\n\n\n1\n394913\n1\nNew York, NY\nmsa\nNY\n2015-01-31\n2233.133615\n\n\n2\n753899\n2\nLos Angeles, CA\nmsa\nCA\n2015-01-31\n2571.296547\n\n\n3\n394463\n3\nChicago, IL\nmsa\nIL\n2015-01-31\n1504.096116\n\n\n4\n394514\n4\nDallas, TX\nmsa\nTX\n2015-01-31\n1363.557414"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#group-data",
    "href": "slides/03-numpy-pandas.html#group-data",
    "title": "Intro to Numpy + Pandas",
    "section": "Group data",
    "text": "Group data\n\ngrouped_df = df2.groupby('StateName')\nprint(type(grouped_df))\n\n&lt;class 'pandas.core.groupby.generic.DataFrameGroupBy'&gt;"
  },
  {
    "objectID": "slides/03-numpy-pandas.html#grouped-statistics",
    "href": "slides/03-numpy-pandas.html#grouped-statistics",
    "title": "Intro to Numpy + Pandas",
    "section": "Grouped statistics",
    "text": "Grouped statistics\n\nDescribeSingle stat\n\n\n\n# Summary statistics for all numeric columns by sex\ngrouped_df.describe()\n\n\n\n\n\n\n\n\nRegionID\nSizeRank\n...\ndate\navg_price\n\n\n\ncount\nmean\nmin\n25%\n50%\n75%\nmax\nstd\ncount\nmean\n...\nmax\nstd\ncount\nmean\nmin\n25%\n50%\n75%\nmax\nstd\n\n\nStateName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAK\n214.0\n394453.500000\n394327.0\n394327.00\n394453.5\n394580.00\n394580.0\n126.796601\n214.0\n273.000000\n...\n2023-11-30 00:00:00\nNaN\n118.0\n1845.229913\n1634.802345\n1709.827198\n1751.882085\n1959.080017\n2281.395586\n180.825268\n\n\nAL\n1605.0\n448643.533333\n394333.0\n394519.00\n394598.0\n395145.00\n845163.0\n138679.865228\n1605.0\n296.066667\n...\n2023-11-30 00:00:00\nNaN\n837.0\n1196.697249\n830.963294\n971.353373\n1190.838894\n1347.038333\n2032.164480\n254.603330\n\n\nAR\n749.0\n394790.428571\n394590.0\n394609.00\n394728.0\n395042.00\n395077.0\n182.464426\n749.0\n285.142857\n...\n2023-11-30 00:00:00\nNaN\n354.0\n1095.547769\n726.685275\n940.461179\n1068.180400\n1253.028677\n1697.220290\n228.390724\n\n\nAZ\n856.0\n451262.875000\n394595.0\n394923.25\n395096.5\n395187.00\n845160.0\n148966.294950\n856.0\n214.375000\n...\n2023-11-30 00:00:00\nNaN\n502.0\n1557.286231\n975.778114\n1239.202922\n1468.813304\n1825.604726\n2729.174782\n413.841467\n\n\nCA\n3424.0\n428576.656250\n394357.0\n394841.75\n395047.5\n395142.00\n753920.0\n104654.375661\n3424.0\n191.437500\n...\n2023-11-30 00:00:00\nNaN\n2262.0\n2472.280505\n1056.267157\n1832.396777\n2412.471519\n3015.948801\n5280.032047\n801.072889\n\n\nCO\n1284.0\n454493.666667\n394405.0\n394518.50\n394620.5\n394908.75\n753881.0\n133940.119391\n1284.0\n348.833333\n...\n2023-11-30 00:00:00\nNaN\n716.0\n2346.684403\n1058.116385\n1596.669792\n1904.408666\n2271.895581\n16415.672810\n2257.370863\n\n\nCT\n535.0\n394815.600000\n394415.0\n394669.00\n394908.0\n394924.00\n395162.0\n254.108902\n535.0\n119.600000\n...\n2023-11-30 00:00:00\nNaN\n433.0\n2127.777496\n1231.613286\n1599.540968\n1837.233176\n2604.887072\n4416.410828\n748.713311\n\n\nDE\n214.0\n394795.000000\n394539.0\n394539.00\n394795.0\n395051.00\n395051.0\n256.600235\n214.0\n189.000000\n...\n2023-11-30 00:00:00\nNaN\n127.0\n1571.385754\n1258.289127\n1340.570246\n1469.069826\n1812.232209\n2085.191980\n258.317915\n\n\nFL\n2568.0\n424798.708333\n394440.0\n394759.00\n394950.0\n395079.25\n753906.0\n99244.412111\n2568.0\n174.916667\n...\n2023-11-30 00:00:00\nNaN\n2122.0\n1668.835798\n885.529271\n1273.651277\n1522.096523\n1936.250181\n4340.326552\n550.513435\n\n\nGA\n2033.0\n413673.210526\n394306.0\n394423.00\n394813.0\n395126.00\n753893.0\n80210.928282\n2033.0\n326.421053\n...\n2023-11-30 00:00:00\nNaN\n1129.0\n1256.099519\n624.240075\n971.108002\n1184.687231\n1465.110193\n2238.706120\n375.740443\n\n\nHI\n321.0\n514445.000000\n394680.0\n394680.00\n394731.0\n753924.00\n753924.0\n169601.609159\n321.0\n183.666667\n...\n2023-11-30 00:00:00\nNaN\n132.0\n2705.681385\n1941.739389\n2376.900621\n2535.854344\n2903.391210\n4534.504002\n591.932689\n\n\nIA\n749.0\n394623.571429\n394325.0\n394447.00\n394542.0\n394707.00\n395210.0\n263.893527\n749.0\n320.714286\n...\n2023-11-30 00:00:00\nNaN\n413.0\n1343.504147\n924.635859\n1096.610185\n1226.942363\n1525.647707\n2304.133291\n346.240757\n\n\nID\n749.0\n446097.000000\n394399.0\n394480.00\n394988.0\n395173.00\n753916.0\n125750.835880\n749.0\n363.142857\n...\n2023-11-30 00:00:00\nNaN\n289.0\n1576.334430\n995.965187\n1281.801032\n1520.317263\n1750.688649\n2458.333333\n374.149199\n\n\nIL\n1177.0\n468306.000000\n394454.0\n394516.00\n394734.0\n395114.00\n845167.0\n157410.509968\n1177.0\n239.636364\n...\n2023-11-30 00:00:00\nNaN\n629.0\n1220.872101\n645.511180\n1003.992490\n1133.110230\n1406.751015\n2225.798038\n331.832737\n\n\nIN\n1391.0\n422359.384615\n394393.0\n394565.00\n394705.0\n395021.00\n753895.0\n95740.797170\n1391.0\n299.538462\n...\n2023-11-30 00:00:00\nNaN\n730.0\n1105.728925\n643.993545\n831.024770\n1045.852512\n1317.120042\n2085.765612\n324.831936\n\n\nKS\n749.0\n394959.285714\n394701.0\n394778.00\n394981.0\n395161.00\n395224.0\n184.506905\n749.0\n390.571429\n...\n2023-11-30 00:00:00\nNaN\n423.0\n1100.784587\n680.241603\n869.782224\n1063.870894\n1245.758531\n1927.089567\n299.129530\n\n\nKY\n749.0\n394736.285714\n394406.0\n394563.00\n394792.0\n394949.00\n395023.0\n203.545232\n749.0\n267.857143\n...\n2023-11-30 00:00:00\nNaN\n272.0\n1201.673804\n915.665260\n1061.281701\n1172.542508\n1322.833020\n1628.296815\n170.093385\n\n\nLA\n1177.0\n394735.090909\n394314.0\n394608.00\n394761.0\n394910.00\n395096.0\n236.021094\n1177.0\n260.545455\n...\n2023-11-30 00:00:00\nNaN\n558.0\n1263.411616\n897.251299\n1101.569579\n1279.399917\n1393.830133\n1839.146198\n218.119976\n\n\nMA\n428.0\n394779.500000\n394361.0\n394393.25\n394759.5\n395145.75\n395238.0\n400.131638\n428.0\n88.750000\n...\n2023-11-30 00:00:00\nNaN\n274.0\n2246.404623\n1471.260619\n1762.759314\n2264.264095\n2598.178490\n3533.185405\n522.650962\n\n\nMD\n428.0\n484350.750000\n394358.0\n394474.25\n394586.5\n484463.00\n753872.0\n155790.307335\n428.0\n240.000000\n...\n2023-11-30 00:00:00\nNaN\n247.0\n1552.644194\n880.592353\n1210.839158\n1589.107929\n1754.226876\n2184.235363\n315.788335\n\n\nME\n214.0\n394678.000000\n394359.0\n394359.00\n394678.0\n394997.00\n394997.0\n319.747949\n214.0\n196.500000\n...\n2023-11-30 00:00:00\nNaN\n78.0\n2134.470922\n1547.912828\n1834.919379\n2041.777850\n2482.006422\n2775.031672\n378.392726\n\n\nMI\n1712.0\n417161.437500\n394302.0\n394580.00\n394751.0\n394901.25\n753890.0\n86968.672381\n1712.0\n247.875000\n...\n2023-11-30 00:00:00\nNaN\n704.0\n1444.416460\n618.854999\n997.830541\n1227.899830\n1599.409474\n3644.308459\n684.450686\n\n\nMN\n642.0\n394836.000000\n394543.0\n394637.00\n394844.0\n395030.00\n395118.0\n201.659805\n642.0\n231.166667\n...\n2023-11-30 00:00:00\nNaN\n310.0\n1588.607379\n1197.459955\n1375.809178\n1548.545456\n1733.734201\n2231.628451\n247.955226\n\n\nMO\n1498.0\n394825.571429\n394411.0\n394604.00\n394743.0\n395116.00\n395204.0\n271.321557\n1498.0\n396.000000\n...\n2023-11-30 00:00:00\nNaN\n509.0\n1122.500158\n762.926459\n1000.200109\n1092.990495\n1252.354572\n1547.110695\n188.219653\n\n\nMS\n642.0\n394880.833333\n394658.0\n394671.00\n394831.0\n395124.00\n395170.0\n212.375595\n642.0\n308.000000\n...\n2023-11-30 00:00:00\nNaN\n225.0\n1192.876828\n937.793923\n1068.174125\n1144.629497\n1317.754833\n2279.597698\n195.298729\n\n\nMT\n642.0\n394577.833333\n394386.0\n394407.00\n394537.0\n394733.00\n394867.0\n182.675809\n642.0\n421.666667\n...\n2023-11-30 00:00:00\nNaN\n177.0\n1793.224137\n1094.019889\n1216.021805\n1627.453364\n2329.398684\n3136.530533\n591.359944\n\n\nNC\n2354.0\n411102.045455\n394338.0\n394562.00\n394697.5\n395063.00\n753912.0\n74823.677625\n2354.0\n274.500000\n...\n2023-11-30 00:00:00\nNaN\n1286.0\n1366.269717\n846.562543\n1106.111669\n1331.843142\n1556.471201\n2288.942284\n324.147384\n\n\nND\n321.0\n394892.666667\n394585.0\n394585.00\n394866.0\n395227.00\n395227.0\n263.183083\n321.0\n455.666667\n...\n2023-11-30 00:00:00\nNaN\n22.0\n1651.132776\n1395.000000\n1519.067443\n1712.143286\n1755.955326\n1808.444444\n132.405607\n\n\nNE\n428.0\n394817.750000\n394617.0\n394751.25\n394858.0\n394924.50\n394938.0\n128.299053\n428.0\n425.000000\n...\n2023-11-30 00:00:00\nNaN\n216.0\n1320.009482\n940.764327\n1186.933246\n1262.477897\n1451.544329\n1754.718239\n189.568181\n\n\nNH\n214.0\n619992.000000\n394820.0\n394820.00\n619992.0\n845164.00\n845164.0\n225699.953831\n214.0\n171.000000\n...\n2023-11-30 00:00:00\nNaN\n22.0\n2582.894543\n2325.537810\n2480.164956\n2562.927550\n2709.069839\n2791.183412\n139.749875\n\n\nNJ\n214.0\n394756.000000\n394348.0\n394348.00\n394756.0\n395164.00\n395164.0\n408.956625\n214.0\n161.000000\n...\n2023-11-30 00:00:00\nNaN\n214.0\n1693.799261\n1108.055046\n1402.009299\n1642.693619\n1931.930719\n2543.122507\n353.021462\n\n\nNM\n963.0\n394666.777778\n394305.0\n394443.00\n394588.0\n394996.00\n395066.0\n292.082726\n963.0\n440.444444\n...\n2023-11-30 00:00:00\nNaN\n314.0\n1472.158264\n987.763290\n1157.028714\n1301.372585\n1634.597233\n2925.870370\n453.840507\n\n\nNV\n642.0\n394673.666667\n394444.0\n394584.00\n394610.0\n394775.00\n395019.0\n182.289096\n642.0\n452.833333\n...\n2023-11-30 00:00:00\nNaN\n264.0\n1784.668225\n1212.685378\n1484.060443\n1755.211957\n2081.924961\n2817.571625\n370.648528\n\n\nNY\n1070.0\n439881.200000\n394308.0\n394693.00\n394972.0\n395179.00\n845159.0\n135156.094569\n1070.0\n163.300000\n...\n2023-11-30 00:00:00\nNaN\n641.0\n1790.942113\n997.328276\n1343.320969\n1602.835366\n2157.428456\n3509.480232\n596.847035\n\n\nOH\n1284.0\n432299.833333\n394304.0\n394472.75\n394760.5\n395175.25\n845158.0\n124530.356368\n1284.0\n141.750000\n...\n2023-11-30 00:00:00\nNaN\n923.0\n1046.700170\n680.642040\n839.625107\n987.004712\n1188.448704\n1947.044776\n265.814765\n\n\nOK\n1177.0\n394820.000000\n394300.0\n394548.00\n394935.0\n395133.00\n395169.0\n309.974483\n1177.0\n465.454545\n...\n2023-11-30 00:00:00\nNaN\n410.0\n1062.128302\n758.667864\n973.232481\n1038.672842\n1176.785601\n1458.135575\n182.618956\n\n\nOR\n1498.0\n471653.571429\n394307.0\n394505.00\n394800.0\n395048.00\n753923.0\n147450.415722\n1498.0\n379.928571\n...\n2023-11-30 00:00:00\nNaN\n600.0\n1781.272373\n1052.830183\n1532.939293\n1757.701867\n1985.272415\n2611.379315\n360.962236\n\n\nPA\n2033.0\n394875.421053\n394318.0\n394666.00\n394974.0\n395106.00\n395244.0\n262.799913\n2033.0\n224.368421\n...\n2023-11-30 00:00:00\nNaN\n875.0\n1347.330330\n789.815931\n1149.120217\n1306.885412\n1518.000385\n2094.027778\n277.309547\n\n\nRI\n107.0\n395005.000000\n395005.0\n395005.00\n395005.0\n395005.00\n395005.0\n0.000000\n107.0\n39.000000\n...\n2023-11-30 00:00:00\nNaN\n107.0\n2118.407898\n1598.141501\n1805.755429\n2012.306431\n2439.407877\n2912.998572\n389.954589\n\n\nSC\n1070.0\n394772.600000\n394457.0\n394597.00\n394667.0\n395085.00\n395139.0\n248.911116\n1070.0\n225.800000\n...\n2023-11-30 00:00:00\nNaN\n743.0\n1396.031749\n853.147291\n1118.728682\n1338.169915\n1577.549159\n2620.224277\n357.345479\n\n\nSD\n321.0\n394845.000000\n394419.0\n394419.00\n395013.0\n395103.00\n395103.0\n303.933833\n321.0\n424.333333\n...\n2023-11-30 00:00:00\nNaN\n106.0\n1384.547508\n1049.505973\n1162.543829\n1311.456545\n1602.649611\n1872.468058\n230.479838\n\n\nTN\n1177.0\n394705.181818\n394460.0\n394474.00\n394726.0\n394849.00\n395168.0\n211.301360\n1177.0\n192.636364\n...\n2023-11-30 00:00:00\nNaN\n667.0\n1371.017577\n935.476460\n1104.347806\n1363.832948\n1532.375111\n2270.663942\n298.293853\n\n\nTX\n3317.0\n409264.806452\n394299.0\n394502.00\n394746.0\n395054.00\n845162.0\n79596.074231\n3317.0\n259.967742\n...\n2023-11-30 00:00:00\nNaN\n2088.0\n1438.496827\n765.245138\n1152.171443\n1396.188630\n1668.594537\n2474.220726\n357.363631\n\n\nUT\n856.0\n394902.000000\n394446.0\n394768.50\n394968.5\n395069.50\n395187.0\n232.809618\n856.0\n320.750000\n...\n2023-11-30 00:00:00\nNaN\n458.0\n1711.807021\n1109.188006\n1408.681922\n1591.513180\n1930.749340\n4311.466765\n506.007518\n\n\nVA\n1070.0\n394914.300000\n394392.0\n394668.00\n395025.0\n395194.00\n395232.0\n298.071878\n1070.0\n188.400000\n...\n2023-11-30 00:00:00\nNaN\n851.0\n1536.584520\n782.641195\n1268.882352\n1451.721042\n1780.951306\n2880.797205\n441.327399\n\n\nVT\n107.0\n394429.000000\n394429.0\n394429.00\n394429.0\n394429.00\n394429.0\n0.000000\n107.0\n206.000000\n...\n2023-11-30 00:00:00\nNaN\n11.0\n2900.941104\n2639.431318\n2837.553193\n2958.561667\n2986.743498\n3027.025463\n125.568309\n\n\nWA\n1605.0\n394891.866667\n394378.0\n394741.00\n394925.0\n395113.00\n395240.0\n264.588738\n1605.0\n303.733333\n...\n2023-11-30 00:00:00\nNaN\n844.0\n1852.587674\n1025.907447\n1514.166912\n1812.799384\n2157.861092\n3104.024269\n428.180994\n\n\nWI\n1177.0\n394791.727273\n394334.0\n394646.00\n394816.0\n394944.00\n395215.0\n224.222302\n1177.0\n247.727273\n...\n2023-11-30 00:00:00\nNaN\n323.0\n1514.551976\n907.936037\n1130.945896\n1419.831933\n1827.497187\n2671.202919\n434.493367\n\n\nWV\n321.0\n394601.000000\n394455.0\n394455.00\n394469.0\n394879.00\n394879.0\n196.965797\n321.0\n306.666667\n...\n2023-11-30 00:00:00\nNaN\n123.0\n1340.545489\n905.843432\n1095.441407\n1383.271660\n1485.772036\n1751.850634\n245.916508\n\n\nWY\n321.0\n394512.666667\n394445.0\n394445.00\n394462.0\n394631.00\n394631.0\n84.092719\n321.0\n458.666667\n...\n2023-11-30 00:00:00\nNaN\n92.0\n1386.686876\n1182.758469\n1252.376297\n1359.626203\n1525.037930\n1678.124614\n157.596041\n\n\n\n\n50 rows × 32 columns\n\n\n\n\n\n\n# Provide the mean for each numeric column by sex\ngrouped_df.mean(numeric_only = True)\n\n\n\n\n\n\n\n\nRegionID\nSizeRank\navg_price\n\n\nStateName\n\n\n\n\n\n\n\nAK\n394453.500000\n273.000000\n1845.229913\n\n\nAL\n448643.533333\n296.066667\n1196.697249\n\n\nAR\n394790.428571\n285.142857\n1095.547769\n\n\nAZ\n451262.875000\n214.375000\n1557.286231\n\n\nCA\n428576.656250\n191.437500\n2472.280505\n\n\nCO\n454493.666667\n348.833333\n2346.684403\n\n\nCT\n394815.600000\n119.600000\n2127.777496\n\n\nDE\n394795.000000\n189.000000\n1571.385754\n\n\nFL\n424798.708333\n174.916667\n1668.835798\n\n\nGA\n413673.210526\n326.421053\n1256.099519\n\n\nHI\n514445.000000\n183.666667\n2705.681385\n\n\nIA\n394623.571429\n320.714286\n1343.504147\n\n\nID\n446097.000000\n363.142857\n1576.334430\n\n\nIL\n468306.000000\n239.636364\n1220.872101\n\n\nIN\n422359.384615\n299.538462\n1105.728925\n\n\nKS\n394959.285714\n390.571429\n1100.784587\n\n\nKY\n394736.285714\n267.857143\n1201.673804\n\n\nLA\n394735.090909\n260.545455\n1263.411616\n\n\nMA\n394779.500000\n88.750000\n2246.404623\n\n\nMD\n484350.750000\n240.000000\n1552.644194\n\n\nME\n394678.000000\n196.500000\n2134.470922\n\n\nMI\n417161.437500\n247.875000\n1444.416460\n\n\nMN\n394836.000000\n231.166667\n1588.607379\n\n\nMO\n394825.571429\n396.000000\n1122.500158\n\n\nMS\n394880.833333\n308.000000\n1192.876828\n\n\nMT\n394577.833333\n421.666667\n1793.224137\n\n\nNC\n411102.045455\n274.500000\n1366.269717\n\n\nND\n394892.666667\n455.666667\n1651.132776\n\n\nNE\n394817.750000\n425.000000\n1320.009482\n\n\nNH\n619992.000000\n171.000000\n2582.894543\n\n\nNJ\n394756.000000\n161.000000\n1693.799261\n\n\nNM\n394666.777778\n440.444444\n1472.158264\n\n\nNV\n394673.666667\n452.833333\n1784.668225\n\n\nNY\n439881.200000\n163.300000\n1790.942113\n\n\nOH\n432299.833333\n141.750000\n1046.700170\n\n\nOK\n394820.000000\n465.454545\n1062.128302\n\n\nOR\n471653.571429\n379.928571\n1781.272373\n\n\nPA\n394875.421053\n224.368421\n1347.330330\n\n\nRI\n395005.000000\n39.000000\n2118.407898\n\n\nSC\n394772.600000\n225.800000\n1396.031749\n\n\nSD\n394845.000000\n424.333333\n1384.547508\n\n\nTN\n394705.181818\n192.636364\n1371.017577\n\n\nTX\n409264.806452\n259.967742\n1438.496827\n\n\nUT\n394902.000000\n320.750000\n1711.807021\n\n\nVA\n394914.300000\n188.400000\n1536.584520\n\n\nVT\n394429.000000\n206.000000\n2900.941104\n\n\nWA\n394891.866667\n303.733333\n1852.587674\n\n\nWI\n394791.727273\n247.727273\n1514.551976\n\n\nWV\n394601.000000\n306.666667\n1340.545489\n\n\nWY\n394512.666667\n458.666667\n1386.686876"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#announcements",
    "href": "slides/01-meet-the-toolkit.html#announcements",
    "title": "Meet the toolkit",
    "section": "Announcements",
    "text": "Announcements\n\nIf you have not yet completed the Getting to know you survey, please do so asap!\nIf you have not yet accepted the invite to join the course GitHub Organization, please do so asap!\nOffice hours linked at https://datasciaz.netlify.app/course-team.html"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#course-homepage",
    "href": "slides/01-meet-the-toolkit.html#course-homepage",
    "title": "Meet the toolkit",
    "section": "Course homepage",
    "text": "Course homepage\nLet’s take a tour!"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#collaboration-policy",
    "href": "slides/01-meet-the-toolkit.html#collaboration-policy",
    "title": "Meet the toolkit",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\nOnly work that is clearly assigned as team work should be completed collaboratively.\nHomeworks must be completed individually. You may not directly share answers / code with others, however you are welcome to discuss the problems in general and ask for advice.\nExams must be completed individually. You may not discuss any aspect of the exam with peers. If you have questions, post as private questions on the course forum, only the teaching team will see and answer."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#sharing-reusing-code-policy",
    "href": "slides/01-meet-the-toolkit.html#sharing-reusing-code-policy",
    "title": "Meet the toolkit",
    "section": "Sharing / reusing code policy",
    "text": "Sharing / reusing code policy\n\nWe are aware that a huge volume of code is available on the web, and many tasks may have solutions posted\nUnless explicitly stated otherwise, this course’s policy is that you may make use of any online resources (e.g. RStudio Community, StackOverflow, etc.) but you must explicitly cite where you obtained any code you directly use or use as inspiration in your solution(s).\nAny recycled code that is discovered and is not explicitly cited will be treated as plagiarism, regardless of source"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#use-of-generative-ai",
    "href": "slides/01-meet-the-toolkit.html#use-of-generative-ai",
    "title": "Meet the toolkit",
    "section": "Use of generative AI",
    "text": "Use of generative AI\n\nTreat generative AI, such as ChatGPT, as an online resource.\nGuiding principles:\n\n(1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning.\n(2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n✅ AI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code.\n❌ AI tools for narrative: Unless instructed, you may not use generative AI to write narrative on assignments. You may use generative AI as a resource as you complete assignments but not for answers."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#academic-integrity",
    "href": "slides/01-meet-the-toolkit.html#academic-integrity",
    "title": "Meet the toolkit",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the UArizona iSchool Community Standard:\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#most-importantly",
    "href": "slides/01-meet-the-toolkit.html#most-importantly",
    "title": "Meet the toolkit",
    "section": "Most importantly!",
    "text": "Most importantly!\nAsk if you’re not sure if something violates a policy!"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#five-tips-for-success",
    "href": "slides/01-meet-the-toolkit.html#five-tips-for-success",
    "title": "Meet the toolkit",
    "section": "Five tips for success",
    "text": "Five tips for success\n\nComplete all the preparation work before class.\nAsk questions.\nDo the readings.\nDo the lab.\nDon’t procrastinate – at least on a weekly basis!"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#course-toolkit-1",
    "href": "slides/01-meet-the-toolkit.html#course-toolkit-1",
    "title": "Meet the toolkit",
    "section": "Course toolkit",
    "text": "Course toolkit\n\n\nCourse operation\n\nMaterials: datasciaz.netlify.app\nSubmission: GitHub\nDiscussion: Slack\nGradebook: D2L\n\n\nDoing data science\n\nComputing:\n\nPython\nVS Code\nQuarto/Jupyter\n\nVersion control and collaboration:\n\nGit\nGitHub"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#learning-goals",
    "href": "slides/01-meet-the-toolkit.html#learning-goals",
    "title": "Meet the toolkit",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the course, you will be able to…\n\n\ngain insight from data\ngain insight from data, reproducibly\ngain insight from data, reproducibly, using modern programming tools and techniques\ngain insight from data, reproducibly and collaboratively, using modern programming tools and techniques\ngain insight from data, reproducibly (with literate programming and version control) and collaboratively, using modern programming tools and techniques"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#reproducibility-checklist",
    "href": "slides/01-meet-the-toolkit.html#reproducibility-checklist",
    "title": "Meet the toolkit",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for a data analysis to be “reproducible”?\n\n\nShort-term goals:\n\nAre the tables and figures reproducible from the code and data?\nDoes the code actually do what you think it does?\nIn addition to what was done, is it clear why it was done?\n\n\n\nLong-term goals:\n\nCan the code be used for other data?\nCan you extend the code to do other things?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#toolkit-for-reproducibility",
    "href": "slides/01-meet-the-toolkit.html#toolkit-for-reproducibility",
    "title": "Meet the toolkit",
    "section": "Toolkit for reproducibility",
    "text": "Toolkit for reproducibility\n\nScriptability \\(\\rightarrow\\) Python\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto/Jupyter\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#python-and-jupyter-1",
    "href": "slides/01-meet-the-toolkit.html#python-and-jupyter-1",
    "title": "Meet the toolkit",
    "section": "Python and Jupyter",
    "text": "Python and Jupyter\n\n\n\n\n\n\n\n\nPython is an open-source general purpose programming language\nPython is also an environment for statistical computing and graphics\nIt’s easily extensible with packages\n\n\n\n\n\n\n\n\nJupyter is a convenient interface for Python called an IDE (integrated development environment), e.g. “I write Python code in the Jupyter IDE”\n\n\n\nJupyter is not a requirement for programming with Python, but it’s very commonly used by Python programmers and data scientists"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#python-vs.-jupyter",
    "href": "slides/01-meet-the-toolkit.html#python-vs.-jupyter",
    "title": "Meet the toolkit",
    "section": "Python vs. Jupyter",
    "text": "Python vs. Jupyter\n\n\n\n\n\n\n\nSource: Modern Dive (modified)."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#python-packages",
    "href": "slides/01-meet-the-toolkit.html#python-packages",
    "title": "Meet the toolkit",
    "section": "Python packages",
    "text": "Python packages\n\n\nPackages: Fundamental units of reproducible Python code, including reusable Python modules/functions, the documentation that describes how to use them, and sample data1\nAs of 23 July 2024, there are 557,005 Python packages (projects) available on PyPI (the Python Package Index)2\nWe’re going to work with a small (but important) subset of these!\n\n\n\n\n1 Beuzen and Timbers, Python Packages.\n2 PyPI contributed packages."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-python-jupyter-via-vs-code",
    "href": "slides/01-meet-the-toolkit.html#tour-python-jupyter-via-vs-code",
    "title": "Meet the toolkit",
    "section": "Tour: Python + Jupyter (via VS Code)",
    "text": "Tour: Python + Jupyter (via VS Code)\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\nOption 2:\nClone the corresponding application exercise repo and follow along.\n ae-01-meet-the-penguins\nGo to the course GitHub organization and clone ae-01-meet-the-penguins to your environment."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-python-jupyter-via-vs-code",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-python-jupyter-via-vs-code",
    "title": "Meet the toolkit",
    "section": "Tour recap: Python + Jupyter (via VS Code)",
    "text": "Tour recap: Python + Jupyter (via VS Code)"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#a-short-list-for-now-of-python-essentials",
    "href": "slides/01-meet-the-toolkit.html#a-short-list-for-now-of-python-essentials",
    "title": "Meet the toolkit",
    "section": "A short list (for now) of Python essentials",
    "text": "A short list (for now) of Python essentials\n\nFunctions are (most often) verbs, followed by what they will be applied to in parentheses:\n\n\nto_this.do_this()\nto_that.do_that(to_this, with_those)\n\n\n\nPackages are installed with the pip install function (via the terminal)…\n\npip install package_name\n\n… and loaded with the import function, once per session (usually with a shorthand “nickname”):\n\n\nimport package_name as pkg"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#python-essentials-continued",
    "href": "slides/01-meet-the-toolkit.html#python-essentials-continued",
    "title": "Meet the toolkit",
    "section": "Python essentials (continued)",
    "text": "Python essentials (continued)\n\nColumns (variables) in data frames are accessed with ['']:\n\n\ndataframe['var_name']\n\n\n\nObject documentation can be accessed with help()\n\n\nhelp(pd.Series.mean)"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#pandas",
    "href": "slides/01-meet-the-toolkit.html#pandas",
    "title": "Meet the toolkit",
    "section": "pandas",
    "text": "pandas\n\npandas.pydata.org\n\nPandas is a quintessential package designed for data analysis"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#jupyter-notebooks-1",
    "href": "slides/01-meet-the-toolkit.html#jupyter-notebooks-1",
    "title": "Meet the toolkit",
    "section": "Jupyter Notebooks",
    "text": "Jupyter Notebooks\n\n\nFully reproducible reports – each time you run the analysis is ran from the beginning\nCode goes in code chunks narrative goes in markdown chunks\nA visual editor for a familiar / Google docs-like editing experience"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-jupyter-notebooks",
    "href": "slides/01-meet-the-toolkit.html#tour-jupyter-notebooks",
    "title": "Meet the toolkit",
    "section": "Tour: Jupyter Notebooks",
    "text": "Tour: Jupyter Notebooks\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\nOption 2:\nClone the corresponding application exercise repo and follow along.\n ae-01-meet-the-penguins\nGo to the course GitHub organization and clone ae-01-meet-the-penguins to your environment."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-jupyter-notebooks",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-jupyter-notebooks",
    "title": "Meet the toolkit",
    "section": "Tour recap: Jupyter Notebooks",
    "text": "Tour recap: Jupyter Notebooks"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-jupyter-notebooks",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-jupyter-notebooks",
    "title": "Meet the toolkit",
    "section": "How will we use Jupyter Notebooks?",
    "text": "How will we use Jupyter Notebooks?\n\nEvery application exercise, lab, project, etc. is a Jupyter notebook\n\nHowever, projects will be built with Quarto Websites (more later)\n\nYou’ll always have a template Jupyter notebook to start with\nThe amount of scaffolding in the template will decrease over the semester\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#linear-algebra-1",
    "href": "slides/22-linear-algebra-I.html#linear-algebra-1",
    "title": "Linear algebra I",
    "section": "Linear algebra",
    "text": "Linear algebra\n\n\n\nLinear algebra is the study of vectors, vector spaces, and linear transformations.\nFundamental to many fields including data science, machine learning, and statistics."
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#vectors-1",
    "href": "slides/22-linear-algebra-I.html#vectors-1",
    "title": "Linear algebra I",
    "section": "Vectors",
    "text": "Vectors\n\nDefinition:\n\n\nVectors are objects that can be added together and multiplied by scalars to form new vectors. In a data science context, vectors are often used to represent numeric data.\n\n\n\n\nExamples:\n\n\nThree-dimensional vector: [height, weight, age] = [70, 170, 40]\nFour-dimensional vector: [exam1, exam2, exam3, exam4] = [95, 80, 75, 62]"
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#vectors-in-python",
    "href": "slides/22-linear-algebra-I.html#vectors-in-python",
    "title": "Linear algebra I",
    "section": "Vectors in Python",
    "text": "Vectors in Python\n\nNumpyVisual\n\n\n\nimport numpy as np\nv = np.array([3, 2])\nprint(v)\n\n[3 2]\n\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nv = np.array([3, 2])\norigin = np.array([0, 0])\n\nplt.quiver(*origin, *v, scale=1, scale_units='xy', angles='xy')\nplt.xlim(0, 4)\nplt.ylim(0, 3)\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#vector-addition",
    "href": "slides/22-linear-algebra-I.html#vector-addition",
    "title": "Linear algebra I",
    "section": "Vector addition",
    "text": "Vector addition\n\nExamplePythonVisual\n\n\n\n\nVectors of the same length can be added or subtracted componentwise.\nExample: \\(\\mathbf{v} = [3,2]\\) and \\(\\mathbf{w}=[2,-1]\\)\nResult: \\(\\mathbf{v}+\\mathbf{w}=[5,1]\\)\n\n\n\n\n\nv = np.array([3, 2])\nw = np.array([2, -1])\nv_plus_w = v + w\nprint(v_plus_w) \n\n[5 1]\n\n\n\n\n\n\nCode\nv = np.array([3, 2])\nw = np.array([2, -1])\nv_plus_w = v + w\n\nplt.quiver(*origin, *v, color='r', scale=1, scale_units='xy', angles='xy')\nplt.quiver(*origin, *w, color='b', scale=1, scale_units='xy', angles='xy')\nplt.quiver(*origin, *v_plus_w, color='g', scale=1, scale_units='xy', angles='xy')\nplt.xlim(0, 6)\nplt.ylim(-2, 3)\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#vector-subtraction",
    "href": "slides/22-linear-algebra-I.html#vector-subtraction",
    "title": "Linear algebra I",
    "section": "Vector subtraction",
    "text": "Vector subtraction\n\nExamplePythonVisual\n\n\n\n\nVectors of the same length can be added or subtracted componentwise.\nExample: \\(\\mathbf{v} = [3,2]\\) and \\(\\mathbf{w}=[2,-1]\\)\nResult: \\(\\mathbf{v}-\\mathbf{w}=[1,3]\\)\n\n\n\n\n\nv = np.array([3, 2])\nw = np.array([2, -1])\nv_plus_w = v - w\nprint(v_plus_w) \n\n[1 3]\n\n\n\n\n\n\nCode\nv = np.array([3, 2])\nw = np.array([2, -1])\nv_plus_w = v - w\n\nplt.quiver(*origin, *v, color='r', scale=1, scale_units='xy', angles='xy')\nplt.quiver(*origin, *w, color='b', scale=1, scale_units='xy', angles='xy')\nplt.quiver(*origin, *v_plus_w, color='g', scale=1, scale_units='xy', angles='xy')\nplt.xlim(0, 6)\nplt.ylim(-2, 3)\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#vector-scaling",
    "href": "slides/22-linear-algebra-I.html#vector-scaling",
    "title": "Linear algebra I",
    "section": "Vector scaling",
    "text": "Vector scaling\n\nExamplePythonVisual\n\n\n\n\nScaling vector \\(\\mathbf{v}=[3,2]\\) by \\(2\\)\nResult: \\([6,4]\\)\n\n\n\n\n\nv = np.array([3, 2])\nscaled_v = 2.0 * v\nprint(scaled_v)\n\n[6. 4.]\n\n\n\n\n\n\nCode\nscaled_v = 2 * v\n\nplt.quiver(*origin, *v, color='r', scale=1, scale_units='xy', angles='xy')\nplt.quiver(*origin, *scaled_v, color='g', scale=1, scale_units='xy', angles='xy', alpha=0.75)\nplt.xlim(0, 7)\nplt.ylim(0, 5)\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#span",
    "href": "slides/22-linear-algebra-I.html#span",
    "title": "Linear algebra I",
    "section": "Span",
    "text": "Span\n\nThe span of a set of vectors \\(\\mathbf{v1},\\mathbf{v2},...,\\mathbf{vn}\\) is the set of all linear combinations of the vectors.\ni.e., all the vectors \\(\\mathbf{b}\\) for which the equation \\([\\mathbf{v1} \\space \\mathbf{v2} \\space... \\space\\mathbf{vn}]\\mathbf{x=b}\\)"
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#linear-independent-vs.-dependent",
    "href": "slides/22-linear-algebra-I.html#linear-independent-vs.-dependent",
    "title": "Linear algebra I",
    "section": "Linear independent vs. dependent",
    "text": "Linear independent vs. dependent\n\nVectors are linearly independent if each vector lies outside the span of the remaining vectors. Otherwise, the vectors are said to be linearly dependent1.\n\n\n\n\n\n\nFor more information, see this nice blog on the topic"
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#linear-independent-vs.-dependent-1",
    "href": "slides/22-linear-algebra-I.html#linear-independent-vs.-dependent-1",
    "title": "Linear algebra I",
    "section": "Linear independent vs. dependent",
    "text": "Linear independent vs. dependent\n\nThe vector on th right can be constructed by any two combination of the other vectors."
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#matrices-1",
    "href": "slides/22-linear-algebra-I.html#matrices-1",
    "title": "Linear algebra I",
    "section": "Matrices",
    "text": "Matrices\n\nDefinitionPython\n\n\n\nMatrices are collections of vectors arranged in rows and columns.\nRepresent linear transformations.\nExample Matrix:\n\n\\[\n\\mathbf{A} = \\begin{bmatrix}3 & 0 \\\\0 & 2 \\end{bmatrix}\n\\]\n\n\n\nA = np.array([[3,0],[0,2]])\nprint(A)\n\n[[3 0]\n [0 2]]"
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#matrix-transposition",
    "href": "slides/22-linear-algebra-I.html#matrix-transposition",
    "title": "Linear algebra I",
    "section": "Matrix transposition",
    "text": "Matrix transposition\n\nMatrix transposition involves swapping the rows and columns.\nNotation: If \\(\\mathbf{A}\\) is a matrix, then its transpose is denoted as \\(\\mathbf{A}^T\\).\nGiven the matrix \\(\\mathbf{A}\\):\n\n\\[\n\\mathbf{A}= \\begin{bmatrix}a_{11} & a_{12} & a_{13}\\\\a_{21} & a_{22} & a_{23}\\\\a_{31} & a_{32} & a_{33}\\end{bmatrix}\n\\]\n\nThe matrix \\(\\mathbf{A}^T\\) is:\n\n\\[\n\\mathbf{A}^T=\\begin{bmatrix}a_{11} & a_{21} & a_{31}\\\\a_{12} & a_{22} & a_{32}\\\\a_{13} & a_{23} & a_{33}\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#matrix-transposition-python",
    "href": "slides/22-linear-algebra-I.html#matrix-transposition-python",
    "title": "Linear algebra I",
    "section": "Matrix transposition: Python",
    "text": "Matrix transposition: Python\n\n\nCode\nimport numpy as np\n\n# Original matrix\nA = np.array([\n    [1, 2, 3],\n    [4, 5, 6],\n    [7, 8, 9]\n])\n\n# Transpose of the matrix\nA_T = A.T\n\nprint(\"Original Matrix:\")\nprint(A)\nprint(\"\\nTransposed Matrix:\")\nprint(A_T)\n\n\nOriginal Matrix:\n[[1 2 3]\n [4 5 6]\n [7 8 9]]\n\nTransposed Matrix:\n[[1 4 7]\n [2 5 8]\n [3 6 9]]"
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#matrix-vector-multiplication",
    "href": "slides/22-linear-algebra-I.html#matrix-vector-multiplication",
    "title": "Linear algebra I",
    "section": "Matrix-vector multiplication",
    "text": "Matrix-vector multiplication"
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#matrix-vector-multiplication-1",
    "href": "slides/22-linear-algebra-I.html#matrix-vector-multiplication-1",
    "title": "Linear algebra I",
    "section": "Matrix-vector multiplication",
    "text": "Matrix-vector multiplication\nGeometrically"
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#matrix-vector-multiplication-2",
    "href": "slides/22-linear-algebra-I.html#matrix-vector-multiplication-2",
    "title": "Linear algebra I",
    "section": "Matrix-vector multiplication",
    "text": "Matrix-vector multiplication\n\nExamplePythonVisual\n\n\n\nMatrix-vector multiplication transforms the vector according to the basis vectors of the matrix.\nFormula: \\(\\mathbf{A} \\cdot \\mathbf{v}\\)\n\n\\[\n\\mathbf{A} \\cdot \\mathbf{v} = \\begin{bmatrix}3 & 0 \\\\0 & 2 \\end{bmatrix} \\cdot [3, 2]\n\\]\n\n\n\nA = np.array([[3,0],[0,2]])\nv = np.array([3, 2])\nnew_v = A.dot(v)\nprint(new_v) \n\n[9 4]\n\n\n\n\n\n\nCode\nA = np.array([[3, 0], [0, 2]])\nv = np.array([3, 2])\nnew_v = A.dot(v)\n\nplt.quiver(*origin, *v, color='r', scale=1, scale_units='xy', angles='xy')\nplt.quiver(*origin, *new_v, color='g', scale=1, scale_units='xy', angles='xy')\nplt.xlim(0, 10)\nplt.ylim(0, 5)\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#determinants",
    "href": "slides/22-linear-algebra-I.html#determinants",
    "title": "Linear algebra I",
    "section": "Determinants",
    "text": "Determinants\n\nThe determinant is a function that maps square matrices to real numbers: \\(\\text{Det}:ℝ^{m×m}→ℝ\\)\nwhere the absolute value of the determinant describes the volume of the parallelepided formed by the matrix’s columns."
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#determinants-python",
    "href": "slides/22-linear-algebra-I.html#determinants-python",
    "title": "Linear algebra I",
    "section": "Determinants: Python",
    "text": "Determinants: Python\n\nDeterminants measure the scale factor of a transformation.\nDeterminant of 0 indicates linear dependence.\n\n\nfrom numpy.linalg import det\nA = np.array([[3, 0], [0, 2]])\ndeterminant = det(A)\nprint(determinant)\n\n6.0"
  },
  {
    "objectID": "slides/22-linear-algebra-I.html#ae-15-linear-algebra",
    "href": "slides/22-linear-algebra-I.html#ae-15-linear-algebra",
    "title": "Linear algebra I",
    "section": "ae-15-linear-algebra",
    "text": "ae-15-linear-algebra\nPractice matrix operations (you will be tested on this in Exam 2)\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "INFO 511: Fundamentals of Data Science",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses and the timeline of topics and assignments might be updated throughout the semester.\n\n\n\n\n\n\n\n\nWEEK\nDATE\nTOPIC\nPREPARE\nMATERIALS\nDUE\n\n\n\n\n1\nWed, Jan 15\nWelcome + Intro to data science\n📚 DS From Scratch - Chp 1\n🎥 Week 1 Lectures  ⌨️ ae 00  💻 HW 0\n\n\n\n\n\nFri, Jan 17\nIntroducing your Toolkit\n📃 Jupyter + VSCode  OR  🎥 Jupyter + VSCode (up to 4:50)\n⌨️ ae 01\n\n\n\n\n2\nMon, Jan 20\nIntro to Python + Git/GitHub\n📚 DS From Scratch - Chp 2  🎥 Git + VSCode\n🎥 Week 2 Lectures  💻 DS experience\n\n\n\n\n\nFri, Jan 24\nIntro to Numpy + Pandas\n📚 Python Data Analysis - Chp 4  📚 Python Data Analysis - Chp 5\n💻 HW 1\n\n\n\n\n3\nMon, Jan 27\nExploratory Data Analysis\n📚 Prac Stats for DS - Chp 1  📚 Math for DS - Chp 3\n🎥 Week 3 Lectures  ⌨️ ae 02  ✅ ae 02\n\n\n\n\n\nFri, Jan 31\nData visualization\n📚 Python Data Analysis - Chp 9\n⌨️ ae 03  ✅ ae 03\n\n\n\n\n4\nMon, Feb 3\nData preprocessing\n📚 Python Data Analysis - Chp 7  📃 Data Preprocessing in Python\n🎥 Week 4 Lectures  ⌨️ ae 04  ✅ ae 04 💻 HW 2\n\n\n\n\n\nFri, Feb 7\nData wrangling\n📚 Python Data Analysis - Chp 8\n⌨️ ae 05  ✅ ae 05\nHW 1 @ 5pm\n\n\n5\nMon, Feb 10\nWeb scraping\n📚 DS From Scratch - Chp 9  📃 Web Scraping in Python\n🎥 Week 5 Lectures  ⌨️ ae 06  ✅ ae 06\n\n\n\n\n\nFri, Feb 14\nMidterm Review\n\n\n\n\n\n\n\n\n6\nMon, Feb 17\nMidterm Released\n\n\n🎥 Week 6 Lectures  📝 Midterm assignment\n\n\n\n\n\nFri, Feb 21\nData science ethics\n📚 DS From Scratch - Chp 26  🎥 Misrepresentation  🎥 Data privacy  🎥 Algorithmic bias  🎥 Alberto Cairo - How charts lie  🎥 Joy Buolamwini - How I’m fighting bias in algorithms\n\n\n\n\n\n\n7\nMon, Feb 24\nProbability  Final Project Released\n📚 DS From Scratch - Chp 6 (up to conditional probability)\n🎥 Week 7 Lectures  ⌨️ ae 07  ✅ ae 07  📓 final project description\n\n\n\n\n\nFri, Feb 28\nConditional probability\n📚 DS From Scratch - Chp 6 (Conditional probability)\n⌨️ ae 08  ✅ ae 08  💻 HW 3\nHW 2 @ 5pm\n\n\n8\nMon, Mar 3\nHypothesis testing\n📚 DS From Scratch - Chp 5\n🎥 Week 8 Lectures\n\n\n\n\n\nFri, Mar 7\nSampling distributions + inference\n📚 Review DS From Scratch - Chp 6 (Central Limit Theorem)  📚 IMS - Chp 13\n⌨️ ae 09  ✅ ae 09\nMidterm assignment due @ 5pm\n\n\n9\nMon, Mar 10\nSpring recess ☀️🌼\n\n\nNo Week 9 Lectures\n\n\n\n\n\nFri, Mar 14\nSpring recess ☀️🌼\n\n\nNo Week 9 Lectures\n\n\n\n\n10\nMon, Mar 17\nLinear regression\n📚 DS From Scratch - Chp 14 (up to Gradient Descent)\n🎥 Week 10 Lectures  ⌨️ ae 10  ✅ ae 10\n\n\n\n\n\nFri, Mar 21\nMultiple linear regression\n📚 DS From Scratch - Chp 15 (up to Regularization)\n⌨️ ae 11  ✅ ae 11\n\n\n\n\n11\nMon, Mar 24\nLogistic regression\n📚 DS From Scratch - Chp 16 (up to SVMs)\n🎥 Week 11 Lectures\n\n\n\n\n\nWed, Mar 26\n\n\n\n\n💻 HW 4\nHW 3 @ 5pm\n\n\n\nFri, Mar 28\nPrediction + uncertainty\n📚 DS From Scratch - Chp 11  📚 Python Data Analysis - Chp 12.1 - 12.2\n⌨️ ae 12  ✅ ae 12\n\n\n\n\n12\nMon, Mar 31\nModel validation\n📚 Python for DS - Chp 5.3\n🎥 Week 12 Lectures\n\n\n\n\n\nFri, Apr 4\nCalculus I\n📚 Math for DS - Chp 1 (up to Integrals)\n⌨️ ae 13  ✅ ae 13\n\n\n\n\n13\nMon, Apr 7\nCalculus II\n📚 Math for DS - Chp 1 (Integrals)\n🎥 Week 13 Lectures  ⌨️ ae 14  ✅ ae 14\n\n\n\n\n\n\n\nLinear Algebra I\n📚 Math for DS - Chp 4 (up to Eigenvalues)\n⌨️ ae 15  ✅ ae 15\n\n\n\n\n\nFri, Apr 11\nLinear Algebra II\n📚 Math for DS - Chp 4 (from Eigenvalues)  📃 Dr. Bernstein’s Posts on Linear Algebra\n🎥 Week 14 Lectures  ⌨️ ae 16  ✅ ae 16  💻 HW 5\nHW 4 @ 5pm\n\n\n14\nMon, Apr 14\nComparing machine learning models  (See YouTube recordings)\n📚 DS From Scratch - Chp 17\n🎥 Comparing Machine Learning Classifiers  🎥 Hyperparameter Tuning  ⌨️ ae 17  ✅ ae 16\n\n\n\n\n\nFri, Apr 18\n\n\n\n\n📝 Final assignment\nAEs final deadline\n\n\n15\nMon, Apr 21\nCommunicating data science results effectively\n📚 fdv - Chp 29\n\n\n\n\n\n\n\nFri, Apr 25\nFinal Review  Final Released\n\n\n\n\n💻 DS experience @ 11:59pm\n\n\n16\nMon, Apr 28\nWork on final project and assignment\n\n\n\n\n\n\n\n\n\nFri, May 2\n\n\n\n\n\n\n\n\n\n\n17\nMon, May 5\nWork on final project and assignment\n\n\n\n\nHW 5 @ 5pm\n\n\n\nWed, May 7\n\n\n\n\n\n\n\n\n\n\nFinals\nWed, May 14\nFinish final project\n\n\n\n\nFinal project due @ 5pm  Final assignment due @ 5pm",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Dr. Greg Chism (he/him) is an Assistant Professor of the Practice at the School of Information at The University of Arizona. Greg is a data scientist, educator, and behavioral ecologist. He is passionate about telling stories through data. He accomplishes this by leveraging his interdisciplinary background to provide an innovative approach to answering complex questions.\n\n\n\nOffice hours\nLocation\n\n\n\n\nBy appointment\nZoom",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-team.html#instructor",
    "href": "course-team.html#instructor",
    "title": "Teaching team",
    "section": "",
    "text": "Dr. Greg Chism (he/him) is an Assistant Professor of the Practice at the School of Information at The University of Arizona. Greg is a data scientist, educator, and behavioral ecologist. He is passionate about telling stories through data. He accomplishes this by leveraging his interdisciplinary background to provide an innovative approach to answering complex questions.\n\n\n\nOffice hours\nLocation\n\n\n\n\nBy appointment\nZoom",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "slides/25-final-review.html#final-assignment",
    "href": "slides/25-final-review.html#final-assignment",
    "title": "Final review",
    "section": "Final Assignment",
    "text": "Final Assignment\nSame as Midterm assignment!\n\nAssignment format / flow\nAsking questions!"
  },
  {
    "objectID": "slides/25-final-review.html#concepts-covered-midterm",
    "href": "slides/25-final-review.html#concepts-covered-midterm",
    "title": "Final review",
    "section": "Concepts covered (+ Midterm)",
    "text": "Concepts covered (+ Midterm)\n\n\nA hypothesis test is a statistical technique used to evaluate competing claims (null and alternative hypotheses) using data.\nWe simulate a null distribution using our original data.\nWe use our sample statistic and direction of the alternative hypothesis to calculate the p-value.\nWe use the p-value to determine conclusions about the alternative hypotheses.\nDerivative Calculation: Computing the derivative of a given function.\nIntegral Calculation: Solving an integral involving exponential and power functions.\nVector and Matrix Transpose: Writing down the transpose of vectors and matrices.\nMatrix Dimensions: Determining the dimensions of matrices and the validity of matrix products.\nMatrix Multiplication: Performing matrix multiplication and understanding the resulting matrix dimensions.\n\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/19-validation.html#setup",
    "href": "slides/19-validation.html#setup",
    "title": "Model validation",
    "section": "Setup",
    "text": "Setup\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_theme(style=\"whitegrid\", rc={\"figure.figsize\": (8, 6), \"axes.labelsize\": 16, \"xtick.labelsize\": 14, \"ytick.labelsize\": 14})"
  },
  {
    "objectID": "slides/19-validation.html#data-candy-rankings",
    "href": "slides/19-validation.html#data-candy-rankings",
    "title": "Model validation",
    "section": "Data: Candy Rankings",
    "text": "Data: Candy Rankings\n\ncandy_rankings = pd.read_csv(\"data/candy_rankings.csv\")\n\ncandy_rankings.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 85 entries, 0 to 84\nData columns (total 13 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   competitorname    85 non-null     object \n 1   chocolate         85 non-null     bool   \n 2   fruity            85 non-null     bool   \n 3   caramel           85 non-null     bool   \n 4   peanutyalmondy    85 non-null     bool   \n 5   nougat            85 non-null     bool   \n 6   crispedricewafer  85 non-null     bool   \n 7   hard              85 non-null     bool   \n 8   bar               85 non-null     bool   \n 9   pluribus          85 non-null     bool   \n 10  sugarpercent      85 non-null     float64\n 11  pricepercent      85 non-null     float64\n 12  winpercent        85 non-null     float64\ndtypes: bool(9), float64(3), object(1)\nmemory usage: 3.5+ KB"
  },
  {
    "objectID": "slides/19-validation.html#overfitting",
    "href": "slides/19-validation.html#overfitting",
    "title": "Model validation",
    "section": "Overfitting",
    "text": "Overfitting\n\n\nThe data we are using to construct our models come from a larger population.\nUltimately we want our model to tell us how the population works, not just the sample we have.\nIf the model we fit is too tailored to our sample, it might not perform as well with the remaining population. This means the model is “overfitting” our data.\nWe measure this using model validation techniques.\nNote: Overfitting is not a huge concern with linear models with low level interactions, however it can be with more complex and flexible models. The following is just an example of model validation, even though we’re using it in a scenario where the concern for overfitting is not high."
  },
  {
    "objectID": "slides/19-validation.html#model-validation-1",
    "href": "slides/19-validation.html#model-validation-1",
    "title": "Model validation",
    "section": "Model validation",
    "text": "Model validation\n\n\nOne commonly used model validation technique is to partition your data into training and testing set\nThat is, fit the model on the training data\nAnd test it on the testing data\nEvaluate model performance using \\(RMSE\\), root-mean squared error\n\n\n\n\\[ RMSE = \\sqrt{\\frac{\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2}{n}} \\]\n\n\n\nDo you think we should prefer low or high RMSE?"
  },
  {
    "objectID": "slides/19-validation.html#random-sampling-and-reproducibility",
    "href": "slides/19-validation.html#random-sampling-and-reproducibility",
    "title": "Model validation",
    "section": "Random sampling and reproducibility",
    "text": "Random sampling and reproducibility\nGotta set a seed!\n\nnp.random.seed(1234)\n\n\n\nUse different seeds from each other\nNeed inspiration? https://www.random.org/"
  },
  {
    "objectID": "slides/19-validation.html#cross-validation",
    "href": "slides/19-validation.html#cross-validation",
    "title": "Model validation",
    "section": "Cross validation",
    "text": "Cross validation\nMore specifically, k-fold cross validation\n\n\n\n\nSplit your data into k folds.\nUse 1 fold for testing and the remaining (k - 1) folds for training.\nRepeat k times."
  },
  {
    "objectID": "slides/19-validation.html#prepping-your-data-for-5-fold-cv",
    "href": "slides/19-validation.html#prepping-your-data-for-5-fold-cv",
    "title": "Model validation",
    "section": "Prepping your data for 5-fold CV",
    "text": "Prepping your data for 5-fold CV\n\ncandy_rankings['id'] = np.arange(len(candy_rankings))\ncandy_rankings = candy_rankings.sample(frac=1).reset_index(drop=True)\ncandy_rankings['fold'] = (np.arange(len(candy_rankings)) % 5) + 1\n\ncandy_rankings_cv = candy_rankings.groupby('fold').size().reset_index(name='count')\nprint(candy_rankings_cv)\n\n   fold  count\n0     1     17\n1     2     17\n2     3     17\n3     4     17\n4     5     17"
  },
  {
    "objectID": "slides/19-validation.html#cv-1",
    "href": "slides/19-validation.html#cv-1",
    "title": "Model validation",
    "section": "CV 1",
    "text": "CV 1\n\ntest_fold = 1\ntest = candy_rankings[candy_rankings['fold'] == test_fold]\ntrain = candy_rankings[candy_rankings['fold'] != test_fold]\n\nmodel = smf.ols('winpercent ~ chocolate + fruity + peanutyalmondy + crispedricewafer + hard + sugarpercent', data=train).fit()\nrmse_test1 = np.sqrt(mean_squared_error(test['winpercent'], model.predict(test)))\nprint(f'RMSE Test 1: {rmse_test1}')\n\nRMSE Test 1: 10.15009006066606"
  },
  {
    "objectID": "slides/19-validation.html#rmse-on-training-vs.-testing",
    "href": "slides/19-validation.html#rmse-on-training-vs.-testing",
    "title": "Model validation",
    "section": "RMSE on training vs. testing",
    "text": "RMSE on training vs. testing\n\nWould you expect the RMSE to be higher for your training data or your testing data? Why?"
  },
  {
    "objectID": "slides/19-validation.html#rmse-on-training-vs.-testing-1",
    "href": "slides/19-validation.html#rmse-on-training-vs.-testing-1",
    "title": "Model validation",
    "section": "RMSE on training vs. testing",
    "text": "RMSE on training vs. testing\nRMSE for testing:\n\nrmse_test1 = np.sqrt(mean_squared_error(test['winpercent'], model.predict(test)))\nprint(f'RMSE Test 1: {rmse_test1}')\n\nRMSE Test 1: 10.15009006066606\n\n\nRMSE for training:\n\nrmse_train1 = np.sqrt(mean_squared_error(train['winpercent'], model.predict(train)))\nprint(f'RMSE Train 1: {rmse_train1}')\n\nRMSE Train 1: 10.117840760774037"
  },
  {
    "objectID": "slides/19-validation.html#cv-2",
    "href": "slides/19-validation.html#cv-2",
    "title": "Model validation",
    "section": "CV 2",
    "text": "CV 2\n\ntest_fold = 2\ntest = candy_rankings[candy_rankings['fold'] == test_fold]\ntrain = candy_rankings[candy_rankings['fold'] != test_fold]\nmodel = smf.ols('winpercent ~ chocolate + fruity + peanutyalmondy + crispedricewafer + hard + sugarpercent', data=train).fit()\n\n\nrmse_test2 = np.sqrt(mean_squared_error(test['winpercent'], model.predict(test)))\nrmse_train2 = np.sqrt(mean_squared_error(train['winpercent'], model.predict(train)))\nprint(f'RMSE Test 2: {rmse_test2}')\nprint(f'RMSE Train 2: {rmse_train2}')\n\nRMSE Test 2: 10.432240639004073\nRMSE Train 2: 10.027804484574576"
  },
  {
    "objectID": "slides/19-validation.html#cv-3",
    "href": "slides/19-validation.html#cv-3",
    "title": "Model validation",
    "section": "CV 3",
    "text": "CV 3\n\ntest_fold = 3\ntest = candy_rankings[candy_rankings['fold'] == test_fold]\ntrain = candy_rankings[candy_rankings['fold'] != test_fold]\nmodel = smf.ols('winpercent ~ chocolate + fruity + peanutyalmondy + crispedricewafer + hard + sugarpercent', data=train).fit()\n\n\nrmse_test3 = np.sqrt(mean_squared_error(test['winpercent'], model.predict(test)))\nrmse_train3 = np.sqrt(mean_squared_error(train['winpercent'], model.predict(train)))\nprint(f'RMSE Test 3: {rmse_test3}')\nprint(f'RMSE Train 3: {rmse_train3}')\n\nRMSE Test 3: 11.95850312007085\nRMSE Train 3: 9.801042089669558"
  },
  {
    "objectID": "slides/19-validation.html#cv-4",
    "href": "slides/19-validation.html#cv-4",
    "title": "Model validation",
    "section": "CV 4",
    "text": "CV 4\n\ntest_fold = 4\ntest = candy_rankings[candy_rankings['fold'] == test_fold]\ntrain = candy_rankings[candy_rankings['fold'] != test_fold]\nmodel = smf.ols('winpercent ~ chocolate + fruity + peanutyalmondy + crispedricewafer + hard + sugarpercent', data=train).fit()\n\n\nrmse_test4 = np.sqrt(mean_squared_error(test['winpercent'], model.predict(test)))\nrmse_train4 = np.sqrt(mean_squared_error(train['winpercent'], model.predict(train)))\nprint(f'RMSE Test 4: {rmse_test4}')\nprint(f'RMSE Train 4: {rmse_train4}')\n\nRMSE Test 4: 12.39965858487449\nRMSE Train 4: 9.60646325325732"
  },
  {
    "objectID": "slides/19-validation.html#cv-5",
    "href": "slides/19-validation.html#cv-5",
    "title": "Model validation",
    "section": "CV 5",
    "text": "CV 5\n\ntest_fold = 5\ntest = candy_rankings[candy_rankings['fold'] == test_fold]\ntrain = candy_rankings[candy_rankings['fold'] != test_fold]\nmodel = smf.ols('winpercent ~ chocolate + fruity + peanutyalmondy + crispedricewafer + hard + sugarpercent', data=train).fit()\n\n\nrmse_test5 = np.sqrt(mean_squared_error(test['winpercent'], model.predict(test)))\nrmse_train5 = np.sqrt(mean_squared_error(train['winpercent'], model.predict(train)))\nprint(f'RMSE Test 5: {rmse_test5}')\nprint(f'RMSE Train 5: {rmse_train5}')\n\nRMSE Test 5: 10.01290509309602\nRMSE Train 5: 10.13805597882432"
  },
  {
    "objectID": "slides/19-validation.html#putting-it-altogether",
    "href": "slides/19-validation.html#putting-it-altogether",
    "title": "Model validation",
    "section": "Putting it altogether",
    "text": "Putting it altogether\n\n\nDataframe\nrmse_candy = pd.DataFrame({\n    'test_fold': np.arange(1, 6),\n    'rmse_train': [rmse_train1, rmse_train2, rmse_train3, rmse_train4, rmse_train5],\n    'rmse_test': [rmse_test1, rmse_test2, rmse_test3, rmse_test4, rmse_test5]\n})\n\n\n\n\nVisual\nplt.figure(figsize=(8, 5))\nsns.lineplot(data=rmse_candy, x='test_fold', y='rmse_test', marker='o', label='Test RMSE')\nplt.xlabel('Fold')\nplt.ylabel('RMSE')\nplt.title('Test RMSE for each fold')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "slides/19-validation.html#how-does-rmse-compare-to-y",
    "href": "slides/19-validation.html#how-does-rmse-compare-to-y",
    "title": "Model validation",
    "section": "How does RMSE compare to y?",
    "text": "How does RMSE compare to y?\n\n\nwinpercent summary stats:\n\n\n\ncount    85.000000\nmean     50.316764\nstd      14.714357\nmin      22.445341\n25%      39.141056\n50%      47.829754\n75%      59.863998\nmax      84.180290\nName: winpercent, dtype: float64\n\n\n\n\n\nrmse_test summary stats:\n\n\n\ncount     5.000000\nmean     10.990679\nstd       1.106390\nmin      10.012905\n25%      10.150090\n50%      10.432241\n75%      11.958503\nmax      12.399659\nName: rmse_test, dtype: float64"
  },
  {
    "objectID": "slides/19-validation.html#model_selection-in-scikit-learn",
    "href": "slides/19-validation.html#model_selection-in-scikit-learn",
    "title": "Model validation",
    "section": "model_selection in scikit-learn",
    "text": "model_selection in scikit-learn\n\n\n\n\nThe scikit-learn package provides functions that help you create pipelines when modeling.\n\nfrom sklearn.model_selection import KFold\n\n\n\n\nmodel selection via scikit-learn"
  },
  {
    "objectID": "slides/19-validation.html#cross-validation---faster",
    "href": "slides/19-validation.html#cross-validation---faster",
    "title": "Model validation",
    "section": "Cross Validation - Faster",
    "text": "Cross Validation - Faster\n\nsklearn.model_selection.KFold: Partition data into k folds\nCalculate RMSEs for each of the models on the testing set"
  },
  {
    "objectID": "slides/19-validation.html#partition-data-into-k-folds",
    "href": "slides/19-validation.html#partition-data-into-k-folds",
    "title": "Model validation",
    "section": "Partition data into k folds",
    "text": "Partition data into k folds\nk = 5:\n\nkf = KFold(n_splits=5, shuffle=True, random_state=102319)\nfolds = list(kf.split(candy_rankings))"
  },
  {
    "objectID": "slides/19-validation.html#fit-model-on-each-of-training-set",
    "href": "slides/19-validation.html#fit-model-on-each-of-training-set",
    "title": "Model validation",
    "section": "Fit model on each of training set",
    "text": "Fit model on each of training set\n\nrmses = []\nfor train_index, test_index in folds:\n    train_data = candy_rankings.iloc[train_index]\n    test_data = candy_rankings.iloc[test_index]\n    model = smf.ols('winpercent ~ chocolate + fruity + peanutyalmondy + crispedricewafer + hard + sugarpercent', data=train_data).fit()\n    rmse = np.sqrt(mean_squared_error(test_data['winpercent'], model.predict(test_data)))\n    rmses.append(rmse)"
  },
  {
    "objectID": "slides/19-validation.html#calculate-rmses",
    "href": "slides/19-validation.html#calculate-rmses",
    "title": "Model validation",
    "section": "Calculate RMSEs",
    "text": "Calculate RMSEs\n\n\n\n\nCode\nfold_ids = list(range(1, 6))\nplt.figure(figsize=(8, 5))\nplt.plot(fold_ids, rmses, marker='o', label='Test RMSE')\nplt.xlabel('Fold')\nplt.ylabel('RMSE')\nplt.title('Test RMSE for each fold')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n \n\nrmse_summary = pd.Series(rmses).describe()\nprint(rmse_summary)\n\ncount     5.000000\nmean     10.644100\nstd       3.751177\nmin       5.336119\n25%       8.319019\n50%      11.885830\n75%      13.232239\nmax      14.447295\ndtype: float64\n\n\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/00-welcome-511.html#meet-the-prof",
    "href": "slides/00-welcome-511.html#meet-the-prof",
    "title": "Welcome to INFO 511",
    "section": "Meet the prof",
    "text": "Meet the prof\n\n\nDr. Greg Chism\nAssistant Professor of the Practice\nHarvill 420"
  },
  {
    "objectID": "slides/00-welcome-511.html#meet-each-other",
    "href": "slides/00-welcome-511.html#meet-each-other",
    "title": "Welcome to INFO 511",
    "section": "Meet each other!",
    "text": "Meet each other!\n\n\n\n\n\n\nImportant\n\n\nIntroduce yourself via the #general channel in the course Slack"
  },
  {
    "objectID": "slides/00-welcome-511.html#meet-data-science",
    "href": "slides/00-welcome-511.html#meet-data-science",
    "title": "Welcome to INFO 511",
    "section": "Meet data science",
    "text": "Meet data science\n\nData science is an exciting discipline that allows you to turn raw data into understanding, insight, and knowledge.\nWe’re going to learn to do this in a formulaic way – more on that later!\nThis is a course on introduction to data science, with an emphasis on statistical thinking and mathematics."
  },
  {
    "objectID": "slides/00-welcome-511.html#excel---not",
    "href": "slides/00-welcome-511.html#excel---not",
    "title": "Welcome to INFO 511",
    "section": "Excel - not…",
    "text": "Excel - not…"
  },
  {
    "objectID": "slides/00-welcome-511.html#python",
    "href": "slides/00-welcome-511.html#python",
    "title": "Welcome to INFO 511",
    "section": "Python",
    "text": "Python"
  },
  {
    "objectID": "slides/00-welcome-511.html#vs-code",
    "href": "slides/00-welcome-511.html#vs-code",
    "title": "Welcome to INFO 511",
    "section": "VS Code",
    "text": "VS Code"
  },
  {
    "objectID": "slides/00-welcome-511.html#data-science-life-cycle-1",
    "href": "slides/00-welcome-511.html#data-science-life-cycle-1",
    "title": "Welcome to INFO 511",
    "section": "Data science life cycle",
    "text": "Data science life cycle"
  },
  {
    "objectID": "slides/00-welcome-511.html#import",
    "href": "slides/00-welcome-511.html#import",
    "title": "Welcome to INFO 511",
    "section": "Import",
    "text": "Import"
  },
  {
    "objectID": "slides/00-welcome-511.html#tidy-transform",
    "href": "slides/00-welcome-511.html#tidy-transform",
    "title": "Welcome to INFO 511",
    "section": "Tidy + transform",
    "text": "Tidy + transform"
  },
  {
    "objectID": "slides/00-welcome-511.html#visualize",
    "href": "slides/00-welcome-511.html#visualize",
    "title": "Welcome to INFO 511",
    "section": "Visualize",
    "text": "Visualize"
  },
  {
    "objectID": "slides/00-welcome-511.html#model",
    "href": "slides/00-welcome-511.html#model",
    "title": "Welcome to INFO 511",
    "section": "Model",
    "text": "Model"
  },
  {
    "objectID": "slides/00-welcome-511.html#understand",
    "href": "slides/00-welcome-511.html#understand",
    "title": "Welcome to INFO 511",
    "section": "Understand",
    "text": "Understand"
  },
  {
    "objectID": "slides/00-welcome-511.html#section",
    "href": "slides/00-welcome-511.html#section",
    "title": "Welcome to INFO 511",
    "section": "",
    "text": "date  season\n0   23 January 2017  winter\n1      4 March 2017  spring\n2      14 June 2017  summer\n3  1 September 2017    fall\n4               ...     ..."
  },
  {
    "objectID": "slides/00-welcome-511.html#communicate",
    "href": "slides/00-welcome-511.html#communicate",
    "title": "Welcome to INFO 511",
    "section": "Communicate",
    "text": "Communicate"
  },
  {
    "objectID": "slides/00-welcome-511.html#understand-communicate",
    "href": "slides/00-welcome-511.html#understand-communicate",
    "title": "Welcome to INFO 511",
    "section": "Understand + communicate",
    "text": "Understand + communicate"
  },
  {
    "objectID": "slides/00-welcome-511.html#program",
    "href": "slides/00-welcome-511.html#program",
    "title": "Welcome to INFO 511",
    "section": "Program",
    "text": "Program"
  },
  {
    "objectID": "slides/00-welcome-511.html#application-exercise",
    "href": "slides/00-welcome-511.html#application-exercise",
    "title": "Welcome to INFO 511",
    "section": "Application exercise",
    "text": "Application exercise\n\nOr more like demo for today…\n📋 github.com/INFO-511-F24/ae-00-unvotes"
  },
  {
    "objectID": "slides/00-welcome-511.html#homepage",
    "href": "slides/00-welcome-511.html#homepage",
    "title": "Welcome to INFO 511",
    "section": "Homepage",
    "text": "Homepage\nhttps://datasciaz.netlify.app/\n\nAll course materials\nLinks to GitHub, D2L, Posit Cloud (can run Jupyter), etc."
  },
  {
    "objectID": "slides/00-welcome-511.html#course-toolkit",
    "href": "slides/00-welcome-511.html#course-toolkit",
    "title": "Welcome to INFO 511",
    "section": "Course toolkit",
    "text": "Course toolkit\nAll linked from the course website:\n\nGitHub org: github.com/INFO-511-F24\nPosit Cloud: posit.cloud\nCommunication: Slack\nAssignment submission and feedback: Github"
  },
  {
    "objectID": "slides/00-welcome-511.html#activities",
    "href": "slides/00-welcome-511.html#activities",
    "title": "Welcome to INFO 511",
    "section": "Activities",
    "text": "Activities\n\nIntroduce new content and prepare for lectures by watching the videos and completing the readings\nActively participate office hours, team meetings\nPractice applying data science concepts and computing with application exercises during lecture, graded for completion\nPut together what you’ve learned to analyze real-world data\n\nLab assignments x 7\nExams x 2\nTerm project presented in the last lab session"
  },
  {
    "objectID": "slides/00-welcome-511.html#exams",
    "href": "slides/00-welcome-511.html#exams",
    "title": "Welcome to INFO 511",
    "section": "Exams",
    "text": "Exams\n\nTwo exams, each 20%\nTake home: Focus on the analysis of a dataset introduced in the take home exam, or solve mathematical prompts\n\n\n\n\n\n\n\nCaution\n\n\nExam dates cannot be changed and no make-up exams will be given. If you can’t take the exams on these dates, you should drop this class."
  },
  {
    "objectID": "slides/00-welcome-511.html#project",
    "href": "slides/00-welcome-511.html#project",
    "title": "Welcome to INFO 511",
    "section": "Project",
    "text": "Project\n\nDataset of your choice, method of your choice\nTeamwork\nPresentation and write-up\nPresentations in the last week (video recordings)\nInterim deadlines, peer review on content, peer evaluation for team contribution\n\n\n\n\n\n\n\nCaution\n\n\nFinal presentation date cannot be changed. If you can’t present on that date, you should drop this class. You must complete the project to pass this class."
  },
  {
    "objectID": "slides/00-welcome-511.html#teams",
    "href": "slides/00-welcome-511.html#teams",
    "title": "Welcome to INFO 511",
    "section": "Teams",
    "text": "Teams\n\nAssigned by me\nProject\nPeer evaluation during teamwork and after completion\nExpectations and roles\n\nEveryone is expected to contribute equal effort\nEveryone is expected to understand all code turned in\nIndividual contribution evaluated by peer evaluation, commits, etc."
  },
  {
    "objectID": "slides/00-welcome-511.html#grading",
    "href": "slides/00-welcome-511.html#grading",
    "title": "Welcome to INFO 511",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nLabs\n30%\n\n\nProject\n25%\n\n\nExam 1\n20%\n\n\nExam 2\n20%\n\n\nApplication Exercises\n5%\n\n\n\nNo specific points allocated to participation, but participation via Slack, particularly Discussions, will be recorded periodically throughout the semester, and this information will be used as “extra credit” if you’re in between two grades and a minor bump would help.\nSee course syllabus for how the final letter grade will be determined."
  },
  {
    "objectID": "slides/00-welcome-511.html#support",
    "href": "slides/00-welcome-511.html#support",
    "title": "Welcome to INFO 511",
    "section": "Support",
    "text": "Support\n\nAttend office hours (by appointment)\nAsk and answer questions on the discussion forum\nReserve email for questions on personal matters and/or grades\nRead the course support page"
  },
  {
    "objectID": "slides/00-welcome-511.html#announcements",
    "href": "slides/00-welcome-511.html#announcements",
    "title": "Welcome to INFO 511",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on D2L (Announcements tool) but primarily sent via Slack, be sure to check both regularly\nI’ll assume that you’ve read an announcement by the next “business” day"
  },
  {
    "objectID": "slides/00-welcome-511.html#diversity-inclusion",
    "href": "slides/00-welcome-511.html#diversity-inclusion",
    "title": "Welcome to INFO 511",
    "section": "Diversity + inclusion",
    "text": "Diversity + inclusion\nMy goal is to ensure that students from all diverse backgrounds are well-served by this course, addressing their learning needs in and out of class, and recognizing the diversity they bring as a valuable resource and strength.\n\n\nPlease let me know your preferred name and pronouns on the Getting to know you survey.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisers, and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me."
  },
  {
    "objectID": "slides/00-welcome-511.html#accessibility",
    "href": "slides/00-welcome-511.html#accessibility",
    "title": "Welcome to INFO 511",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Disability Resource Center is available to ensure that students are able to engage with their courses and related assignments.\nI am committed to making all course materials accessible and I’m always learning how to do this better. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/00-welcome-511.html#late-work-waivers-regrades-policy",
    "href": "slides/00-welcome-511.html#late-work-waivers-regrades-policy",
    "title": "Welcome to INFO 511",
    "section": "Late work, waivers, regrades policy",
    "text": "Late work, waivers, regrades policy\n\nWe have policies!\nRead about them on the course syllabus and refer back to them when you need it"
  },
  {
    "objectID": "slides/00-welcome-511.html#academic-integrity",
    "href": "slides/00-welcome-511.html#academic-integrity",
    "title": "Welcome to INFO 511",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the UArizona InfoSci Community Standard:\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "slides/00-welcome-511.html#this-weeks-tasks",
    "href": "slides/00-welcome-511.html#this-weeks-tasks",
    "title": "Welcome to INFO 511",
    "section": "This week’s tasks",
    "text": "This week’s tasks\n\nComplete Lab 0\n\nComputational setup\nGetting to know you survey\n\nRead the syllabus\nStart readings for next week\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/02-python-git.html#what-is-python",
    "href": "slides/02-python-git.html#what-is-python",
    "title": "Intro to Python",
    "section": "What is Python?",
    "text": "What is Python?\n\n\n“Python is the second best language at everything.” - Van Lindberg\nVersatile and popular programming language with simple syntax\nLarge collection of frameworks and libraries\nLarge, active community\nWidely used for web development, data analysis, artificial intelligence, scientific computing, and more."
  },
  {
    "objectID": "slides/02-python-git.html#basic-syntax-and-comments",
    "href": "slides/02-python-git.html#basic-syntax-and-comments",
    "title": "Intro to Python",
    "section": "Basic syntax and comments",
    "text": "Basic syntax and comments\n\n# This is a comment\nprint(\"Hello, Python!\")  # This prints a message\n\nHello, Python!\n\n\n\n\nIndentation for code blocks (instead of brackets)\nComments start with a # (used to explain code)"
  },
  {
    "objectID": "slides/02-python-git.html#variables-and-data-types",
    "href": "slides/02-python-git.html#variables-and-data-types",
    "title": "Intro to Python",
    "section": "Variables and data types",
    "text": "Variables and data types\n\n# Integer\nx = 5\n\n# Float\ny = 3.14\n\n# String\nname = \"Python\"\n\n# Boolean\nis_easy = True\n\n\n\nVariables store data values.\nPython uses integers (whole numbers), floats (non-whole numbers), strings (text), and booleans (true/false)."
  },
  {
    "objectID": "slides/02-python-git.html#factors-categorical-data",
    "href": "slides/02-python-git.html#factors-categorical-data",
    "title": "Intro to Python",
    "section": "Factors (categorical data)",
    "text": "Factors (categorical data)\n\n\n\nimport pandas as pd\n\nx = pd.Categorical([\"a\", \"b\", \"b\", \"a\"])\nprint(x)\nprint(type(x))\nprint(x.categories)\nprint(x.codes)\n\n['a', 'b', 'b', 'a']\nCategories (2, object): ['a', 'b']\n&lt;class 'pandas.core.arrays.categorical.Categorical'&gt;\nIndex(['a', 'b'], dtype='object')\n[0 1 1 0]"
  },
  {
    "objectID": "slides/02-python-git.html#other-classes",
    "href": "slides/02-python-git.html#other-classes",
    "title": "Intro to Python",
    "section": "Other classes",
    "text": "Other classes\n\n\nDate\n\nimport datetime\n\ntoday = datetime.date.today()\nprint(today)\nprint(type(today))\nprint(dir(today))\n\n2024-08-19\n&lt;class 'datetime.date'&gt;\n['__add__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__radd__', '__reduce__', '__reduce_ex__', '__repr__', '__rsub__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', 'ctime', 'day', 'fromisocalendar', 'fromisoformat', 'fromordinal', 'fromtimestamp', 'isocalendar', 'isoformat', 'isoweekday', 'max', 'min', 'month', 'replace', 'resolution', 'strftime', 'timetuple', 'today', 'toordinal', 'weekday', 'year']\n\n\n\nDate-Time\n\nnow = pd.Timestamp(\"2024-02-08 11:45:00\", tz=\"EST\")\nprint(now)\nprint(type(now))\nprint(now.tz)\n\n2024-02-08 11:45:00-05:00\n&lt;class 'pandas._libs.tslibs.timestamps.Timestamp'&gt;\nEST"
  },
  {
    "objectID": "slides/02-python-git.html#basic-operations",
    "href": "slides/02-python-git.html#basic-operations",
    "title": "Intro to Python",
    "section": "Basic operations",
    "text": "Basic operations\n\n# Arithmetic Operations\na = 10\nb = 3\nsum = a + b\ndifference = a - b\nproduct = a * b\nquotient = a / b\n\n# Logical Operations\nis_greater = a &gt; b\nis_equal = (a == b)\n\n\n\nPython supports various arithmetic and logical operations."
  },
  {
    "objectID": "slides/02-python-git.html#control-structures-if-else",
    "href": "slides/02-python-git.html#control-structures-if-else",
    "title": "Intro to Python",
    "section": "Control structures: if-else",
    "text": "Control structures: if-else\n\nage = 20\nif age &gt;= 18:\n    print(\"Adult\")\nelse:\n    print(\"Minor\")\n\nAdult\n\n\n\n\nPython uses if, elif, and else for decision-making."
  },
  {
    "objectID": "slides/02-python-git.html#loops",
    "href": "slides/02-python-git.html#loops",
    "title": "Intro to Python",
    "section": "Loops",
    "text": "Loops\n\n# For Loop\nfor i in range(5):\n    print(i)\n\n# While Loop\nj = 0\nwhile j &lt; 5:\n    print(j)\n    j += 1\n\n\n\nPython has two types of loops: for and while."
  },
  {
    "objectID": "slides/02-python-git.html#lists",
    "href": "slides/02-python-git.html#lists",
    "title": "Intro to Python",
    "section": "Lists",
    "text": "Lists\n\nfruits = [\"apple\", \"banana\", \"cherry\"]\nprint(fruits[0])  # Accessing the first item\n\n\n\nLists store multiple items in a single variable.\nAccess elements using index (starting at 0)."
  },
  {
    "objectID": "slides/02-python-git.html#functions",
    "href": "slides/02-python-git.html#functions",
    "title": "Intro to Python",
    "section": "Functions",
    "text": "Functions\n\ndef greet(name):\n    return \"Hello \" + name\n\nprint(greet(\"Alice\"))\n\n\n\nFunctions perform specific tasks.\nCall a function with its name and arguments."
  },
  {
    "objectID": "slides/02-python-git.html#conclusion",
    "href": "slides/02-python-git.html#conclusion",
    "title": "Intro to Python",
    "section": "Conclusion",
    "text": "Conclusion\n\n\nPython is a versatile and user-friendly language.\nIdeal for beginners and widely used.\nEncourages readable and maintainable code.\nExtensive libraries and community support."
  },
  {
    "objectID": "slides/02-python-git.html#git-and-github",
    "href": "slides/02-python-git.html#git-and-github",
    "title": "Intro to Python",
    "section": "Git and GitHub",
    "text": "Git and GitHub\n\n\n\n\n\n\n\n\nGit is a version control system – like “Track Changes” features from Microsoft Word, on steroids\nIt’s not the only version control system, but it’s a very popular one\n\n\n\n\n\n\n\n\nGitHub is the home for your Git-based projects on the internet – like DropBox but much, much better\nWe will use GitHub as a platform for web hosting and collaboration (and as our course management system!)"
  },
  {
    "objectID": "slides/02-python-git.html#versioning---done-badly",
    "href": "slides/02-python-git.html#versioning---done-badly",
    "title": "Intro to Python",
    "section": "Versioning - done badly",
    "text": "Versioning - done badly"
  },
  {
    "objectID": "slides/02-python-git.html#versioning---done-better",
    "href": "slides/02-python-git.html#versioning---done-better",
    "title": "Intro to Python",
    "section": "Versioning - done better",
    "text": "Versioning - done better"
  },
  {
    "objectID": "slides/02-python-git.html#versioning---done-even-better",
    "href": "slides/02-python-git.html#versioning---done-even-better",
    "title": "Intro to Python",
    "section": "Versioning - done even better",
    "text": "Versioning - done even better\nwith human readable messages"
  },
  {
    "objectID": "slides/02-python-git.html#how-will-we-use-git-and-github",
    "href": "slides/02-python-git.html#how-will-we-use-git-and-github",
    "title": "Intro to Python",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/02-python-git.html#how-will-we-use-git-and-github-1",
    "href": "slides/02-python-git.html#how-will-we-use-git-and-github-1",
    "title": "Intro to Python",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/02-python-git.html#how-will-we-use-git-and-github-2",
    "href": "slides/02-python-git.html#how-will-we-use-git-and-github-2",
    "title": "Intro to Python",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/02-python-git.html#how-will-we-use-git-and-github-3",
    "href": "slides/02-python-git.html#how-will-we-use-git-and-github-3",
    "title": "Intro to Python",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/02-python-git.html#git-and-github-tips",
    "href": "slides/02-python-git.html#git-and-github-tips",
    "title": "Intro to Python",
    "section": "Git and GitHub tips",
    "text": "Git and GitHub tips\n\n\nThere are millions of git commands – ok, that’s an exaggeration, but there are a lot of them – and very few people know them all. 99% of the time you will use git to add, commit, push, and pull.\nWe will be doing Git things and interfacing with GitHub through VS Code, but if you google for help you might come across methods for doing these things in the command line – skip that and move on to the next resource unless you feel comfortable trying it out.\nThere is a great resource for working with git and Python: git-github-python. Some of the content in there is beyond the scope of this course, but it’s a good place to look for help."
  },
  {
    "objectID": "slides/02-python-git.html#tour-git-github",
    "href": "slides/02-python-git.html#tour-git-github",
    "title": "Intro to Python",
    "section": "Tour: Git + GitHub",
    "text": "Tour: Git + GitHub\n\nJust one option for now:\nSit back and enjoy the show!\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/20-calculus-I.html#calculus-in-data-science",
    "href": "slides/20-calculus-I.html#calculus-in-data-science",
    "title": "Calculus I",
    "section": "Calculus in data science",
    "text": "Calculus in data science\n\n\nOptimization Algorithms: Calculus is essential for understanding and implementing optimization algorithms like gradient descent, which are used to minimize error functions in machine learning models.\nModeling Change: Derivatives help in modeling and understanding the rate of change in various phenomena, which is crucial for predictive analytics and dynamic systems in data science.\nIntegral Applications: Integrals are used in calculating areas under curves, which is fundamental for probability distributions, statistical inference, and understanding cumulative effects in data analysis."
  },
  {
    "objectID": "slides/20-calculus-I.html#functions-and-their-graphs",
    "href": "slides/20-calculus-I.html#functions-and-their-graphs",
    "title": "Calculus I",
    "section": "Functions and their graphs",
    "text": "Functions and their graphs\n\nDefinitionExamplesPlottingCode\n\n\n\n\nA function is a relation between a set of inputs and a set of permissible outputs, where each input is related to exactly one output.\nMathematical notation: \\(f(x)\\) denotes a function named \\(f\\) with \\(x\\) as the input variable.\n\n\n\n\n\nLinear function: \\(f(x)=2x+3\\)\nQuadratic function: \\(f(x)=x^2-4x+4\\)\nExponential function: \\(f(x)=e^x\\)\nLogarithmic function: \\(f(x)=log(x)\\)\n\n\n\n\n\nUsing matplotlib\n\n\n\n\n\n\n\n\n\n\nUsing SymPy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing matplotlib\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the function\ndef f(x):\n    return 2 * x + 3\n\n# Generate x values\nx = np.linspace(-10, 10, 400)\ny = f(x)\n\n# Plot the function\nplt.plot(x, y, label='f(x) = 2x + 3')\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.title('Graph of the Linear Function')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\nUsing SymPy\n\nfrom sympy import symbols, plot\n\n# Define the variable and function\nx = symbols('x')\nf = 2 * x + 3\n\n# Plot the function\nplot(f)"
  },
  {
    "objectID": "slides/20-calculus-I.html#importance-of-functions-in-modeling",
    "href": "slides/20-calculus-I.html#importance-of-functions-in-modeling",
    "title": "Calculus I",
    "section": "Importance of functions in modeling",
    "text": "Importance of functions in modeling\n\n\nPredictive Modeling:\n\nFunctions predict outputs from inputs, essential for machine learning.\nExample: Linear regression predicts continuous outcomes.\n\nDescriptive Analysis:\n\nFunctions describe relationships, revealing patterns and trends.\nExample: Growth functions model population or business growth.\n\nDecision Making:\n\nFunctions formulate decision rules and optimization problems.\nExample: Cost functions minimize expenses or maximize profits."
  },
  {
    "objectID": "slides/20-calculus-I.html#overview-of-calculus",
    "href": "slides/20-calculus-I.html#overview-of-calculus",
    "title": "Calculus I",
    "section": "Overview of Calculus",
    "text": "Overview of Calculus\n\nBranch of mathematics that studies continuous change.\n\n\n\nDifferential (rates of change & slopes of curves)\n\n\n\n\n\n\nIntegral (accumulation of quantities & areas under curves)"
  },
  {
    "objectID": "slides/20-calculus-I.html#differentiation-and-integration",
    "href": "slides/20-calculus-I.html#differentiation-and-integration",
    "title": "Calculus I",
    "section": "Differentiation and Integration",
    "text": "Differentiation and Integration\n\nDifferentiationIntegration\n\n\n\n\nMeasures the rate at which a quantity changes.\nExample: In machine learning, the derivative of the loss function with respect to model parameters helps in finding the optimal parameters.\nSymbol: \\(\\frac{dy}{dx}\\) of \\(f^{'}(x)\\)\nPractical Application: Gradient Descent Algorithm\n\n\n\n\n\n\nMeasures the accumulation of quantities and the area under a curve.\nExample: Used to compute the area under probability distribution functions, which is essential in statistics and data analysis.\nSymbol: \\(\\int f(x) dx\\)\nPractical Application: Calculating Cumulative Distribution Functions (CDFs)"
  },
  {
    "objectID": "slides/20-calculus-I.html#calculating-the-slope",
    "href": "slides/20-calculus-I.html#calculating-the-slope",
    "title": "Calculus I",
    "section": "Calculating the slope",
    "text": "Calculating the slope\n\n\n\n\n\n\n\n\n\n\\(\\text{slope}=\\frac{\\text{rise}}{\\text{run}}\\)\n\n\n\\(\\text{slope}=\\frac{\\text{change in distance}(\\Delta x)}{\\text{change in time}(\\Delta t)}\\)\n\n\n\\(\\text{slope}=\\frac{x(15)-x(10)}{t(15)-t(10)}\\)\n\n\n\\(\\text{slope}=\\frac{202m - 122m}{15s-10s}\\)\n\n\n\\(\\text{slope}=\\frac{80m}{5s}=16m/s\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#the-derivative",
    "href": "slides/20-calculus-I.html#the-derivative",
    "title": "Calculus I",
    "section": "The derivative",
    "text": "The derivative"
  },
  {
    "objectID": "slides/20-calculus-I.html#the-derivative-1",
    "href": "slides/20-calculus-I.html#the-derivative-1",
    "title": "Calculus I",
    "section": "The derivative",
    "text": "The derivative"
  },
  {
    "objectID": "slides/20-calculus-I.html#the-derivative-2",
    "href": "slides/20-calculus-I.html#the-derivative-2",
    "title": "Calculus I",
    "section": "The derivative",
    "text": "The derivative"
  },
  {
    "objectID": "slides/20-calculus-I.html#the-derivative-3",
    "href": "slides/20-calculus-I.html#the-derivative-3",
    "title": "Calculus I",
    "section": "The derivative",
    "text": "The derivative"
  },
  {
    "objectID": "slides/20-calculus-I.html#the-derivative-4",
    "href": "slides/20-calculus-I.html#the-derivative-4",
    "title": "Calculus I",
    "section": "The derivative",
    "text": "The derivative"
  },
  {
    "objectID": "slides/20-calculus-I.html#the-derivative-5",
    "href": "slides/20-calculus-I.html#the-derivative-5",
    "title": "Calculus I",
    "section": "The derivative",
    "text": "The derivative"
  },
  {
    "objectID": "slides/20-calculus-I.html#derivatives-in-python",
    "href": "slides/20-calculus-I.html#derivatives-in-python",
    "title": "Calculus I",
    "section": "Derivatives in Python",
    "text": "Derivatives in Python\nCalculating derivatives using SymPy\n\nfrom sympy import symbols, diff\n\nx = symbols('x')\nf = x**2 # x^2\ndf = diff(f)\nprint(df)\n\n2*x"
  },
  {
    "objectID": "slides/20-calculus-I.html#solving-derivatives",
    "href": "slides/20-calculus-I.html#solving-derivatives",
    "title": "Calculus I",
    "section": "Solving derivatives",
    "text": "Solving derivatives\nDifferentiation rules\n\n\nConstant rule: \\(\\frac{d}{dx} (c) = 0\\)\nPower rule: \\(\\frac{d}{dx} (x^n) = nx^{n-1}\\)\nConstant multiple rule: \\(\\frac{d}{dx} [c \\cdot f(x)] = c \\cdot f'(x)\\)\nSum rule: \\(\\frac{d}{dx} [f(x) + g(x)] = f'(x) + g'(x)\\)\nDifference rule: \\(\\frac{d}{dx} [f(x) - g(x)] = f'(x) - g'(x)\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#example-1-differentiating-a-constant",
    "href": "slides/20-calculus-I.html#example-1-differentiating-a-constant",
    "title": "Calculus I",
    "section": "Example 1: Differentiating a Constant",
    "text": "Example 1: Differentiating a Constant\n\n\nFunction: \\(f(x) = 7\\)\nDerivative: \\(f'(x) = 0\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#example-2-power-rule",
    "href": "slides/20-calculus-I.html#example-2-power-rule",
    "title": "Calculus I",
    "section": "Example 2: Power rule",
    "text": "Example 2: Power rule\n\n\nFunction: \\(f(x) = x^3\\)\nDerivative: \\(f'(x) = \\frac{d}{dx} (x^3) = 3x^2\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#example-3-constant-multiple-rule",
    "href": "slides/20-calculus-I.html#example-3-constant-multiple-rule",
    "title": "Calculus I",
    "section": "Example 3: Constant multiple rule",
    "text": "Example 3: Constant multiple rule\n\n\nFunction: \\(f(x) = 5x^2\\)\nDerivative: \\(f'(x) = 5 \\cdot \\frac{d}{dx} (x^2) = 5 \\cdot 2x = 10x\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#example-4-sum-and-difference-rule",
    "href": "slides/20-calculus-I.html#example-4-sum-and-difference-rule",
    "title": "Calculus I",
    "section": "Example 4: Sum and difference rule",
    "text": "Example 4: Sum and difference rule\n\n\nFunction: \\(f(x) = x^3 + 4x - 5\\)\nDerivative: \\(f'(x) = \\frac{d}{dx} (x^3) + \\frac{d}{dx} (4x) - \\frac{d}{dx} (5) = 3x^2 + 4 - 0 = 3x^2 + 4\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#solving-complex-derivatives",
    "href": "slides/20-calculus-I.html#solving-complex-derivatives",
    "title": "Calculus I",
    "section": "Solving complex derivatives",
    "text": "Solving complex derivatives\nComplex Derivatives:\n\n\nInvolves functions composed of multiple less complex functions.\nRequires application of rules like the chain rule and product rule for differentiation.\n\n\n\nExample Function: \\[\nh(x)=(\\ln(x) \\cdot e^{ax})^k\n\\]\n\n\n\nObjective: Find the derivative \\(\\frac{d}{dx}h(x)\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#the-chain-rule",
    "href": "slides/20-calculus-I.html#the-chain-rule",
    "title": "Calculus I",
    "section": "The Chain Rule",
    "text": "The Chain Rule\n\\[\n(f(g(x)))^{'}=f{'}(g(x)) \\cdot g{'}(x)\n\\]\n\nUsed when differentiating a composition of functions"
  },
  {
    "objectID": "slides/20-calculus-I.html#the-chain-rule-composition",
    "href": "slides/20-calculus-I.html#the-chain-rule-composition",
    "title": "Calculus I",
    "section": "The Chain Rule: Composition",
    "text": "The Chain Rule: Composition\nFunction: \\(f(x) = (3x^{2} + 2)^{5}\\)\n\n\nIdentify the Outer and Inner Functions\n\n\n\nOuter function: \\(u^5\\)\nInner function: \\(u = 3x^2 + 2\\)\n\n\n\n\n\nApply the Chain Rule\n\n\\(f{'}(x) = 5(3x^{2}+2)^{4} \\cdot \\frac{d}{dx}(3x^2 + 2)\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#the-chain-rule-composition-1",
    "href": "slides/20-calculus-I.html#the-chain-rule-composition-1",
    "title": "Calculus I",
    "section": "The Chain Rule: Composition",
    "text": "The Chain Rule: Composition\nFunction: \\(f(x) = (3x^{2} + 2)^{5}\\)\n\n\nDifferentiate the Inner Function\n\n\\(\\frac{d}{dx}(3x^2 + 2) = 6x\\)\n\n\n\nCombine the results\n\n\\(f{'}(x)=5(3x^2 + 2)^{4} \\cdot 6x\\)\n\\(f{'}(x)=30x(3x^2 + 2)^{4}\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#the-chain-rule-nested-composition",
    "href": "slides/20-calculus-I.html#the-chain-rule-nested-composition",
    "title": "Calculus I",
    "section": "The Chain Rule: Nested composition",
    "text": "The Chain Rule: Nested composition\nFunction: \\(g(x) = \\sin(x^3 + 4x)\\)\n\n\nIdentify the Outer and Inner Functions\n\n\n\nOuter function: \\(\\sin(u)\\)\nInner function: \\(u=x^3+4x\\)\n\n\n\n\n\nApply the Chain Rule\n\n\\(g'(x) = \\cos(x^3 + 4x) \\cdot \\frac{d}{dx}(x^3 + 4x)\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#the-chain-rule-nested-composition-1",
    "href": "slides/20-calculus-I.html#the-chain-rule-nested-composition-1",
    "title": "Calculus I",
    "section": "The Chain Rule: Nested composition",
    "text": "The Chain Rule: Nested composition\nFunction: \\(g(x) = \\sin(x^3 + 4x)\\)\n\n\nDifferentiate the Inner Function\n\n\\(\\frac{d}{dx}(x^3 + 4x) = 3x^2 + 4\\)\n\n\n\nCombine the Results\n\n\\(g'(x) = \\cos(x^3 + 4x) \\cdot (3x^2 + 4)\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#the-chain-rule-complex-nested-composition",
    "href": "slides/20-calculus-I.html#the-chain-rule-complex-nested-composition",
    "title": "Calculus I",
    "section": "The Chain Rule: Complex nested composition",
    "text": "The Chain Rule: Complex nested composition\nFunction: \\(h(x) = \\left( e^{x^2} \\cdot \\ln(x) \\right)^2\\)\n\n\nIdentify the Outer and Inner Functions\n\n\n\nOuter function: \\(u^2\\)\nInner function: \\(u=e^{x^{2}} \\cdot \\ln(x)\\)\n\n\n\n\n\nApply the Chain Rule\n\n\\(h'(x) = 2\\left( e^{x^2} \\cdot \\ln(x) \\right) \\cdot \\frac{d}{dx}(e^{x^2} \\cdot \\ln(x))\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#the-chain-rule-complex-nested-composition-1",
    "href": "slides/20-calculus-I.html#the-chain-rule-complex-nested-composition-1",
    "title": "Calculus I",
    "section": "The Chain Rule: Complex nested composition",
    "text": "The Chain Rule: Complex nested composition\nFunction: \\(h(x) = \\left( e^{x^2} \\cdot \\ln(x) \\right)^2\\)\n\n\nDifferentiate the Inner Function using the Product Rule\n\n\n\nInner function: \\(u=e^{x^{2}} \\cdot \\ln(x)\\)\nProduct rule: \\((u \\cdot v)' = u' \\cdot v + u \\cdot v'\\)\nLet \\(u = e^{x^2}\\) and \\(\\quad v = \\ln(x)\\)\n\\(u' = \\frac{d}{dx}(e^{x^2}) = 2xe^{x^2}\\)\n\\(v' = \\frac{d}{dx}(\\ln(x)) = \\frac{1}{x}\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#the-chain-rule-complex-nested-composition-2",
    "href": "slides/20-calculus-I.html#the-chain-rule-complex-nested-composition-2",
    "title": "Calculus I",
    "section": "The Chain Rule: Complex nested composition",
    "text": "The Chain Rule: Complex nested composition\nFunction: \\(h(x) = \\left( e^{x^2} \\cdot \\ln(x) \\right)^2\\)\n\n\nCombine the Produce Rule Results\n\n\n\n\\(\\frac{d}{dx}(e^{x^2} \\cdot \\ln(x)) = (2xe^{x^2}) \\cdot \\ln(x) + e^{x^2} \\cdot \\frac{1}{x}\\)\n\\(= 2xe^{x^2} \\ln(x) + \\frac{e^{x^2}}{x}\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#the-chain-rule-complex-nested-composition-3",
    "href": "slides/20-calculus-I.html#the-chain-rule-complex-nested-composition-3",
    "title": "Calculus I",
    "section": "The Chain Rule: Complex nested composition",
    "text": "The Chain Rule: Complex nested composition\nFunction: \\(h(x) = \\left( e^{x^2} \\cdot \\ln(x) \\right)^2\\)\n\n\nCombine with the Outer Function Derivative\n\n\n\n\\(h'(x) = 2\\left( e^{x^2} \\cdot \\ln(x) \\right) \\cdot \\left( 2xe^{x^2} \\ln(x) + \\frac{e^{x^2}}{x} \\right)\\)\nSimplify:\n\\(h'(x) = 2e^{x^2} \\ln(x) \\left( 2xe^{x^2} \\ln(x) + \\frac{e^{x^2}}{x} \\right)\\)\n\\(h'(x) = 2e^{x^2} \\ln(x) \\left( 2xe^{x^2} \\ln(x) + e^{x^2} \\cdot x^{-1} \\right)\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#partial-derivatives-1",
    "href": "slides/20-calculus-I.html#partial-derivatives-1",
    "title": "Calculus I",
    "section": "Partial derivatives",
    "text": "Partial derivatives\nDefinition:\n\n\nA partial derivative represents the rate of change of a function with respect to one variable while keeping other variables constant.\nNotation: \\(\\frac{\\partial f}{\\partial x}\\) denotes the partial derivative of \\(f\\) with respect to \\(x\\)."
  },
  {
    "objectID": "slides/20-calculus-I.html#partial-derivatives-2",
    "href": "slides/20-calculus-I.html#partial-derivatives-2",
    "title": "Calculus I",
    "section": "Partial derivatives",
    "text": "Partial derivatives\nSignificance:\n\n\nEssential in understanding functions of multiple variables.\nCrucial for optimization in multivariable calculus.\nUsed in various fields such as physics, engineering, and economics to model complex systems."
  },
  {
    "objectID": "slides/20-calculus-I.html#application-in-multi-variable-functions",
    "href": "slides/20-calculus-I.html#application-in-multi-variable-functions",
    "title": "Calculus I",
    "section": "Application in multi-variable functions",
    "text": "Application in multi-variable functions\n\nMulti-variable functions:\n\n\nFunctions that depend on two or more variables, e.g., \\(f(x,y)=x^2+y^2\\)\n\n\n\n\nGradient:\n\n\nThe vector of all partial derivatives in a function.\nIndicates the direction of the steepest ascent\nNotation: \\(\\nabla f=(\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y})\\)"
  },
  {
    "objectID": "slides/20-calculus-I.html#partial-derivatives-in-python",
    "href": "slides/20-calculus-I.html#partial-derivatives-in-python",
    "title": "Calculus I",
    "section": "Partial derivatives in Python",
    "text": "Partial derivatives in Python\nGiven the function \\(f(x,y)=x^3+3xy+y^3\\), calculate the partial derivatives with respect to \\(x\\) and \\(y\\):\n\nfrom sympy import symbols, diff\n\n# Define the variables and function\nx, y = symbols('x y')\nf = x**3 + 3*x*y + y**3\n\n# Calculate partial derivatives\npartial_x = diff(f, x)\npartial_y = diff(f, y)\n\nprint(partial_x)  # Output: 3*x**2 + 3*y\nprint(partial_y)  # Output: 3*x + 3*y**2\n\n3*x**2 + 3*y\n3*x + 3*y**2"
  },
  {
    "objectID": "slides/20-calculus-I.html#gradient-descent",
    "href": "slides/20-calculus-I.html#gradient-descent",
    "title": "Calculus I",
    "section": "Gradient descent",
    "text": "Gradient descent\nYou’ll learn more about this in INFO 521: Introduction to Machine Learning"
  },
  {
    "objectID": "slides/20-calculus-I.html#ae-13-derivation",
    "href": "slides/20-calculus-I.html#ae-13-derivation",
    "title": "Calculus I",
    "section": "ae-13-derivation",
    "text": "ae-13-derivation\nDerivations (you will be tested on this in Exam 2)\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/12-conditional-probability.html#conditional-probability",
    "href": "slides/12-conditional-probability.html#conditional-probability",
    "title": "Conditional Probability",
    "section": "Conditional probability",
    "text": "Conditional probability\nThe probability an event will occur given that another event has already occurred is a conditional probability. The conditional probability of event \\(A\\) given event \\(B\\) is:\n\n\\[P(A | B) = \\frac{P(A \\text{ and } B)}{P(B)}\\]"
  },
  {
    "objectID": "slides/12-conditional-probability.html#conditional-probabilities",
    "href": "slides/12-conditional-probability.html#conditional-probabilities",
    "title": "Conditional Probability",
    "section": "Conditional probabilities",
    "text": "Conditional probabilities\n\n\\[P(A | B) = \\frac{P(A \\text{ and } B)}{P(B)}\\]\n\nExamples come up all the time in the real world:\n\n\nGiven that it rained yesterday, what is the probability that it will rain today?\nGiven that a mammogram comes back positive, what is the probability that a woman has breast cancer?\nGiven that I’ve already watched six episodes of How I Met Your Mother tonight, what is the probability that I’ll get any work done this evening?"
  },
  {
    "objectID": "slides/12-conditional-probability.html#coffee-and-mortality",
    "href": "slides/12-conditional-probability.html#coffee-and-mortality",
    "title": "Conditional Probability",
    "section": "Coffee and mortality",
    "text": "Coffee and mortality\n\n\n\n\n\n\n\n\n\n\n\nDid not die\n\nDied\n\n\n\n\nDoes not drink coffee\n5438\n1039\n\n\nDrinks coffee occasionally\n29712\n4440\n\n\nDrinks coffee regularly\n24934\n3601"
  },
  {
    "objectID": "slides/12-conditional-probability.html#three-probabilities",
    "href": "slides/12-conditional-probability.html#three-probabilities",
    "title": "Conditional Probability",
    "section": "Three probabilities",
    "text": "Three probabilities\n\n\n\n\n\n\n\n\n\n\nDid not die\n\nDied\n\n\n\n\nDoes not drink coffee\n5438\n1039\n\n\nDrinks coffee occasionally\n29712\n4440\n\n\nDrinks coffee regularly\n24934\n3601\n\n\n\n\nDefine events \\(A\\) = died and \\(B\\) = non-coffee drinker. Calculate the following for a randomly selected person in the cohort:\n\n\nMarginal probability: \\(P(A)\\), \\(P(B)\\)\nJoint probability: \\(P(A \\text{ and } B)\\)\nConditional probability: \\(P(A | B)\\), \\(P(B | A)\\)"
  },
  {
    "objectID": "slides/12-conditional-probability.html#the-multiplicative-rule",
    "href": "slides/12-conditional-probability.html#the-multiplicative-rule",
    "title": "Conditional Probability",
    "section": "The multiplicative rule",
    "text": "The multiplicative rule\nWe can write the definition of condition probability\n\n\\[P(A | B) = \\frac{P(A \\text{ and } B)}{P(B)}\\]\n\n\n\n\nUsing the equation above, we get…\n\\[P(B) \\times P(A | B) = P(A \\text{ and } B)\\]\n\nWhat does the multiplicative rule mean in plain English?"
  },
  {
    "objectID": "slides/12-conditional-probability.html#defining-independence",
    "href": "slides/12-conditional-probability.html#defining-independence",
    "title": "Conditional Probability",
    "section": "Defining independence",
    "text": "Defining independence\nEvents \\(A\\) and \\(B\\) are said to be independent when\n\\[P(A | B) = P(A) \\hspace{10mm} \\textbf{OR} \\hspace{10mm}\nP(B | A) = P(B)\\]\n\n\nIn other words, knowing that one event has occurred doesn’t cause us to “adjust” the probability we assign to another event."
  },
  {
    "objectID": "slides/12-conditional-probability.html#checking-independence",
    "href": "slides/12-conditional-probability.html#checking-independence",
    "title": "Conditional Probability",
    "section": "Checking independence",
    "text": "Checking independence\nWe can use the multiplicative rule to see if two events are independent.\n\nIf events \\(A\\) and \\(B\\) are independent, then\n\\[P(A \\text{ and } B) = P(A) \\times P(B)\\]"
  },
  {
    "objectID": "slides/12-conditional-probability.html#independent-vs.-disjoint-events",
    "href": "slides/12-conditional-probability.html#independent-vs.-disjoint-events",
    "title": "Conditional Probability",
    "section": "Independent vs. disjoint events",
    "text": "Independent vs. disjoint events\nSince for two independent events \\(P(A|B) = P(A)\\) and \\(P(B|A) = P(B)\\), knowing that one event has occurred tells us nothing more about the probability of the other occurring.\n\nFor two disjoint events \\(A\\) and \\(B\\), knowing that one has occurred tells us that the other definitely has not occurred: \\(P(A \\text{ and } B) = 0\\).\n\n\n\nDisjoint events are not independent!"
  },
  {
    "objectID": "slides/12-conditional-probability.html#checking-independence-1",
    "href": "slides/12-conditional-probability.html#checking-independence-1",
    "title": "Conditional Probability",
    "section": "Checking independence",
    "text": "Checking independence\n\n\n\n\n\n\n\n\n\n\nDid not die\n\nDied\n\n\n\n\nDoes not drink coffee\n5438\n1039\n\n\nDrinks coffee occasionally\n29712\n4440\n\n\nDrinks coffee regularly\n24934\n3601\n\n\n\n\n\n\nAre dying and abstaining from coffee independent events? How might we check?"
  },
  {
    "objectID": "slides/12-conditional-probability.html#an-example",
    "href": "slides/12-conditional-probability.html#an-example",
    "title": "Conditional Probability",
    "section": "An example",
    "text": "An example\nIn an introductory statistics course, 50% of students were first years, 30% were sophomores, and 20% were upperclassmen.\n\n80% of the first years didn’t get enough sleep, 40% of the sophomores didn’t get enough sleep, and 10% of the upperclassmen didn’t get enough sleep.\n\n\n\nWhat is the probability that a randomly selected student in this class didn’t get enough sleep?"
  },
  {
    "objectID": "slides/12-conditional-probability.html#bayes-rule-1",
    "href": "slides/12-conditional-probability.html#bayes-rule-1",
    "title": "Conditional Probability",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\nAs we saw before, the two conditional probabilities \\(P(A | B)\\) and \\(P(B | A)\\) are not the same. But are they related in some way?\n\nYes they are (!) using Bayes’ rule:\n\nBayes’ rule:\n\\[\\begin{align}P(A | B) &= \\frac{P(A \\text{ and } B)}{P(B)}\\\\[10pt]\n&= \\frac{P(B | A)P(A)}{P(B)}\n\\end{align}\\]"
  },
  {
    "objectID": "slides/12-conditional-probability.html#bayes-rule-continued",
    "href": "slides/12-conditional-probability.html#bayes-rule-continued",
    "title": "Conditional Probability",
    "section": "Bayes’ Rule (continued)",
    "text": "Bayes’ Rule (continued)\nPutting together a few rules of probability…\n\\[\\begin{align}P(A | B) &= \\frac{P(A \\text{ and } B)}{P(B)}\\\\[10pt]\n&= \\frac{P(B | A)P(A)}{P(B)}\\\\[15pt]\n&= \\frac{P(B | A)P(A)}{P(B | A)P(A) + P(B | A^c)P(A^c)}\\end{align}\\]\nLet’s took at an example to see how this works."
  },
  {
    "objectID": "slides/12-conditional-probability.html#definitions",
    "href": "slides/12-conditional-probability.html#definitions",
    "title": "Conditional Probability",
    "section": "Definitions",
    "text": "Definitions\nSuppose we’re interested in the performance of a diagnostic test. Let \\(D\\) be the event that a patient has the disease, and let \\(T\\) be the event that the test is positive for that disease.\n\n\nPrevalence: \\(P(D)\\)\nSensitivity: \\(P(T | D)\\)\nSpecificity: \\(P(T^c | D^c)\\)\nPositive predictive value: \\(P(D | T)\\)\nNegative predictive value: \\(P(D^c | T^c)\\)\n\n\n\n\nWhat do these probabilities mean in plain English?"
  },
  {
    "objectID": "slides/12-conditional-probability.html#rapid-self-administered-covid-19-tests",
    "href": "slides/12-conditional-probability.html#rapid-self-administered-covid-19-tests",
    "title": "Conditional Probability",
    "section": "Rapid self-administered COVID-19 tests",
    "text": "Rapid self-administered COVID-19 tests\n\n\nFor a Abbott BinaxNOW COVID-19 Rapid antigen tests,\n\n\nSensitivity, \\(P(T | D)\\), is 64.2% in symptomatic individuals\nSpecificity, \\(P(T^c | D^c)\\), is 99.8%\nFrom CDC statistics in 2021, with 8.7% prevalence from Pima County, Arizona persons aged ≥10 years.\n\n\n\n\n\n\n\n\n\n\n\nSuppose a randomly selected American aged 13+ has a positive test result. What is the probability they have COVID-19?"
  },
  {
    "objectID": "slides/12-conditional-probability.html#using-bayes-rule",
    "href": "slides/12-conditional-probability.html#using-bayes-rule",
    "title": "Conditional Probability",
    "section": "Using Bayes’ Rule",
    "text": "Using Bayes’ Rule\n\\[\\begin{align*}\nP(D | T) &= \\frac{P(D \\text{ and } T)}{P(T)}\\\\\n&= \\frac{P(T | D)P(D)}{P(T)}\\\\[5pt]\n&= \\frac{P(T | D)P(D)}{P(T | D)P(D) + P(T | D^c)P(D^c)}\\\\[5pt]\n&= \\frac{P(T | D)P(D)}{P(T | D)P(D) + (1 - P(T^c | D^c))(1 - P(D))}\n\\end{align*}\\]\n\n\n\nWhat does all of this mean? Let’s take a look!"
  },
  {
    "objectID": "slides/12-conditional-probability.html#ae-08",
    "href": "slides/12-conditional-probability.html#ae-08",
    "title": "Conditional Probability",
    "section": "ae-08",
    "text": "ae-08\nGiven:\n\n\nPrevalence: \\(P(D)\\) = 8.7% = 0.087\nSensitivity: \\(P(T | D)\\) = 64.2% = 0.642\nSpecificity: \\(P(T^c | D^c)\\) = 99.8% = 0.998\n\n\n\nWork through ae-08 then move on to the discussion questions"
  },
  {
    "objectID": "slides/12-conditional-probability.html#a-discussion",
    "href": "slides/12-conditional-probability.html#a-discussion",
    "title": "Conditional Probability",
    "section": "A discussion",
    "text": "A discussion\nThink about the following questions:\n\n\nIs this calculation surprising?\nWhat is the explanation?\nWas this calculation actually reasonable to perform?\nWhat if we tested in a different population, such as high-risk individuals?\nWhat if we were to test a random individual in a county where the prevalence of COVID-19 is approximately 25%?\n\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/17-logistic-regression.html#setup",
    "href": "slides/17-logistic-regression.html#setup",
    "title": "Logistic regression",
    "section": "Setup",
    "text": "Setup\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nsns.set_theme(style=\"whitegrid\", rc={\"figure.figsize\": (10, 6), \"axes.labelsize\": 16, \"xtick.labelsize\": 14, \"ytick.labelsize\": 14})"
  },
  {
    "objectID": "slides/17-logistic-regression.html#recap-modeling-loans",
    "href": "slides/17-logistic-regression.html#recap-modeling-loans",
    "title": "Logistic regression",
    "section": "Recap: Modeling Loans",
    "text": "Recap: Modeling Loans\n\nWhat is the practical difference between a model with parallel and non-parallel lines?\nWhat is the definition of R-squared?\nWhy do we choose models based on adjusted R-squared and not R-squared?"
  },
  {
    "objectID": "slides/17-logistic-regression.html#predict-interest-rate",
    "href": "slides/17-logistic-regression.html#predict-interest-rate",
    "title": "Logistic regression",
    "section": "Predict interest rate…",
    "text": "Predict interest rate…\nfrom credit utilization and homeownership\n\nX = loans[['credit_util', 'homeownership']]\nX = pd.get_dummies(X, drop_first=True).astype(float)\ny = loans['interest_rate']\n\nX = sm.add_constant(X)  \nmodel = sm.OLS(y, X).fit()\n\n\nprint(model.summary2())\n\n                   Results: Ordinary least squares\n=====================================================================\nModel:                OLS              Adj. R-squared:     0.068     \nDependent Variable:   interest_rate    AIC:                59859.3779\nDate:                 2024-08-19 13:43 BIC:                59888.2185\nNo. Observations:     9998             Log-Likelihood:     -29926.   \nDf Model:             3                F-statistic:        243.7     \nDf Residuals:         9994             Prob (F-statistic): 1.25e-152 \nR-squared:            0.068            Scale:              23.309    \n---------------------------------------------------------------------\n                       Coef.  Std.Err.    t    P&gt;|t|   [0.025  0.975]\n---------------------------------------------------------------------\nconst                  9.9250   0.1401 70.8498 0.0000  9.6504 10.1996\ncredit_util            5.3356   0.2074 25.7266 0.0000  4.9291  5.7421\nhomeownership_Mortgage 0.6956   0.1208  5.7590 0.0000  0.4588  0.9323\nhomeownership_Own      0.1283   0.1552  0.8266 0.4085 -0.1760  0.4326\n---------------------------------------------------------------------\nOmnibus:              1150.070       Durbin-Watson:          1.981   \nProb(Omnibus):        0.000          Jarque-Bera (JB):       1616.376\nSkew:                 0.900          Prob(JB):               0.000   \nKurtosis:             3.800          Condition No.:          6       \n=====================================================================\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors\nis correctly specified."
  },
  {
    "objectID": "slides/17-logistic-regression.html#intercept",
    "href": "slides/17-logistic-regression.html#intercept",
    "title": "Logistic regression",
    "section": "Intercept",
    "text": "Intercept\n\n\n                   Results: Ordinary least squares\n=====================================================================\nModel:                OLS              Adj. R-squared:     0.068     \nDependent Variable:   interest_rate    AIC:                59859.3779\nDate:                 2024-08-19 13:43 BIC:                59888.2185\nNo. Observations:     9998             Log-Likelihood:     -29926.   \nDf Model:             3                F-statistic:        243.7     \nDf Residuals:         9994             Prob (F-statistic): 1.25e-152 \nR-squared:            0.068            Scale:              23.309    \n---------------------------------------------------------------------\n                       Coef.  Std.Err.    t    P&gt;|t|   [0.025  0.975]\n---------------------------------------------------------------------\nconst                  9.9250   0.1401 70.8498 0.0000  9.6504 10.1996\ncredit_util            5.3356   0.2074 25.7266 0.0000  4.9291  5.7421\nhomeownership_Mortgage 0.6956   0.1208  5.7590 0.0000  0.4588  0.9323\nhomeownership_Own      0.1283   0.1552  0.8266 0.4085 -0.1760  0.4326\n---------------------------------------------------------------------\nOmnibus:              1150.070       Durbin-Watson:          1.981   \nProb(Omnibus):        0.000          Jarque-Bera (JB):       1616.376\nSkew:                 0.900          Prob(JB):               0.000   \nKurtosis:             3.800          Condition No.:          6       \n=====================================================================\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors\nis correctly specified.\n\n\n\nIntercept: Loan applicants who rent and have 0 credit utilization are predicted to receive an interest rate of 9.93%, on average."
  },
  {
    "objectID": "slides/17-logistic-regression.html#slopes",
    "href": "slides/17-logistic-regression.html#slopes",
    "title": "Logistic regression",
    "section": "Slopes",
    "text": "Slopes\n\nModelSlope\n\n\n\n\n                   Results: Ordinary least squares\n=====================================================================\nModel:                OLS              Adj. R-squared:     0.068     \nDependent Variable:   interest_rate    AIC:                59859.3779\nDate:                 2024-08-19 13:43 BIC:                59888.2185\nNo. Observations:     9998             Log-Likelihood:     -29926.   \nDf Model:             3                F-statistic:        243.7     \nDf Residuals:         9994             Prob (F-statistic): 1.25e-152 \nR-squared:            0.068            Scale:              23.309    \n---------------------------------------------------------------------\n                       Coef.  Std.Err.    t    P&gt;|t|   [0.025  0.975]\n---------------------------------------------------------------------\nconst                  9.9250   0.1401 70.8498 0.0000  9.6504 10.1996\ncredit_util            5.3356   0.2074 25.7266 0.0000  4.9291  5.7421\nhomeownership_Mortgage 0.6956   0.1208  5.7590 0.0000  0.4588  0.9323\nhomeownership_Own      0.1283   0.1552  0.8266 0.4085 -0.1760  0.4326\n---------------------------------------------------------------------\nOmnibus:              1150.070       Durbin-Watson:          1.981   \nProb(Omnibus):        0.000          Jarque-Bera (JB):       1616.376\nSkew:                 0.900          Prob(JB):               0.000   \nKurtosis:             3.800          Condition No.:          6       \n=====================================================================\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors\nis correctly specified.\n\n\n\n\n\n\nAll else held constant, for each additional percent credit utilization is higher, interest rate is predicted to be higher, on average, by 0.0534%.\nAll else held constant, the model predicts that loan applicants who have a mortgage for their home receive 0.696% higher interest rate than those who rent their home, on average.\nAll else held constant, the model predicts that loan applicants who own their home receive 0.128% higher interest rate than those who rent their home, on average."
  },
  {
    "objectID": "slides/17-logistic-regression.html#predict-loginterest-rate",
    "href": "slides/17-logistic-regression.html#predict-loginterest-rate",
    "title": "Logistic regression",
    "section": "Predict log(interest rate)",
    "text": "Predict log(interest rate)\n\nX_log = loans[['credit_checks']]\nX_log = sm.add_constant(X_log)\ny_log = np.log(loans['interest_rate'])\n\nmodel_log = sm.OLS(y_log, X_log).fit()"
  },
  {
    "objectID": "slides/17-logistic-regression.html#model-1",
    "href": "slides/17-logistic-regression.html#model-1",
    "title": "Logistic regression",
    "section": "Model",
    "text": "Model\n\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:          interest_rate   R-squared:                       0.020\nModel:                            OLS   Adj. R-squared:                  0.020\nMethod:                 Least Squares   F-statistic:                     202.2\nDate:                Mon, 19 Aug 2024   Prob (F-statistic):           1.91e-45\nTime:                        13:43:48   Log-Likelihood:                -4912.6\nNo. Observations:                9998   AIC:                             9829.\nDf Residuals:                    9996   BIC:                             9844.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nconst             2.3947      0.005    467.428      0.000       2.385       2.405\ncredit_checks     0.0236      0.002     14.220      0.000       0.020       0.027\n==============================================================================\nOmnibus:                      329.756   Durbin-Watson:                   2.002\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              152.256\nSkew:                          -0.010   Prob(JB):                     8.67e-34\nKurtosis:                       2.396   Cond. No.                         4.17\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\\[\n\\widehat{log(interest~rate)} = 2.39 + 0.0236 \\times credit~checks\n\\]"
  },
  {
    "objectID": "slides/17-logistic-regression.html#slope-1",
    "href": "slides/17-logistic-regression.html#slope-1",
    "title": "Logistic regression",
    "section": "Slope",
    "text": "Slope\n\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:          interest_rate   R-squared:                       0.020\nModel:                            OLS   Adj. R-squared:                  0.020\nMethod:                 Least Squares   F-statistic:                     202.2\nDate:                Mon, 19 Aug 2024   Prob (F-statistic):           1.91e-45\nTime:                        13:43:48   Log-Likelihood:                -4912.6\nNo. Observations:                9998   AIC:                             9829.\nDf Residuals:                    9996   BIC:                             9844.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nconst             2.3947      0.005    467.428      0.000       2.385       2.405\ncredit_checks     0.0236      0.002     14.220      0.000       0.020       0.027\n==============================================================================\nOmnibus:                      329.756   Durbin-Watson:                   2.002\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              152.256\nSkew:                          -0.010   Prob(JB):                     8.67e-34\nKurtosis:                       2.396   Cond. No.                         4.17\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nFor each additional credit check, log of interest rate is predicted to be higher, on average, by 0.0236%."
  },
  {
    "objectID": "slides/17-logistic-regression.html#slope-2",
    "href": "slides/17-logistic-regression.html#slope-2",
    "title": "Logistic regression",
    "section": "Slope",
    "text": "Slope\n\\[\nlog(interest~rate_{x+1}) - log(interest~rate_{x}) =  0.0236\n\\]\n\n\\[\nlog(\\frac{interest~rate_{x+1}}{interest~rate_{x}}) = 0.0236\n\\]\n\n\n\\[\ne^{log(\\frac{interest~rate_{x+1}}{interest~rate_{x}})} = e^{0.0236}\n\\]\n\n\n\\[\n\\frac{interest~rate_{x+1}}{interest~rate_{x}} = 1.024\n\\]\n\n\nFor each additional credit check, interest rate is predicted to be higher, on average, by a factor of 1.024."
  },
  {
    "objectID": "slides/17-logistic-regression.html#what-is-logistic-regression",
    "href": "slides/17-logistic-regression.html#what-is-logistic-regression",
    "title": "Logistic regression",
    "section": "What is logistic regression?",
    "text": "What is logistic regression?\n\n\n\n\nSimilar to linear regression…. but\nModeling tool when our response is categorical"
  },
  {
    "objectID": "slides/17-logistic-regression.html#modelling-binary-outcomes",
    "href": "slides/17-logistic-regression.html#modelling-binary-outcomes",
    "title": "Logistic regression",
    "section": "Modelling binary outcomes",
    "text": "Modelling binary outcomes\n\n\nVariables with binary outcomes follow the Bernouilli distribution:\n\n\\(y_i \\sim Bern(p)\\)\n\\(p\\): Probability of success\n\\(1-p\\): Probability of failure\n\nWe can’t model \\(y\\) directly, so instead we model \\(p\\)"
  },
  {
    "objectID": "slides/17-logistic-regression.html#linear-model",
    "href": "slides/17-logistic-regression.html#linear-model",
    "title": "Logistic regression",
    "section": "Linear model",
    "text": "Linear model\n\\[\np_i = \\beta_o + \\beta_1 \\times X_1 + \\cdots + \\epsilon\n\\]\n\n\nBut remember that \\(p\\) must be between 0 and 1\nWe need a link function that transforms the linear model to have an appropriate range"
  },
  {
    "objectID": "slides/17-logistic-regression.html#logit-link-function",
    "href": "slides/17-logistic-regression.html#logit-link-function",
    "title": "Logistic regression",
    "section": "Logit link function",
    "text": "Logit link function\nThe logit function take values between 0 and 1 (probabilities) and maps them to values in the range negative infinity to positive infinity:\n\\[\nlogit(p) = log \\bigg( \\frac{p}{1 - p} \\bigg)\n\\]"
  },
  {
    "objectID": "slides/17-logistic-regression.html#this-isnt-exactly-what-we-need-though..",
    "href": "slides/17-logistic-regression.html#this-isnt-exactly-what-we-need-though..",
    "title": "Logistic regression",
    "section": "This isn’t exactly what we need though…..",
    "text": "This isn’t exactly what we need though…..\n\n\nRecall, the goal is to take values between -\\(\\infty\\) and \\(\\infty\\) and map them to probabilities.\nWe need the opposite of the link function… or the inverse\nTaking the inverse of the logit function will map arbitrary real values back to the range [0, 1]"
  },
  {
    "objectID": "slides/17-logistic-regression.html#generalized-linear-model",
    "href": "slides/17-logistic-regression.html#generalized-linear-model",
    "title": "Logistic regression",
    "section": "Generalized linear model",
    "text": "Generalized linear model\n\n\nWe model the logit (log-odds) of \\(p\\) :\n\n\n\n\\[\nlogit(p) = log \\bigg( \\frac{p}{1 - p} \\bigg) = \\beta_o + \\beta_1 \\times X1_i + \\cdots + \\epsilon\n\\]\n\n\n\nThen take the inverse to obtain the predicted \\(p\\):\n\n\n\n\\[\np_i = \\frac{e^{\\beta_o + \\beta_1 \\times X1_i + \\cdots + \\epsilon}}{1 + e^{\\beta_o + \\beta_1 \\times X1_i + \\cdots + \\epsilon}}\n\\]"
  },
  {
    "objectID": "slides/17-logistic-regression.html#a-logistic-model-visualized",
    "href": "slides/17-logistic-regression.html#a-logistic-model-visualized",
    "title": "Logistic regression",
    "section": "A logistic model visualized",
    "text": "A logistic model visualized"
  },
  {
    "objectID": "slides/17-logistic-regression.html#takeaways",
    "href": "slides/17-logistic-regression.html#takeaways",
    "title": "Logistic regression",
    "section": "Takeaways",
    "text": "Takeaways\n\n\nGeneralized linear models allow us to fit models to predict non-continuous outcomes\nPredicting binary outcomes requires modeling the log-odds of success, where p = probability of success\n\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/04-eda.html#setup",
    "href": "slides/04-eda.html#setup",
    "title": "Exploratory data analysis",
    "section": "Setup",
    "text": "Setup\n\n# Import all required libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nfrom scipy.stats import skewnorm\nfrom scipy.stats import kurtosis, norm\nfrom scipy.stats import gamma\nimport missingno as msno\nimport random\nimport statsmodels.api as sm\n\n# Load in UK Smoking Data\nbirths14 = pd.read_csv(\"data/births14.csv\")\n\n# Set seed\nrandom.seed(123)"
  },
  {
    "objectID": "slides/04-eda.html#what-is-exploratory-data-analysis",
    "href": "slides/04-eda.html#what-is-exploratory-data-analysis",
    "title": "Exploratory data analysis",
    "section": "What is exploratory data analysis?",
    "text": "What is exploratory data analysis?\n\nExploratory Data Analysis is a statistical approach to analyzing datasets to summarize their main characteristics, often using visual methods."
  },
  {
    "objectID": "slides/04-eda.html#examining-data",
    "href": "slides/04-eda.html#examining-data",
    "title": "Exploratory data analysis",
    "section": "Examining data",
    "text": "Examining data\n\nHeadInfoDescribe\n\n\n\nbirths14.head()\n\n\n\n\n\n\n\n\nfage\nmage\nmature\nweeks\npremie\nvisits\ngained\nweight\nlowbirthweight\nsex\nhabit\nmarital\nwhitemom\n\n\n\n\n0\n34.0\n34\nyounger mom\n37\nfull term\n14.0\n28.0\n6.96\nnot low\nmale\nnonsmoker\nmarried\nwhite\n\n\n1\n36.0\n31\nyounger mom\n41\nfull term\n12.0\n41.0\n8.86\nnot low\nfemale\nnonsmoker\nmarried\nwhite\n\n\n2\n37.0\n36\nmature mom\n37\nfull term\n10.0\n28.0\n7.51\nnot low\nfemale\nnonsmoker\nmarried\nnot white\n\n\n3\nNaN\n16\nyounger mom\n38\nfull term\nNaN\n29.0\n6.19\nnot low\nmale\nnonsmoker\nnot married\nwhite\n\n\n4\n32.0\n31\nyounger mom\n36\npremie\n12.0\n48.0\n6.75\nnot low\nfemale\nnonsmoker\nmarried\nwhite\n\n\n\n\n\n\n\n\n\n\nbirths14.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 13 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   fage            886 non-null    float64\n 1   mage            1000 non-null   int64  \n 2   mature          1000 non-null   object \n 3   weeks           1000 non-null   int64  \n 4   premie          1000 non-null   object \n 5   visits          944 non-null    float64\n 6   gained          958 non-null    float64\n 7   weight          1000 non-null   float64\n 8   lowbirthweight  1000 non-null   object \n 9   sex             1000 non-null   object \n 10  habit           981 non-null    object \n 11  marital         1000 non-null   object \n 12  whitemom        1000 non-null   object \ndtypes: float64(4), int64(2), object(7)\nmemory usage: 101.7+ KB\n\n\n\n\n\nbirths14.describe()\n\n\n\n\n\n\n\n\nfage\nmage\nweeks\nvisits\ngained\nweight\n\n\n\n\ncount\n886.000000\n1000.000000\n1000.000000\n944.000000\n958.000000\n1000.000000\n\n\nmean\n31.133183\n28.449000\n38.666000\n11.351695\n30.425887\n7.198160\n\n\nstd\n7.058135\n5.759737\n2.564961\n4.108192\n15.242527\n1.306775\n\n\nmin\n15.000000\n14.000000\n21.000000\n0.000000\n0.000000\n0.750000\n\n\n25%\n26.000000\n24.000000\n38.000000\n9.000000\n20.000000\n6.545000\n\n\n50%\n31.000000\n28.000000\n39.000000\n12.000000\n30.000000\n7.310000\n\n\n75%\n35.000000\n33.000000\n40.000000\n14.000000\n38.000000\n8.000000\n\n\nmax\n85.000000\n47.000000\n46.000000\n30.000000\n98.000000\n10.620000"
  },
  {
    "objectID": "slides/04-eda.html#visualizing-data-relationships",
    "href": "slides/04-eda.html#visualizing-data-relationships",
    "title": "Exploratory data analysis",
    "section": "Visualizing data relationships",
    "text": "Visualizing data relationships\n\nsns.pairplot(births14[['fage', 'mage', 'weeks', 'mature']], hue='mature', height=2)\nplt.show()"
  },
  {
    "objectID": "slides/04-eda.html#group-descriptive-statistics",
    "href": "slides/04-eda.html#group-descriptive-statistics",
    "title": "Exploratory data analysis",
    "section": "Group descriptive statistics",
    "text": "Group descriptive statistics\n\n# Example with the premie column\nbirths14.groupby('premie').describe()\n\n\n\n\n\n\n\n\nfage\nmage\n...\ngained\nweight\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\ncount\nmean\n...\n75%\nmax\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\npremie\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull term\n775.0\n30.967742\n6.681591\n15.0\n26.0\n31.0\n35.0\n49.0\n876.0\n28.329909\n...\n38.0\n98.0\n876.0\n7.434178\n1.021699\n3.93\n6.77\n7.44\n8.0825\n10.62\n\n\npremie\n111.0\n32.288288\n9.226826\n15.0\n27.0\n32.0\n36.0\n85.0\n124.0\n29.290323\n...\n41.0\n85.0\n124.0\n5.530806\n1.801182\n0.75\n4.50\n5.75\n6.5725\n9.25\n\n\n\n\n2 rows × 48 columns"
  },
  {
    "objectID": "slides/04-eda.html#outliers",
    "href": "slides/04-eda.html#outliers",
    "title": "Exploratory data analysis",
    "section": "Outliers",
    "text": "Outliers\nOutliers are data points that are significantly different from others. Identifying and handling outliers is important in data analysis.\n\n\n\nOutliers = 1.5 * Interquartile range"
  },
  {
    "objectID": "slides/04-eda.html#assess-outliers-visually",
    "href": "slides/04-eda.html#assess-outliers-visually",
    "title": "Exploratory data analysis",
    "section": "Assess outliers visually",
    "text": "Assess outliers visually\n\nsns.boxplot(data = births14, x = 'weight', width = 0.20)\nplt.show()"
  },
  {
    "objectID": "slides/04-eda.html#find-outliers",
    "href": "slides/04-eda.html#find-outliers",
    "title": "Exploratory data analysis",
    "section": "Find outliers",
    "text": "Find outliers\n\nOutputCode\n\n\n\n\nfage: 7 outliers\nmage: 1 outliers\nweeks: 72 outliers\nvisits: 30 outliers\ngained: 26 outliers\nweight: 32 outliers\n\n\n\n\n\nfor column in births14.select_dtypes(include=np.number).columns:\n    q25 = births14[column].quantile(0.25)\n    q75 = births14[column].quantile(0.75)\n    iqr = q75 - q25\n    lower_bound = q25 - 1.5 * iqr\n    upper_bound = q75 + 1.5 * iqr\n    outliers = births14[(births14[column] &lt; lower_bound) | (births14[column] &gt; upper_bound)]\n    print(f\"{column}: {outliers.shape[0]} outliers\")\n\n\n\n\n\n\nq25: 1/4 quartile, 25th percentile; q75: 3/4 quartile, 75th percentile\nIQR: interquartile range, \\(IQR = q75-q25\\)\nlower; upper: lower, upper limit of \\(1.5\\times IQR\\) used to calculate outliers"
  },
  {
    "objectID": "slides/04-eda.html#remove-outliers",
    "href": "slides/04-eda.html#remove-outliers",
    "title": "Exploratory data analysis",
    "section": "Remove outliers",
    "text": "Remove outliers\n\nCleaningPlot\n\n\n\n# Select numerical columns\nnumerical_cols = births14.select_dtypes(include = ['number']).columns\n\nfor col in numerical_cols:\n    # Find Q1, Q3, and interquartile range (IQR) for each column\n    Q1 = births14[col].quantile(0.25)\n    Q3 = births14[col].quantile(0.75)\n    IQR = Q3 - Q1\n    # Upper and lower bounds for each column\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    # Filter out the outliers from the DataFrame\n    births14_clean = births14[(births14[col] &gt;= lower_bound) & (births14[col] &lt;= upper_bound)]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy are there still outliers?"
  },
  {
    "objectID": "slides/04-eda.html#missing-values-nan",
    "href": "slides/04-eda.html#missing-values-nan",
    "title": "Exploratory data analysis",
    "section": "Missing values (NaN)",
    "text": "Missing values (NaN)\n\n# Count missing values in each column\nbirths14.isnull().sum()\n\nfage              114\nmage                0\nmature              0\nweeks               0\npremie              0\nvisits             56\ngained             42\nweight              0\nlowbirthweight      0\nsex                 0\nhabit              19\nmarital             0\nwhitemom            0\ndtype: int64"
  },
  {
    "objectID": "slides/04-eda.html#visualizing-nan",
    "href": "slides/04-eda.html#visualizing-nan",
    "title": "Exploratory data analysis",
    "section": "Visualizing (NaN)",
    "text": "Visualizing (NaN)\nWe can use the missingno library to visualize missing data.\n\nmsno.bar(births14, figsize = (7, 5), fontsize = 10)\nplt.show()"
  },
  {
    "objectID": "slides/04-eda.html#describe-categorical-variables",
    "href": "slides/04-eda.html#describe-categorical-variables",
    "title": "Exploratory data analysis",
    "section": "Describe categorical variables",
    "text": "Describe categorical variables\n\nDescribeUnique levelsCode\n\n\n\nbirths14.describe(exclude = [np.number])\n\n\n\n\n\n\n\n\nmature\npremie\nlowbirthweight\nsex\nhabit\nmarital\nwhitemom\n\n\n\n\ncount\n1000\n1000\n1000\n1000\n981\n1000\n1000\n\n\nunique\n2\n2\n2\n2\n2\n2\n2\n\n\ntop\nyounger mom\nfull term\nnot low\nmale\nnonsmoker\nmarried\nwhite\n\n\nfreq\n841\n876\n919\n505\n867\n594\n765\n\n\n\n\n\n\n\n\n\n\n\nmature: ['younger mom' 'mature mom']\npremie: ['full term' 'premie']\nlowbirthweight: ['not low' 'low']\nsex: ['male' 'female']\nhabit: ['nonsmoker' 'smoker' nan]\nmarital: ['married' 'not married']\nwhitemom: ['white' 'not white']\n\n\n\n\n\nfor column in births14.select_dtypes(include=['object', 'category']).columns:\n    print(f\"{column}: {births14[column].unique()}\")"
  },
  {
    "objectID": "slides/04-eda.html#normality-check-1",
    "href": "slides/04-eda.html#normality-check-1",
    "title": "Exploratory data analysis",
    "section": "Normality check",
    "text": "Normality check\n\n\n\n\n\n\n\n\n\n\n\n\nHistogram: bell-shaped curve\nSkewness: Close to 0 for symmetry; Kurtosis: Close to 3 for normal “tailedness.”\nSample Size: Larger samples are less sensitive to non-normality.\nEmpirical Rule: 68-95-99.7% rule (1, 2, and 3 st dev. of the mean)."
  },
  {
    "objectID": "slides/04-eda.html#skewness",
    "href": "slides/04-eda.html#skewness",
    "title": "Exploratory data analysis",
    "section": "Skewness",
    "text": "Skewness\n\n\n\n\n\n\n\n\n\n\n\n\nSeveral definitions\nSensitive to outliers\nDesigned for one peak (unimodal)"
  },
  {
    "objectID": "slides/04-eda.html#kurtosis",
    "href": "slides/04-eda.html#kurtosis",
    "title": "Exploratory data analysis",
    "section": "Kurtosis",
    "text": "Kurtosis\n\n\n\n\n\n\n\n\n\n\n\n\nSensitive to outliers\nDesigned for one peak (unimodal)"
  },
  {
    "objectID": "slides/04-eda.html#q-q-plot",
    "href": "slides/04-eda.html#q-q-plot",
    "title": "Exploratory data analysis",
    "section": "Q-Q plot",
    "text": "Q-Q plot\n\nNormalNegative skewPositive skew"
  },
  {
    "objectID": "slides/04-eda.html#testing-normality-data-shape",
    "href": "slides/04-eda.html#testing-normality-data-shape",
    "title": "Exploratory data analysis",
    "section": "Testing normality: data shape",
    "text": "Testing normality: data shape\n\n\nCode\n# Make a copy of the data \ndataCopy = births14.copy()\n\n# Remove NAs\ndataCopyFin = dataCopy.dropna()\n\n# Q-Q plot\nsm.qqplot(dataCopyFin.weight, line='s')\nplt.title('Newborn Weight Q-Q plot')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nNegative-skew (left-tailed)"
  },
  {
    "objectID": "slides/04-eda.html#conclusions",
    "href": "slides/04-eda.html#conclusions",
    "title": "Exploratory data analysis",
    "section": "Conclusions",
    "text": "Conclusions\n\n\nAlways inspect your data first.\nVisualize relationships and distributions.\nIdentify and handle outliers and missing values.\nCheck for normality and understand the distribution of your data."
  },
  {
    "objectID": "slides/24-communicate.html#project",
    "href": "slides/24-communicate.html#project",
    "title": "Communicating data science results effectively",
    "section": "Project",
    "text": "Project\n\nReview peer evaluations left by your peers, implement updates as you see fit, close the issue once you review them.\nHave a clear plan for who is doing what, open issues on your repo, and assign them to individuals who can then close the issues as they finish a task.\nSchedule at least one team meeting between today and your presentation to practice your presentation together.\n\n\nAny project questions?"
  },
  {
    "objectID": "slides/24-communicate.html#take-a-sad-plot-make-it-better",
    "href": "slides/24-communicate.html#take-a-sad-plot-make-it-better",
    "title": "Communicating data science results effectively",
    "section": "Take A Sad Plot & Make It Better",
    "text": "Take A Sad Plot & Make It Better\n\n\n\n\n\n\n\nSource: https://alison.netlify.app/rlm-sad-plot-better"
  },
  {
    "objectID": "slides/24-communicate.html#recap-of-data-viz",
    "href": "slides/24-communicate.html#recap-of-data-viz",
    "title": "Communicating data science results effectively",
    "section": "Recap of data viz",
    "text": "Recap of data viz\n\n\nRepresent percentages as parts of a whole\nPlace variables representing time on the x-axis when possible\nPay attention to data types, e.g., represent time as time on a continuous scale, not years as levels of a categorical variable\nPrefer direct labeling over legends\nUse accessible colors\nUse color to draw attention\nPick a purpose and label, color, annotate for that purpose\nCommunicate your main message directly in the plot labels\nSimplify before you call it done (a.k.a. “Before you leave the house, look in the mirror and take one thing off”)"
  },
  {
    "objectID": "slides/24-communicate.html#project-presentations-due-dec-18",
    "href": "slides/24-communicate.html#project-presentations-due-dec-18",
    "title": "Communicating data science results effectively",
    "section": "Project presentations due Dec 18! 🥳",
    "text": "Project presentations due Dec 18! 🥳\n\nMake sure your presentation is pushed to your GitHub repo before the due date.\nAll team members must take part in the presentation\nRecord your 10-minute presentation – you’ll lose 1 point/ minute over 10.\nFill out feedback forms while you listen to others’ presentations."
  },
  {
    "objectID": "slides/24-communicate.html#project-write-ups-due-dec-20",
    "href": "slides/24-communicate.html#project-write-ups-due-dec-20",
    "title": "Communicating data science results effectively",
    "section": "Project write-ups due Dec 20",
    "text": "Project write-ups due Dec 20\n\nThere’s a good chance you’ll be done with these on Monday as well\nBut you might want to improve your write-up based on inspiration from other teams’ presentations and/or ideas that came up during your peer-reviews."
  },
  {
    "objectID": "slides/24-communicate.html#expectations",
    "href": "slides/24-communicate.html#expectations",
    "title": "Communicating data science results effectively",
    "section": "Expectations",
    "text": "Expectations\n\nThe goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like) and apply them to a novel dataset in a meaningful way.\n\nBeyond, if you like – “you” is the whole team!\n\n\n\n\n\n\n\nRead more\n\n\nhttps://datasciaz.netlify.app/project/description.html#introduction"
  },
  {
    "objectID": "slides/24-communicate.html#expectations-1",
    "href": "slides/24-communicate.html#expectations-1",
    "title": "Communicating data science results effectively",
    "section": "Expectations",
    "text": "Expectations\n\nThe goal is not to do an exhaustive data analysis i.e., do not calculate every statistic and procedure you have learned for every variable, but rather let me know that you are proficient at asking meaningful questions and answering them with results of data analysis, that you are proficient in using Python, and that you are proficient at interpreting and presenting the results.\n\n\n\n\n\n\n\n\nRead more\n\n\nhttps://datasciaz.netlify.app/project/description.html#introduction"
  },
  {
    "objectID": "slides/24-communicate.html#requirements",
    "href": "slides/24-communicate.html#requirements",
    "title": "Communicating data science results effectively",
    "section": "Requirements",
    "text": "Requirements\n\nFocus on methods that help you begin to answer your research questions. You do not have to apply every statistical procedure we learned.\n\n\n\n\n\n\n\n\nRead more\n\n\nhttps://datasciaz.netlify.app/project/description.html#introduction"
  },
  {
    "objectID": "slides/24-communicate.html#tip",
    "href": "slides/24-communicate.html#tip",
    "title": "Communicating data science results effectively",
    "section": "Tip",
    "text": "Tip\n\nCritique your own methods and provide suggestions for improving your analysis. Discuss issues pertaining to the reliability and validity of your data, and appropriateness of the statistical analysis.\n\n\n\n\n\n\n\nTip\n\n\nYou can critique the current research without talking about a hypothetical future research.\n\n\n\n\n\n\n\n\n\n\nRead more\n\n\nhttps://datasciaz.netlify.app/project/description.html#introduction"
  },
  {
    "objectID": "slides/24-communicate.html#how-many-plots",
    "href": "slides/24-communicate.html#how-many-plots",
    "title": "Communicating data science results effectively",
    "section": "How many plots",
    "text": "How many plots\n\nYou do not need to visualize all of the data at once. A single high-quality visualization will receive a much higher grade than a large number of poor-quality visualizations.\n\nThere is no specific, secret number of visualizations I’m expecting, the right number is the number that it takes to answer your question.\n\n\n\n\n\n\n\nRead more\n\n\nhttps://datasciaz.netlify.app/project/description.html#introduction"
  },
  {
    "objectID": "slides/24-communicate.html#submission",
    "href": "slides/24-communicate.html#submission",
    "title": "Communicating data science results effectively",
    "section": "Submission",
    "text": "Submission\n\nSubmission of these deliverables will happen on GitHub and feedback will be provided as GitHub issues that you need to engage with and close. The collection of the documents in your GitHub repo will create a webpage for your project. To create the webpage go to VS Code, open a terminal and type quarto publish gh-pages or if you have published via Quarto Pubs `quarto publish quarto-pub\n\n\n\n\n\n\n\n\nRead more\n\n\nhttps://datasciaz.netlify.app/project/description.html#introduction"
  },
  {
    "objectID": "slides/24-communicate.html#writeup",
    "href": "slides/24-communicate.html#writeup",
    "title": "Communicating data science results effectively",
    "section": "Writeup",
    "text": "Writeup\n\n\nIs there any paper that is required as well as the presentation?\nWhat is the project write up?\nAre write ups usually around the 10 page limit?\nIs there a recommended outline to the project?\n\n\n\n\n\n\n\n\nRead more\n\n\nhttps://datasciaz.netlify.app/project/4-writeup-presentation.html#report-components"
  },
  {
    "objectID": "slides/24-communicate.html#grading-rubric",
    "href": "slides/24-communicate.html#grading-rubric",
    "title": "Communicating data science results effectively",
    "section": "Grading / rubric",
    "text": "Grading / rubric\n\n\n\n\n\n\nRead more\n\n\n\nOverall: https://datasciaz.netlify.app/project/description.html#grading-summary\nWrite-up: https://datasciaz.netlify.app/project/4-writeup-presentation.html#report-components\nPresentation: https://datasciaz.netlify.app/project/4-writeup-presentation.html#presentation-slides"
  },
  {
    "objectID": "slides/24-communicate.html#your-project-write-up-with-quarto",
    "href": "slides/24-communicate.html#your-project-write-up-with-quarto",
    "title": "Communicating data science results effectively",
    "section": "Your project write-up with Quarto",
    "text": "Your project write-up with Quarto\n\nChunk options around what makes it in your final report: message, echo, etc.\nCitations.\nFinalizing your report with echo: false."
  },
  {
    "objectID": "slides/24-communicate.html#building-your-project-website-with-quarto",
    "href": "slides/24-communicate.html#building-your-project-website-with-quarto",
    "title": "Communicating data science results effectively",
    "section": "Building your project website with Quarto",
    "text": "Building your project website with Quarto\n\nThe _site folder.\nMaking sure your website reflects your latest changes.\nCustomizing the look of your website."
  },
  {
    "objectID": "slides/24-communicate.html#slides",
    "href": "slides/24-communicate.html#slides",
    "title": "Communicating data science results effectively",
    "section": "Slides",
    "text": "Slides\n\nOption 1: Make your slides not in Quarto but make sure they’re available in your Quarto project website.\nOption 2: Make your slides with Quarto."
  },
  {
    "objectID": "slides/24-communicate.html#something-else",
    "href": "slides/24-communicate.html#something-else",
    "title": "Communicating data science results effectively",
    "section": "Something else 💛",
    "text": "Something else 💛\n\nI have enjoyed this semester, and I want to continue learning Python. What classes do you recommend I take to continue my learning?\n\n\nINFO 523: Data Mining and Discovery - Python essentially for applied ML\nINFO 521: Intro to Machine Learning - Python as a part of the ML curriculum"
  },
  {
    "objectID": "slides/15-linear-regression.html#setup",
    "href": "slides/15-linear-regression.html#setup",
    "title": "Linear regression",
    "section": "Setup",
    "text": "Setup\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Ellipse\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\nfrom great_tables import GT, style, loc, exibble\n\n# Setting the theme for plots\nsns.set_theme(style=\"whitegrid\", font_scale=1.2)"
  },
  {
    "objectID": "slides/15-linear-regression.html#goals",
    "href": "slides/15-linear-regression.html#goals",
    "title": "Linear regression",
    "section": "Goals",
    "text": "Goals\n\n\nWhat is a model?\nWhy do we model?\nWhat is correlation?"
  },
  {
    "objectID": "slides/15-linear-regression.html#lets-drive-a-tesla",
    "href": "slides/15-linear-regression.html#lets-drive-a-tesla",
    "title": "Linear regression",
    "section": "Let’s drive a Tesla!",
    "text": "Let’s drive a Tesla!"
  },
  {
    "objectID": "slides/15-linear-regression.html#semi-or-garage",
    "href": "slides/15-linear-regression.html#semi-or-garage",
    "title": "Linear regression",
    "section": "Semi or garage?",
    "text": "Semi or garage?\n\ni love how Tesla thinks the wall in my garage is a semi. 😅\n\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/15-linear-regression.html#semi-or-garage-1",
    "href": "slides/15-linear-regression.html#semi-or-garage-1",
    "title": "Linear regression",
    "section": "Semi or garage?",
    "text": "Semi or garage?\n\nNew owner here. Just parked in my garage. Tesla thinks I crashed onto a semi.\n\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/15-linear-regression.html#car-or-trash",
    "href": "slides/15-linear-regression.html#car-or-trash",
    "title": "Linear regression",
    "section": "Car or trash?",
    "text": "Car or trash?\n\nTesla calls Mercedes trash\n\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/15-linear-regression.html#leisure-commute-physical-activity-and-bp",
    "href": "slides/15-linear-regression.html#leisure-commute-physical-activity-and-bp",
    "title": "Linear regression",
    "section": "Leisure, commute, physical activity and BP",
    "text": "Leisure, commute, physical activity and BP\n\nRelation Between Leisure Time, Commuting, and Occupational Physical Activity With Blood Pressure in 125,402 Adults: The Lifelines Cohort\nByambasukh, Oyuntugs, Harold Snieder, and Eva Corpeleijn. “Relation between leisure time, commuting, and occupational physical activity with blood pressure in 125 402 adults: the lifelines cohort.” Journal of the American Heart Association 9.4 (2020): e014313."
  },
  {
    "objectID": "slides/15-linear-regression.html#leisure-commute-physical-activity-and-bp-1",
    "href": "slides/15-linear-regression.html#leisure-commute-physical-activity-and-bp-1",
    "title": "Linear regression",
    "section": "Leisure, commute, physical activity and BP",
    "text": "Leisure, commute, physical activity and BP\nBackground: Whether all domains of daily‐life moderate‐to‐vigorous physical activity (MVPA) are associated with lower blood pressure (BP) and how this association depends on age and body mass index remains unclear.\nMethods and Results: In the population‐based Lifelines cohort (N=125,402), MVPA was assessed by the Short Questionnaire to Assess Health‐Enhancing Physical Activity, a validated questionnaire in different domains such as commuting, leisure‐time, and occupational PA. BP was assessed using the last 3 of 10 measurements after 10 minutes’ rest in the supine position. Hypertension was defined as systolic BP ≥140 mm Hg and/or diastolic BP ≥90 mm Hg and/or use of antihypertensives. In regression analysis, higher commuting and leisure‐time but not occupational MVPA related to lower BP and lower hypertension risk. Commuting‐and‐leisure‐time MVPA was associated with BP in a dose‐dependent manner. β Coefficients (95% CI) from linear regression analyses were −1.64 (−2.03 to −1.24), −2.29 (−2.68 to −1.90), and finally −2.90 (−3.29 to −2.50) mm Hg systolic BP for the low, middle, and highest tertile of MVPA compared with “No MVPA” as the reference group after adjusting for age, sex, education, smoking and alcohol use. Further adjustment for body mass index attenuated the associations by 30% to 50%, but more MVPA remained significantly associated with lower BP and lower risk of hypertension. This association was age dependent. β Coefficients (95% CI) for the highest tertiles of commuting‐and‐leisure‐time MVPA were −1.67 (−2.20 to −1.15), −3.39 (−3.94 to −2.82) and −4.64 (−6.15 to −3.14) mm Hg systolic BP in adults &lt;40, 40 to 60, and &gt;60 years, respectively.\nConclusions: Higher commuting and leisure‐time but not occupational MVPA were significantly associated with lower BP and lower hypertension risk at all ages, but these associations were stronger in older adults."
  },
  {
    "objectID": "slides/15-linear-regression.html#modeling-cars",
    "href": "slides/15-linear-regression.html#modeling-cars",
    "title": "Linear regression",
    "section": "Modeling cars",
    "text": "Modeling cars\n\nQuestionsPlot\n\n\n\n\nWhat is the relationship between cars’ weights and their mileage?\nWhat is your best guess for a car’s MPG that weighs 3,500 pounds?"
  },
  {
    "objectID": "slides/15-linear-regression.html#modelling-cars",
    "href": "slides/15-linear-regression.html#modelling-cars",
    "title": "Linear regression",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nDescribe: What is the relationship between cars’ weights and their mileage?"
  },
  {
    "objectID": "slides/15-linear-regression.html#modelling-cars-1",
    "href": "slides/15-linear-regression.html#modelling-cars-1",
    "title": "Linear regression",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nPredict: What is your best guess for a car’s MPG that weighs 3,500 pounds?"
  },
  {
    "objectID": "slides/15-linear-regression.html#modelling",
    "href": "slides/15-linear-regression.html#modelling",
    "title": "Linear regression",
    "section": "Modelling",
    "text": "Modelling\n\nUse models to explain the relationship between variables and to make predictions\nFor now we will focus on linear models (but there are many many other types of models too!)"
  },
  {
    "objectID": "slides/15-linear-regression.html#modelling-vocabulary",
    "href": "slides/15-linear-regression.html#modelling-vocabulary",
    "title": "Linear regression",
    "section": "Modelling vocabulary",
    "text": "Modelling vocabulary\n\nPredictor (explanatory variable)\nOutcome (response variable)\nRegression line\n\nSlope\nIntercept\n\nCorrelation"
  },
  {
    "objectID": "slides/15-linear-regression.html#predictor-explanatory-variable",
    "href": "slides/15-linear-regression.html#predictor-explanatory-variable",
    "title": "Linear regression",
    "section": "Predictor (explanatory variable)",
    "text": "Predictor (explanatory variable)\n\n\n\n\n\n\n\n\n\n\nmpg\nweight\n\n\n\n\n18.0\n3504\n\n\n15.0\n3693\n\n\n18.0\n3436\n\n\n16.0\n3433\n\n\n17.0\n3449\n\n\n15.0\n4341\n\n\n...\n..."
  },
  {
    "objectID": "slides/15-linear-regression.html#outcome-response-variable",
    "href": "slides/15-linear-regression.html#outcome-response-variable",
    "title": "Linear regression",
    "section": "Outcome (response variable)",
    "text": "Outcome (response variable)\n\n\n\n\n\n\n\n\n\n\nmpg\nweight\n\n\n\n\n18.0\n3504\n\n\n15.0\n3693\n\n\n18.0\n3436\n\n\n16.0\n3433\n\n\n17.0\n3449\n\n\n15.0\n4341\n\n\n...\n..."
  },
  {
    "objectID": "slides/15-linear-regression.html#regression-line",
    "href": "slides/15-linear-regression.html#regression-line",
    "title": "Linear regression",
    "section": "Regression line",
    "text": "Regression line"
  },
  {
    "objectID": "slides/15-linear-regression.html#regression-line-slope",
    "href": "slides/15-linear-regression.html#regression-line-slope",
    "title": "Linear regression",
    "section": "Regression line: slope",
    "text": "Regression line: slope"
  },
  {
    "objectID": "slides/15-linear-regression.html#regression-line-intercept",
    "href": "slides/15-linear-regression.html#regression-line-intercept",
    "title": "Linear regression",
    "section": "Regression line: intercept",
    "text": "Regression line: intercept"
  },
  {
    "objectID": "slides/15-linear-regression.html#correlation",
    "href": "slides/15-linear-regression.html#correlation",
    "title": "Linear regression",
    "section": "Correlation",
    "text": "Correlation\n\n\nCorrelation coefficient: -0.83"
  },
  {
    "objectID": "slides/15-linear-regression.html#correlation-1",
    "href": "slides/15-linear-regression.html#correlation-1",
    "title": "Linear regression",
    "section": "Correlation",
    "text": "Correlation\n\nRanges between -1 and 1.\nSame sign as the slope."
  },
  {
    "objectID": "slides/15-linear-regression.html#visualizing-the-model",
    "href": "slides/15-linear-regression.html#visualizing-the-model",
    "title": "Linear regression",
    "section": "Visualizing the model",
    "text": "Visualizing the model\n\n\nCode\nsns.lmplot(x=\"weight\", y=\"mpg\", data=mtcars, ci=None, scatter_kws={\"s\": 50, \"alpha\": 0.5}, line_kws={\"color\": \"#325b74\"})\nplt.xlabel(\"Weight (1,000 lbs)\")\nplt.ylabel(\"Miles per gallon (MPG)\")\nplt.title(\"MPG vs. weights of cars\")\nplt.show()"
  },
  {
    "objectID": "slides/15-linear-regression.html#data-prep",
    "href": "slides/15-linear-regression.html#data-prep",
    "title": "Linear regression",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\nRename the dataset as movie_scores\n\n\nfandango = pd.read_csv(\"data/fandango.csv\")\nmovie_scores = fandango.rename(columns={\"rt_norm\": \"critics\", \"rt_user_norm\": \"audience\"})"
  },
  {
    "objectID": "slides/15-linear-regression.html#data-overview",
    "href": "slides/15-linear-regression.html#data-overview",
    "title": "Linear regression",
    "section": "Data overview",
    "text": "Data overview\n\nprint(movie_scores[[\"critics\", \"audience\"]].head())\n\n   critics  audience\n0     3.70       4.3\n1     4.25       4.0\n2     4.00       4.5\n3     0.90       4.2\n4     0.70       1.4"
  },
  {
    "objectID": "slides/15-linear-regression.html#data-visualization",
    "href": "slides/15-linear-regression.html#data-visualization",
    "title": "Linear regression",
    "section": "Data visualization",
    "text": "Data visualization"
  },
  {
    "objectID": "slides/15-linear-regression.html#regression-model-1",
    "href": "slides/15-linear-regression.html#regression-model-1",
    "title": "Linear regression",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the outcome, \\(Y\\), and the predictor, \\(X\\).\n\\[\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\\]"
  },
  {
    "objectID": "slides/15-linear-regression.html#regression-model",
    "href": "slides/15-linear-regression.html#regression-model",
    "title": "Linear regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{#325b74}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{#325b74}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{#325b74}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/15-linear-regression.html#simple-linear-regression",
    "href": "slides/15-linear-regression.html#simple-linear-regression",
    "title": "Linear regression",
    "section": "Simple linear regression",
    "text": "Simple linear regression\nUse simple linear regression to model the relationship between a quantitative outcome (\\(Y\\)) and a single quantitative predictor (\\(X\\)): \\[\\Large{Y = \\beta_0 + \\beta_1 X + \\epsilon}\\]\n\n\n\\(\\beta_1\\): True slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): True intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon\\): Error (residual)"
  },
  {
    "objectID": "slides/15-linear-regression.html#simple-linear-regression-1",
    "href": "slides/15-linear-regression.html#simple-linear-regression-1",
    "title": "Linear regression",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\\[\\Large{\\hat{Y} = b_0 + b_1 X}\\]\n\n\\(b_1\\): Estimated slope of the relationship between \\(X\\) and \\(Y\\)\n\\(b_0\\): Estimated intercept of the relationship between \\(X\\) and \\(Y\\)\nNo error term!"
  },
  {
    "objectID": "slides/15-linear-regression.html#residuals",
    "href": "slides/15-linear-regression.html#residuals",
    "title": "Linear regression",
    "section": "Residuals",
    "text": "Residuals\n\n\n\n\n\n\n\n\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y - \\hat{y}\\]"
  },
  {
    "objectID": "slides/15-linear-regression.html#least-squares-line",
    "href": "slides/15-linear-regression.html#least-squares-line",
    "title": "Linear regression",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe least squares line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/15-linear-regression.html#least-squares-line-1",
    "href": "slides/15-linear-regression.html#least-squares-line-1",
    "title": "Linear regression",
    "section": "Least squares line",
    "text": "Least squares line\n\nslope, intercept = model.coef_[0], model.intercept_\nprint(f\"Slope: {slope:.2f}, Intercept: {intercept:.2f}\")\n\nSlope: 0.52, Intercept: 1.62"
  },
  {
    "objectID": "slides/15-linear-regression.html#properties-of-least-squares-regression",
    "href": "slides/15-linear-regression.html#properties-of-least-squares-regression",
    "title": "Linear regression",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point (the coordinates corresponding to average \\(X\\) and average \\(Y\\)): \\(b_0 = \\bar{Y} - b_1~\\bar{X}\\)\nSlope has the same sign as the correlation coefficient: \\(b_1 = r \\frac{s_Y}{s_X}\\)\nSum of the residuals is zero: \\(\\sum_{i = 1}^n \\epsilon_i = 0\\)\nResiduals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/15-linear-regression.html#interpreting-slope-intercept",
    "href": "slides/15-linear-regression.html#interpreting-slope-intercept",
    "title": "Linear regression",
    "section": "Interpreting slope & intercept",
    "text": "Interpreting slope & intercept\n\\[\\widehat{\\text{audience}} = 32.3 + 0.519 \\times \\text{critics}\\]\n\n\nSlope: For every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.\nIntercept: If the critics score is 0 points, we expect the audience score to be 32.3 points."
  },
  {
    "objectID": "slides/15-linear-regression.html#is-the-intercept-meaningful",
    "href": "slides/15-linear-regression.html#is-the-intercept-meaningful",
    "title": "Linear regression",
    "section": "Is the intercept meaningful?",
    "text": "Is the intercept meaningful?\n✅ The intercept is meaningful in context of the data if\n\nthe predictor can feasibly take values equal to or near zero or\nthe predictor has values near zero in the observed data\n\n\n🛑 Otherwise, it might not be meaningful!"
  },
  {
    "objectID": "slides/15-linear-regression.html#application-exercise-ae-10-modeling-fish",
    "href": "slides/15-linear-regression.html#application-exercise-ae-10-modeling-fish",
    "title": "Linear regression",
    "section": "Application exercise: ae-10-modeling-fish",
    "text": "Application exercise: ae-10-modeling-fish\n\n\nGo back to your project called ae.\nIf there are any uncommitted files, commit them, and push.\n\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/10-ethics.html#today",
    "href": "slides/10-ethics.html#today",
    "title": "Data science ethics",
    "section": "Today",
    "text": "Today\nData science ethics:\n\nMisrepresentation\nData privacy\nAlgorithmic bias"
  },
  {
    "objectID": "slides/10-ethics.html#stand-your-ground",
    "href": "slides/10-ethics.html#stand-your-ground",
    "title": "Data science ethics",
    "section": "Stand your ground",
    "text": "Stand your ground\n\nIn 2005, the Florida legislature passed the controversial “Stand Your Ground” law that broadened the situations in which citizens can use lethal force to protect themselves against perceived threats. Advocates believed that the new law would ultimately reduce crime; opponents feared an increase in the use of lethal force."
  },
  {
    "objectID": "slides/10-ethics.html#stand-your-ground-1",
    "href": "slides/10-ethics.html#stand-your-ground-1",
    "title": "Data science ethics",
    "section": "Stand your ground",
    "text": "Stand your ground\n\nQuestion\n\n\n\nWhat does the visualization, published by Reuters on Feb 16, 2014, say about the number of firearm murders in Florida over time?"
  },
  {
    "objectID": "slides/10-ethics.html#your-data",
    "href": "slides/10-ethics.html#your-data",
    "title": "Data science ethics",
    "section": "“Your” data",
    "text": "“Your” data\n\nEvery time we use apps, websites, and devices, our data is being collected and used or sold to others.\nMore importantly, decisions are made by law enforcement, financial institutions, and governments based on data that directly affect the lives of people."
  },
  {
    "objectID": "slides/10-ethics.html#privacy-of-your-data",
    "href": "slides/10-ethics.html#privacy-of-your-data",
    "title": "Data science ethics",
    "section": "Privacy of your data",
    "text": "Privacy of your data\n\nWhat pieces of data have you left on the internet today? Think through everything you’ve logged into, clicked on, checked in, either actively or automatically, that might be tracking you. Do you know where that data is stored? Who it can be accessed by? Whether it’s shared with others?"
  },
  {
    "objectID": "slides/10-ethics.html#sharing-your-data",
    "href": "slides/10-ethics.html#sharing-your-data",
    "title": "Data science ethics",
    "section": "Sharing your data",
    "text": "Sharing your data\n\nWhat are you OK with sharing?\n\n\n\n\n\nName\nAge\nEmail\nPhone Number\nList of every video you watch\nList of every video you comment on\n\n\n\n\n\nHow you type: speed, accuracy\nHow long you spend on different content\nList of all your private messages (date, time, person sent to)\nInfo about your photos (how it was taken, where it was taken (GPS), when it was taken)"
  },
  {
    "objectID": "slides/10-ethics.html#what-does-google-thinkknow-about-you",
    "href": "slides/10-ethics.html#what-does-google-thinkknow-about-you",
    "title": "Data science ethics",
    "section": "What does Google think/know about you?",
    "text": "What does Google think/know about you?\n\nHave you ever thought about why you’re seeing an ad on Google? Google it! Try to figure out if you have ad personalization on and how your ads are personalized."
  },
  {
    "objectID": "slides/10-ethics.html#your-browing-history",
    "href": "slides/10-ethics.html#your-browing-history",
    "title": "Data science ethics",
    "section": "Your browing history",
    "text": "Your browing history\n\nWhich of the following are you OK with your browsing history to be used towards?\n\n\n\nFor serving you targeted ads\nTo score you as a candidate for a job\nTo predict your race/ethnicity for voting purposes"
  },
  {
    "objectID": "slides/10-ethics.html#who-else-gets-to-use-your-data",
    "href": "slides/10-ethics.html#who-else-gets-to-use-your-data",
    "title": "Data science ethics",
    "section": "Who else gets to use your data?",
    "text": "Who else gets to use your data?\n\nSuppose you create a profile on a social media site and share your personal information on your profile. Who else gets to use that data?\n\n\n\nCompanies the social media company has a connection to?\nCompanies the social media company sells your data to?\nResearchers?"
  },
  {
    "objectID": "slides/10-ethics.html#ok-cupid-data-breach",
    "href": "slides/10-ethics.html#ok-cupid-data-breach",
    "title": "Data science ethics",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach\n\nIn 2016, researchers published data of 70,000 OkCupid users—including usernames, political leanings, drug usage, and intimate sexual details\nResearchers didn’t release the real names and pictures of OKCupid users, but their identities could easily be uncovered from the details provided, e.g. usernames\n\n\n\n\n\nSome may object to the ethics of gathering and releasing this data. However, all the data found in the dataset are or were already publicly available, so releasing this dataset merely presents it in a more useful form.\nResearchers Emil Kirkegaard and Julius Daugbjerg Bjerrekær"
  },
  {
    "objectID": "slides/10-ethics.html#garbage-in-garbage-out",
    "href": "slides/10-ethics.html#garbage-in-garbage-out",
    "title": "Data science ethics",
    "section": "Garbage in, garbage out",
    "text": "Garbage in, garbage out\n\nIn statistical modeling and inference we talk about “garbage in, garbage out” – if you don’t have good (random, representative) data, results of your analysis will not be reliable or generalizable.\nCorollary: Bias in, bias out."
  },
  {
    "objectID": "slides/10-ethics.html#google-translate",
    "href": "slides/10-ethics.html#google-translate",
    "title": "Data science ethics",
    "section": "Google translate",
    "text": "Google translate\n\nWhat might be the reason for Google’s gendered translation? How do ethics play into this situation?\n\n\n\n\n\n\n\n\nSource: Engadget - Google is working to remove gender bias in its translations"
  },
  {
    "objectID": "slides/10-ethics.html#stochastic-parrots",
    "href": "slides/10-ethics.html#stochastic-parrots",
    "title": "Data science ethics",
    "section": "Stochastic parrots",
    "text": "Stochastic parrots\n\nExcerptQuestion\n\n\nOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜 (Bender et. al., 2021)\n\nThe past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.\n\n\n\n\nWhat is meant by “stochastic parrots” in the paper title?"
  },
  {
    "objectID": "slides/10-ethics.html#machine-bias",
    "href": "slides/10-ethics.html#machine-bias",
    "title": "Data science ethics",
    "section": "Machine Bias",
    "text": "Machine Bias\n2016 ProPublica article on algorithm used for rating a defendant’s risk of future crime:\n\n\n\nIn forecasting who would re-offend, the algorithm made mistakes with black and white defendants at roughly the same rate but in very different ways.\n\nThe formula was particularly likely to falsely flag black defendants as future criminals, wrongly labeling them this way at almost twice the rate as white defendants.\nWhite defendants were mislabeled as low risk more often than black defendants.\n\n\n\n\n\n\n\n\n\n\n\nSource: ProPublica"
  },
  {
    "objectID": "slides/10-ethics.html#risk-score-errors",
    "href": "slides/10-ethics.html#risk-score-errors",
    "title": "Data science ethics",
    "section": "Risk score errors",
    "text": "Risk score errors\n\n\n\nWhat is common among the defendants who were assigned a high/low risk score for reoffending?"
  },
  {
    "objectID": "slides/10-ethics.html#risk-scores",
    "href": "slides/10-ethics.html#risk-scores",
    "title": "Data science ethics",
    "section": "Risk scores",
    "text": "Risk scores\n\n\n\nHow can an algorithm that doesn’t use race as input data be racist?"
  },
  {
    "objectID": "slides/10-ethics.html#predicting-ethnicity",
    "href": "slides/10-ethics.html#predicting-ethnicity",
    "title": "Data science ethics",
    "section": "Predicting ethnicity",
    "text": "Predicting ethnicity\nImproving Ecological Inference by Predicting Individual Ethnicity from Voter Registration Record (Imran and Khan, 2016)\n\nIn both political behavior research and voting rights litigation, turnout and vote choice for different racial groups are often inferred using aggregate election results and racial composition. Over the past several decades, many statistical methods have been proposed to address this ecological inference problem. We propose an alternative method to reduce aggregation bias by predicting individual-level ethnicity from voter registration records. Building on the existing methodological literature, we use Bayes’s rule to combine the Census Bureau’s Surname List with various information from geocoded voter registration records. We evaluate the performance of the proposed methodology using approximately nine million voter registration records from Florida, where self-reported ethnicity is available. We find that it is possible to reduce the false positive rate among Black and Latino voters to 6% and 3%, respectively, while maintaining the true positive rate above 80%. Moreover, we use our predictions to estimate turnout by race and find that our estimates yields substantially less amounts of bias and root mean squared error than standard ecological inference estimates. We provide open-source software to implement the proposed methodology. The open-source software is available for implementing the proposed methodology."
  },
  {
    "objectID": "slides/10-ethics.html#wru-package-sorry-this-is-in-r",
    "href": "slides/10-ethics.html#wru-package-sorry-this-is-in-r",
    "title": "Data science ethics",
    "section": "wru package (sorry, this is in R)",
    "text": "wru package (sorry, this is in R)\nThe said “source software” is the wru package: https://github.com/kosukeimai/wru.\n\nDo you have any ethical concerns about installing this package?"
  },
  {
    "objectID": "slides/10-ethics.html#wru-package",
    "href": "slides/10-ethics.html#wru-package",
    "title": "Data science ethics",
    "section": "wru package",
    "text": "wru package\n\nWas the publication of this model ethical? Does the open-source nature of the code affect your answer? Is it ethical to use this software? Does your answer change depending on the intended use?\n\n\nlibrary(wru)\npredict_race(voter.file = voters, surname.only = TRUE) |&gt;\n  select(surname, contains(\"pred\"))\n\n      surname    pred.whi    pred.bla     pred.his    pred.asi    pred.oth\n1      Khanna 0.045110474 0.003067623 0.0068522723 0.860411906 0.084557725\n2        Imai 0.052645440 0.001334812 0.0558160072 0.719376581 0.170827160\n3      Rivera 0.043285692 0.008204605 0.9136195794 0.024316883 0.010573240\n4     Fifield 0.895405704 0.001911388 0.0337464844 0.011079323 0.057857101\n5        Zhou 0.006572555 0.001298962 0.0005388581 0.982365594 0.009224032\n6    Ratkovic 0.861236727 0.008212824 0.0095395642 0.011334635 0.109676251\n7     Johnson 0.543815322 0.344128607 0.0272403940 0.007405765 0.077409913\n8       Lopez 0.038939877 0.004920643 0.9318797791 0.012154125 0.012105576\n10 Wantchekon 0.330697188 0.194700665 0.4042849478 0.021379541 0.048937658\n9       Morse 0.866360147 0.044429853 0.0246568086 0.010219712 0.054333479"
  },
  {
    "objectID": "slides/10-ethics.html#wru-package-1",
    "href": "slides/10-ethics.html#wru-package-1",
    "title": "Data science ethics",
    "section": "wru package",
    "text": "wru package\n\nme &lt;- tibble(surname = \"Chism\")\n\npredict_race(voter.file = me, surname.only = TRUE)\n\nPredicting race for 2020\n\n\nWarning: Unknown or uninitialised column: `state`.\n\n\nProceeding with last name predictions...\n\n\nℹ All local files already up-to-date!\nℹ All local files already up-to-date!\n\n\n  surname pred.whi  pred.bla  pred.his    pred.asi   pred.oth\n1   Chism 0.579293 0.3224595 0.0271373 0.006381576 0.06472858\n\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/21-calculus-II.html#summary-of-derivative-rules",
    "href": "slides/21-calculus-II.html#summary-of-derivative-rules",
    "title": "Calculus II",
    "section": "Summary of Derivative Rules",
    "text": "Summary of Derivative Rules\nDifferentiation rules\n\n\nConstant rule: \\(\\frac{d}{dx} (c) = 0\\)\nPower rule: \\(\\frac{d}{dx} (x^n) = nx^{n-1}\\)\nConstant multiple rule: \\(\\frac{d}{dx} [c \\cdot f(x)] = c \\cdot f'(x)\\)\nSum rule: \\(\\frac{d}{dx} [f(x) + g(x)] = f'(x) + g'(x)\\)\nDifference rule: \\(\\frac{d}{dx} [f(x) - g(x)] = f'(x) - g'(x)\\)"
  },
  {
    "objectID": "slides/21-calculus-II.html#integration",
    "href": "slides/21-calculus-II.html#integration",
    "title": "Calculus II",
    "section": "Integration",
    "text": "Integration\nFrom last time:\n\n\nMeasures the accumulation of quantities and the area under a curve.\nExample: Used to compute the area under probability distribution functions, which is essential in statistics and data analysis.\nSymbol: \\(\\int f(x) dx\\)\nPractical Application: Calculating Cumulative Distribution Functions (CDFs)"
  },
  {
    "objectID": "slides/21-calculus-II.html#accumulating-quantities",
    "href": "slides/21-calculus-II.html#accumulating-quantities",
    "title": "Calculus II",
    "section": "Accumulating quantities",
    "text": "Accumulating quantities\n\n\n\n\n\n\n\n\nArea under the curve\n\n\nThe integral of a function represents the area under the curve of that function on a graph, between two points.\nExample: Finding the total distance traveled given a speed-time graph."
  },
  {
    "objectID": "slides/21-calculus-II.html#the-integral",
    "href": "slides/21-calculus-II.html#the-integral",
    "title": "Calculus II",
    "section": "The integral",
    "text": "The integral"
  },
  {
    "objectID": "slides/21-calculus-II.html#integrals-in-python",
    "href": "slides/21-calculus-II.html#integrals-in-python",
    "title": "Calculus II",
    "section": "Integrals in Python",
    "text": "Integrals in Python\nCalculating integrals using SymPy\n\nfrom sympy import symbols, integrate\n\nx = symbols('x')\nf = x**2 + 1\narea = integrate(f, (x, 0, 1))\nprint(area)  # Output: 4/3\n\n4/3"
  },
  {
    "objectID": "slides/21-calculus-II.html#solving-integrals",
    "href": "slides/21-calculus-II.html#solving-integrals",
    "title": "Calculus II",
    "section": "Solving integrals",
    "text": "Solving integrals\nIntegration rules\n\n\nConstant rule: \\(\\int c , dx = cx + C\\)\nPower rule: \\(\\int x^n , dx = \\frac{x^{n+1}}{n+1} + C\\)\nConstant multiple rule: \\(\\int c \\cdot f(x) , dx = c \\cdot \\int f(x) , dx\\)\nSum rule: \\(\\int [f(x) + g(x)] , dx = \\int f(x) , dx + \\int g(x) , dx\\)\nDifference rule: \\(\\int [f(x) - g(x)] , dx = \\int f(x) , dx - \\int g(x) , dx\\)"
  },
  {
    "objectID": "slides/21-calculus-II.html#example-1-integrating-a-constant",
    "href": "slides/21-calculus-II.html#example-1-integrating-a-constant",
    "title": "Calculus II",
    "section": "Example 1: Integrating a Constant",
    "text": "Example 1: Integrating a Constant\n\n\nFunction: \\(f(x) = 7\\)\nIntegral: \\(\\int 7 , dx = 7x + C\\)"
  },
  {
    "objectID": "slides/21-calculus-II.html#example-2-power-rule",
    "href": "slides/21-calculus-II.html#example-2-power-rule",
    "title": "Calculus II",
    "section": "Example 2: Power rule",
    "text": "Example 2: Power rule\n\n\nFunction: \\(f(x) = x^3\\)\nIntegral: \\(\\int x^3 , dx = \\frac{x^{4}}{4} + C\\)"
  },
  {
    "objectID": "slides/21-calculus-II.html#example-3-constant-multiple-rule",
    "href": "slides/21-calculus-II.html#example-3-constant-multiple-rule",
    "title": "Calculus II",
    "section": "Example 3: Constant multiple rule",
    "text": "Example 3: Constant multiple rule\n\n\nFunction: \\(f(x) = 5x^2\\)\nIntegral: \\(\\int 5x^2 , dx = 5 \\cdot \\frac{x^{3}}{3} + C = \\frac{5x^{3}}{3} + C\\)"
  },
  {
    "objectID": "slides/21-calculus-II.html#example-4-sum-and-difference-rule",
    "href": "slides/21-calculus-II.html#example-4-sum-and-difference-rule",
    "title": "Calculus II",
    "section": "Example 4: Sum and difference rule",
    "text": "Example 4: Sum and difference rule\n\n\nFunction: \\(f(x) = x^3 + 4x - 5\\)\nIntegral: \\(\\int (x^3 + 4x - 5) , dx = \\frac{x^{4}}{4} + 2x^2 - 5x + C\\)"
  },
  {
    "objectID": "slides/21-calculus-II.html#solving-complex-integrals",
    "href": "slides/21-calculus-II.html#solving-complex-integrals",
    "title": "Calculus II",
    "section": "Solving complex integrals",
    "text": "Solving complex integrals\nComplex Integrals:\n\n\nInvolves functions composed of multiple simpler functions.\nRequires application of rules like integration by parts and substitution for integration.\n\n\n\nExample Function:\n\\[\n\\int_{a}^{b} \\left( e^{cx} + \\frac{1}{x^n} \\right) \\, dx\n\\]\n\n\n\nObjective: Find the integral"
  },
  {
    "objectID": "slides/21-calculus-II.html#integration-by-parts",
    "href": "slides/21-calculus-II.html#integration-by-parts",
    "title": "Calculus II",
    "section": "Integration by parts",
    "text": "Integration by parts\n\\[\n\\int u \\space dv = uv - \\int v \\space du\n\\]\n\nUsed when integrating the product of two functions."
  },
  {
    "objectID": "slides/21-calculus-II.html#integration-by-parts-1",
    "href": "slides/21-calculus-II.html#integration-by-parts-1",
    "title": "Calculus II",
    "section": "Integration by parts",
    "text": "Integration by parts\nFunction: \\(\\int x e^x , dx\\)\n\n\nIdentify the functions\n\n\n\n\\(u = x \\quad \\Rightarrow \\quad du = dx\\)\n\\(dv = e^x , dx \\quad \\Rightarrow \\quad v = e^x\\)\n\n\n\n\n\nApply Integration by Parts\n\n\\(\\int xe^x \\space dx=xe^x-\\int e^x \\space dx=xe^x-e^x + C\\)"
  },
  {
    "objectID": "slides/21-calculus-II.html#integration-by-parts-example",
    "href": "slides/21-calculus-II.html#integration-by-parts-example",
    "title": "Calculus II",
    "section": "Integration by parts: Example",
    "text": "Integration by parts: Example\nFunction: \\(\\int xe^x \\space dx\\)\n\n\nIdentify the functions\n\n\n\n\\(\\text{Let } u=x\\) and \\(dv=e^x \\space dx\\)\n\n\n\n\n\nDifferentiate and integrate\n\n\n\nDifferentiate: \\(u\\colon du=dx\\)\nIntegrate: \\(dv\\colon v = e^x\\)"
  },
  {
    "objectID": "slides/21-calculus-II.html#integration-by-parts-example-1",
    "href": "slides/21-calculus-II.html#integration-by-parts-example-1",
    "title": "Calculus II",
    "section": "Integration by parts: Example",
    "text": "Integration by parts: Example\nFunction: \\(\\int xe^x \\space dx\\)\n\n\nApply the integration by parts formula\n\n\\[\n\\int u \\space dv = uv - \\int v \\space du\n\\]\n\n\n\nSubstitute the values\n\n\\[\n\\int x e^x \\, dx = x e^x - \\int e^x \\, dx\n\\]"
  },
  {
    "objectID": "slides/21-calculus-II.html#integration-by-parts-example-2",
    "href": "slides/21-calculus-II.html#integration-by-parts-example-2",
    "title": "Calculus II",
    "section": "Integration by parts: Example",
    "text": "Integration by parts: Example\nFunction: \\(\\int xe^x \\space dx\\)\n\n\nSimplify the integral\n\n\\[\n\\int x e^x \\, dx = x e^x - e^x + C\n\\]\n\n\n\nFinal answer\n\n\\[\n\\int x e^x \\, dx = e^x (x - 1) + C\n\\]"
  },
  {
    "objectID": "slides/21-calculus-II.html#integration-by-substitution",
    "href": "slides/21-calculus-II.html#integration-by-substitution",
    "title": "Calculus II",
    "section": "Integration by substitution",
    "text": "Integration by substitution\nFunction: \\(\\int f(g(x))g^{'}(x)dx=\\int f(u)\\space du\\)\n\nUsed when integrating a composite function."
  },
  {
    "objectID": "slides/21-calculus-II.html#integration-by-substitution-example-1",
    "href": "slides/21-calculus-II.html#integration-by-substitution-example-1",
    "title": "Calculus II",
    "section": "Integration by substitution: Example 1",
    "text": "Integration by substitution: Example 1\nFunction: \\(\\int 2x \\sqrt{x^2 + 1} , dx\\)\n\n\nIdentify the substitution\n\n\n\nLet \\(u = x^2 + 1 \\quad \\Rightarrow \\quad du = 2x , dx\\)\n\n\n\n\n\nApply the substitution\n\n\\[\n\\int 2x \\sqrt{x^2 + 1} \\space dx=\\int \\sqrt{u} \\space du = \\frac{2}{3}(x^2 + 1)^{3/2} + C\n\\]"
  },
  {
    "objectID": "slides/21-calculus-II.html#integration-by-substitution-example-2",
    "href": "slides/21-calculus-II.html#integration-by-substitution-example-2",
    "title": "Calculus II",
    "section": "Integration by substitution: Example 2",
    "text": "Integration by substitution: Example 2\nFunction: \\[\\int x \\ln(x) , dx\\]\n\n\nIdentify the functions\n\n\n\n\\(u = \\ln(x) \\quad \\Rightarrow \\quad du = \\frac{1}{x} , dx\\)\n\\(dv = x , dx \\quad \\Rightarrow \\quad v = \\frac{x^2}{2}\\)"
  },
  {
    "objectID": "slides/21-calculus-II.html#integration-by-substitution-example-2-1",
    "href": "slides/21-calculus-II.html#integration-by-substitution-example-2-1",
    "title": "Calculus II",
    "section": "Integration by substitution: Example 2",
    "text": "Integration by substitution: Example 2\nFunction: \\[\\int x \\ln(x) , dx\\]\n\n\nApply integration by parts\n\n\\[\n\\int x \\ln(x) , dx = \\frac{x^2}{2}\\ln(x) - \\int \\frac{x^2}{2} \\cdot \\frac{1}{x} \\space dx = \\frac{x^2}{2} \\ln(x) - \\frac{1}{2} \\int x \\space dx\n\\]\n\\[\n= \\frac{x^2}{2} \\ln(x) - \\frac{x^2}{4} + C\n\\]"
  },
  {
    "objectID": "slides/21-calculus-II.html#regularization",
    "href": "slides/21-calculus-II.html#regularization",
    "title": "Calculus II",
    "section": "Regularization",
    "text": "Regularization\nYou’ll learn more about this in INFO 521: Introduction to Machine Learning and/or INFO 523: Data Mining and Discovery"
  },
  {
    "objectID": "slides/21-calculus-II.html#ae-14-integration",
    "href": "slides/21-calculus-II.html#ae-14-integration",
    "title": "Calculus II",
    "section": "ae-14-integration",
    "text": "ae-14-integration\nPractice integration (you will be tested on this in Exam 2)\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "slides/18-prediction-uncertainty.html#setup",
    "href": "slides/18-prediction-uncertainty.html#setup",
    "title": "Prediction + uncertainty",
    "section": "Setup",
    "text": "Setup\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_theme(style=\"whitegrid\", rc={\"figure.figsize\": (8, 6), \"axes.labelsize\": 16, \"xtick.labelsize\": 14, \"ytick.labelsize\": 14})"
  },
  {
    "objectID": "slides/18-prediction-uncertainty.html#data-candy-rankings",
    "href": "slides/18-prediction-uncertainty.html#data-candy-rankings",
    "title": "Prediction + uncertainty",
    "section": "Data: Candy Rankings",
    "text": "Data: Candy Rankings\n\ncandy_rankings = pd.read_csv(\"data/candy_rankings.csv\")\n\ncandy_rankings.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 85 entries, 0 to 84\nData columns (total 13 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   competitorname    85 non-null     object \n 1   chocolate         85 non-null     bool   \n 2   fruity            85 non-null     bool   \n 3   caramel           85 non-null     bool   \n 4   peanutyalmondy    85 non-null     bool   \n 5   nougat            85 non-null     bool   \n 6   crispedricewafer  85 non-null     bool   \n 7   hard              85 non-null     bool   \n 8   bar               85 non-null     bool   \n 9   pluribus          85 non-null     bool   \n 10  sugarpercent      85 non-null     float64\n 11  pricepercent      85 non-null     float64\n 12  winpercent        85 non-null     float64\ndtypes: bool(9), float64(3), object(1)\nmemory usage: 3.5+ KB"
  },
  {
    "objectID": "slides/18-prediction-uncertainty.html#full-model",
    "href": "slides/18-prediction-uncertainty.html#full-model",
    "title": "Prediction + uncertainty",
    "section": "Full model",
    "text": "Full model\n\nWhat percent of the variability in win percentages is explained by the model?\n\n\nfull_model = smf.ols('winpercent ~ chocolate + fruity + caramel + peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent', data=candy_rankings).fit()\nprint(f'R-squared: {full_model.rsquared.round(3)}')\nprint(f'Adjusted R-squared: {full_model.rsquared_adj.round(3)}')\n\nR-squared: 0.54\nAdjusted R-squared: 0.471"
  },
  {
    "objectID": "slides/18-prediction-uncertainty.html#akaike-information-criterion",
    "href": "slides/18-prediction-uncertainty.html#akaike-information-criterion",
    "title": "Prediction + uncertainty",
    "section": "Akaike Information Criterion",
    "text": "Akaike Information Criterion\n\\[ AIC = -2log(L) + 2k \\]\n\n\n\\(L\\): likelihood of the model\n\nLikelihood of seeing these data given the estimated model parameters\nWon’t go into calculating it in this course (but you will in future courses)\n\nUsed for model selection, lower the better\n\nValue is not informative on its own\n\nApplies a penalty for number of parameters in the model, \\(k\\)\n\nDifferent penalty than adjusted \\(R^2\\) but similar idea\n\n\n\n\n\nprint(f'AIC: {full_model.aic}')\n\nAIC: 655.2701107463729"
  },
  {
    "objectID": "slides/18-prediction-uncertainty.html#model-selection-a-little-faster",
    "href": "slides/18-prediction-uncertainty.html#model-selection-a-little-faster",
    "title": "Prediction + uncertainty",
    "section": "Model selection – a little faster",
    "text": "Model selection – a little faster\n\nselected_model = smf.ols('winpercent ~ chocolate + fruity + peanutyalmondy + crispedricewafer + hard + sugarpercent', data=candy_rankings).fit()\n\n\nprint(selected_model.summary2())\n\n                     Results: Ordinary least squares\n=========================================================================\nModel:                  OLS                Adj. R-squared:       0.492   \nDependent Variable:     winpercent         AIC:                  647.5113\nDate:                   2024-08-19 13:45   BIC:                  664.6099\nNo. Observations:       85                 Log-Likelihood:       -316.76 \nDf Model:               6                  F-statistic:          14.54   \nDf Residuals:           78                 Prob (F-statistic):   4.62e-11\nR-squared:              0.528              Scale:                110.07  \n-------------------------------------------------------------------------\n                          Coef.  Std.Err.    t    P&gt;|t|   [0.025   0.975]\n-------------------------------------------------------------------------\nIntercept                32.9406   3.5175  9.3647 0.0000  25.9377 39.9434\nchocolate[T.True]        19.1470   3.5870  5.3379 0.0000  12.0059 26.2882\nfruity[T.True]            8.8815   3.5606  2.4944 0.0147   1.7929 15.9701\npeanutyalmondy[T.True]    9.4829   3.4464  2.7516 0.0074   2.6217 16.3440\ncrispedricewafer[T.True]  8.3851   4.4843  1.8699 0.0653  -0.5425 17.3127\nhard[T.True]             -5.6693   3.2889 -1.7238 0.0887 -12.2170  0.8784\nsugarpercent              7.9789   4.1289  1.9325 0.0569  -0.2410 16.1989\n-------------------------------------------------------------------------\nOmnibus:                 0.545           Durbin-Watson:             1.735\nProb(Omnibus):           0.761           Jarque-Bera (JB):          0.682\nSkew:                    -0.093          Prob(JB):                  0.711\nKurtosis:                2.602           Condition No.:             6    \n=========================================================================\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is\ncorrectly specified."
  },
  {
    "objectID": "slides/18-prediction-uncertainty.html#selected-variables",
    "href": "slides/18-prediction-uncertainty.html#selected-variables",
    "title": "Prediction + uncertainty",
    "section": "Selected variables",
    "text": "Selected variables\n\n\n\nvariable\nselected\n\n\n\n\nchocolate\nx\n\n\nfruity\nx\n\n\ncaramel\n\n\n\npeanutyalmondy\nx\n\n\nnougat\n\n\n\ncrispedricewafer\nx\n\n\nhard\nx\n\n\nbar\n\n\n\npluribus\n\n\n\nsugarpercent\nx\n\n\npricepercent"
  },
  {
    "objectID": "slides/18-prediction-uncertainty.html#coefficient-interpretation",
    "href": "slides/18-prediction-uncertainty.html#coefficient-interpretation",
    "title": "Prediction + uncertainty",
    "section": "Coefficient interpretation",
    "text": "Coefficient interpretation\n\nInterpret the slopes of chocolate and sugarpercent in context of the data.\n\n\n\nIntercept                   32.940573\nchocolate[T.True]           19.147029\nfruity[T.True]               8.881496\npeanutyalmondy[T.True]       9.482858\ncrispedricewafer[T.True]     8.385138\nhard[T.True]                -5.669297\nsugarpercent                 7.978930\ndtype: float64"
  },
  {
    "objectID": "slides/18-prediction-uncertainty.html#aic",
    "href": "slides/18-prediction-uncertainty.html#aic",
    "title": "Prediction + uncertainty",
    "section": "AIC",
    "text": "AIC\nAs expected, the selected model has a smaller AIC than the full model. In fact, the selected model has the minimum AIC of all possible main effects models.\n\nprint(f'AIC: {full_model.aic}')\n\nAIC: 655.2701107463729\n\n\n\nprint(f'AIC: {selected_model.aic}')\n\nAIC: 647.5113366053722"
  },
  {
    "objectID": "slides/18-prediction-uncertainty.html#parismony",
    "href": "slides/18-prediction-uncertainty.html#parismony",
    "title": "Prediction + uncertainty",
    "section": "Parismony",
    "text": "Parismony\n\n\n\nLook at the variables in the full and the selected model. Can you guess why some of them may have been dropped? Remember: We like parsimonious models.\n\n\n\n\n\nvariable\nselected\n\n\n\n\nchocolate\nx\n\n\nfruity\nx\n\n\ncaramel\n\n\n\npeanutyalmondy\nx\n\n\nnougat\n\n\n\ncrispedricewafer\nx\n\n\nhard\nx\n\n\nbar\n\n\n\npluribus\n\n\n\nsugarpercent\nx\n\n\npricepercent"
  },
  {
    "objectID": "slides/18-prediction-uncertainty.html#new-observation",
    "href": "slides/18-prediction-uncertainty.html#new-observation",
    "title": "Prediction + uncertainty",
    "section": "New observation",
    "text": "New observation\nTo make a prediction for a new observation we need to create a data frame with that observation.\n\nSuppose we want to make a prediction for a candy that contains chocolate, isn’t fruity, has no peanuts or almonds, has a wafer, isn’t hard, and has a sugar content in the 20th percentile.\n\nThe following will result in an incorrect prediction. Why? How would you correct it?\n\n\nnew_candy = pd.DataFrame({'chocolate': [1], 'fruity': [0], 'peanutyalmondy': [0], 'crispedricewafer': [1], 'hard': [0], 'sugarpercent': [20]})"
  },
  {
    "objectID": "slides/18-prediction-uncertainty.html#new-observation-corrected",
    "href": "slides/18-prediction-uncertainty.html#new-observation-corrected",
    "title": "Prediction + uncertainty",
    "section": "New observation, corrected",
    "text": "New observation, corrected\n\nnew_candy = pd.DataFrame({'chocolate': [1], 'fruity': [0], 'peanutyalmondy': [0], 'crispedricewafer': [1], 'hard': [0], 'sugarpercent': [0.20]})\nnew_candy\n\n\n\n\n\n\n\n\nchocolate\nfruity\npeanutyalmondy\ncrispedricewafer\nhard\nsugarpercent\n\n\n\n\n0\n1\n0\n0\n1\n0\n0.2"
  },
  {
    "objectID": "slides/18-prediction-uncertainty.html#prediction-1",
    "href": "slides/18-prediction-uncertainty.html#prediction-1",
    "title": "Prediction + uncertainty",
    "section": "Prediction",
    "text": "Prediction\n\nprediction = selected_model.predict(new_candy)\nprint(f'Prediction: {prediction}')\n\nPrediction: 0    62.068526\ndtype: float64"
  },
  {
    "objectID": "slides/18-prediction-uncertainty.html#uncertainty-around-prediction",
    "href": "slides/18-prediction-uncertainty.html#uncertainty-around-prediction",
    "title": "Prediction + uncertainty",
    "section": "Uncertainty around prediction",
    "text": "Uncertainty around prediction\n\n\nConfidence interval around \\(\\hat{y}\\) for new data (average win percentage for candy types with the given characteristics):\n\n\nconfidence_interval = selected_model.get_prediction(new_candy).conf_int()\nprint(f'Confidence Interval: {confidence_interval}')\n\nConfidence Interval: [[53.65186346 70.48518939]]\n\n\n\n\n\nPrediction interval around \\(\\hat{y}\\) for new data (predicted score for an individual type of candy with the given characteristics ):\n\n\nprediction_interval = selected_model.get_prediction(new_candy).summary_frame(alpha=0.05)\nprint(f'Prediction Interval: {prediction_interval}')\n\nPrediction Interval:         mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n0  62.068526  4.227679      53.651863      70.485189     39.549428   \n\n   obs_ci_upper  \n0     84.587625  \n\n\n\n\n\n\n\n🔗 datasciaz.netlify.app"
  },
  {
    "objectID": "project/1-working-collaboratively.html",
    "href": "project/1-working-collaboratively.html",
    "title": "Working collaboratively",
    "section": "",
    "text": "Data science is a collaborative discipline. Pretty much no data scientist works alone, so neither should you! In this course you’ll collaborate with teammates on the project.\nThe first milestone of the project, today’s activity, will introduce you to the technical aspects of collaborating on a reproducible data science project that is version controlled by Git and hosted on GitHub in a repository shared by all teammates.\nYes, this means you and all of your teammates will be pushing to the same repository! Sometimes things will go swimmingly, and sometimes you’ll run into merge conflicts."
  },
  {
    "objectID": "project/1-working-collaboratively.html#activity",
    "href": "project/1-working-collaboratively.html#activity",
    "title": "Working collaboratively",
    "section": "Activity",
    "text": "Activity\n\nSetup\n\nClone the project repo and open the about.qmd file.\nAssign the numbers 1, 2, 3, 4, and 5 to each of the team members. If your team has fewer than 5 people, some people will need to have multiple numbers.\n\n\n\nLet’s cause a merge conflict!\nOur goal is to see two different types of merges: first we’ll see a type of merge that git can’t figure out on its own how to do on its own (a merge conflict) and requires human intervention, then another type of where that git can figure out how to do without human intervention.\nDoing this will require some tight choreography, so pay attention!\nTake turns in completing the exercise, only one member at a time. Others should just watch, not doing anything on their own projects (this includes not even pulling changes!) until they are instructed to. If you feel like you won’t be able to resist the urge to touch your computer when it’s not your turn, we recommend putting your hands in your pockets or sitting on them!\n\nBefore starting\nEveryone should have the repo cloned and know which role number(s) they are.\nAlso, any teammates who haven’t done this before should go to their Terminal and type git config pull.rebase false to set up their preferences for pulling.\n\n\nRole 1\n\nGo to about.qmd in your project repo. Change the [team name] to your actual team name.\nRender the project by clicking on Render in the Build tab, commit (all changed files), and push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\n\n\nRole 2\n\nChange the team name to some other word.\nRender the project by clicking on Render in the Build tab, commit (all changed files), and push. You should get an error.\nPull. Take a look at the document (about.qmd) with the merge conflict.\nClear the merge conflict by editing the document to choose the correct/preferred change.\nRender the project by clicking on Render in the Build tab.\nClick the Stage checkbox for all files in your Git tab. Make sure they all have check marks, not filled-in boxes.\nCommit and push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\n\n\nRole 3\n\nChange the a name of the first team member.\nRender the project by clicking on Render in the Build tab, commit, push. You should get an error.\nPull. No merge conflicts should occur, but you should see a message about merging.\nNow push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\n\n\nRole 4\n\nChange the a name of the first team member to something other than what the previous team member did.\nRender the project by clicking on Render in the Build tab, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict. Clear the merge conflict by choosing the correct/preferred change. Render the project by clicking on Render in the Build tab, commit, and push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\n\n\nRole 5\n\nChange the a name of the rest of the team members and add descriptions for each person with the help of your team members. Role 5 should be the only one typing, the others should help verbally.\nRender the project by clicking on Render in the Build tab and commit. Discuss as a team what you expect to happen when you hit push. Should there be a merge conflict error or not?\nIf there is a merge conflict, fix it. If not, push your changes.\n\n\n\nEveryone\nPull, and observe the changes in your project."
  },
  {
    "objectID": "project/1-working-collaboratively.html#tips-for-collaborating-via-github",
    "href": "project/1-working-collaboratively.html#tips-for-collaborating-via-github",
    "title": "Working collaboratively",
    "section": "Tips for collaborating via GitHub",
    "text": "Tips for collaborating via GitHub\n\nAlways pull first before you start working.\nResolve a merge conflict (render and push) before continuing your work. Never do new work while resolving a merge conflict.\nRender, commit, and push often to minimize merge conflicts and/or to make merge conflicts easier to resolve.\nIf you find yourself in a situation that is difficult to resolve, ask questions ASAP. Don’t let it linger and get bigger."
  },
  {
    "objectID": "project/3-peer-review.html",
    "href": "project/3-peer-review.html",
    "title": "Peer review",
    "section": "",
    "text": "During the peer feedback process, you will be provided read-only access to your partner team’s GitHub repo. You will provide your feedback in the form of GitHub issues to your partner team’s GitHub repo."
  },
  {
    "objectID": "project/3-peer-review.html#part-1",
    "href": "project/3-peer-review.html#part-1",
    "title": "Peer review",
    "section": "Part 1",
    "text": "Part 1\nDuring the first ~30 minutes, make progress on your own project.\n\nReview the feedback from your Instructor.\nChoose the dataset you want to work with.\nMake progress on your analysis and write-up in index.qmd:\n\nAt a minimum, write a plan that peers can give feedback on.\nTime permitting, start the analysis.\n\nRender the project, commit and push all your changes.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure you always render before you commit and push. If you don’t render first, you’re going to end up with merge conflicts that are difficult to resolve in auxiliary files created during the render process."
  },
  {
    "objectID": "project/3-peer-review.html#part-2",
    "href": "project/3-peer-review.html#part-2",
    "title": "Peer review",
    "section": "Part 2",
    "text": "Part 2\nReview one other team’s project. As a team you should spend ~30 minutes on each team’s project.\n\nFind the names of the teams whose projects you’re reviewing below. You should already have access to this team’s repo.\nEach team member should go to the repo of the team you’re reviewing.\nThen,\n\n1-2 team members clone the team’s project and renders it to check for reproducibility.\n1-2 team members open the team’s project in their browser and starts reading through the project draft.\n1 team member opens an issue on the team’s repo using the peer review template.\nAll team members discuss the project based on the prompts on the issue template and one team member records the feedback and submits the issue.\n\nTo open an issue in the repo you’re reviewing, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical reasoning aspect of the project, but do feel free to comment on aspects beyond the reasoning as well.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation.\nWere you able to reproduce the project by clicking on Render Website once you cloned it? Were there any issues with reproducibility?\nProvide constructive feedback on any issues with file and/or code organization.\nWhat have you learned from this team’s project that you are considering implementing in your own project?\n(Optional) Any further comments or feedback?"
  },
  {
    "objectID": "project/description.html",
    "href": "project/description.html",
    "title": "Flood Risk Prediction Challenge",
    "section": "",
    "text": "Flooding is one of the most common and destructive natural disasters in the United States, causing billions of dollars in damage each year. Accurate flood risk prediction is essential for disaster preparedness, resource allocation, and mitigation efforts.\nThis project challenges you to analyze a real-world dataset of environmental and geospatial features and build a machine learning model that predicts flood risk scores for various regions. You will apply your skills in data cleaning, exploratory data analysis (EDA), feature engineering, and predictive modeling to solve this practical problem.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#reproducibility-organization",
    "href": "project/description.html#reproducibility-organization",
    "title": "Flood Risk Prediction Challenge",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nPoints for reproducibility + organization will be based on the reproducibility of the write-up and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#getting-started",
    "href": "project/description.html#getting-started",
    "title": "Flood Risk Prediction Challenge",
    "section": "Getting Started",
    "text": "Getting Started\n\nDownload the Dataset: Access the training and test datasets from the project repository.\nSet Up Your Environment: Ensure you have Python and essential libraries installed (e.g., Pandas, NumPy, Scikit-learn, Matplotlib).\nFollow the Workflow: Preprocess the data, conduct EDA, engineer features, train your model, and make predictions.\nSubmit Your Work: Upload your notebook and predictions to the provided submission platform.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#tools-and-resources",
    "href": "project/description.html#tools-and-resources",
    "title": "Flood Risk Prediction Challenge",
    "section": "Tools and Resources",
    "text": "Tools and Resources\n\nProgramming Language: Python\nKey Libraries: Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn\nResources: Documentation on regression models, MAE, and data visualization techniques.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#lectures",
    "href": "course-support.html#lectures",
    "title": "Course support",
    "section": "Lectures",
    "text": "Lectures\nIf you have a question during lecture, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours here.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#slack",
    "href": "course-support.html#slack",
    "title": "Course support",
    "section": "Slack",
    "text": "Slack\nHave a question that can’t wait for office hours? Prefer to write out your question in detail rather than asking in person? The course Slack is the best venue for these! There is a chance another student has already asked a similar question, so please check the other posts on Slack before asking a new question. If you know the answer to a question that is posted, I encourage you to respond! I rarely respond to Slack messages sent Friday evening - Sunday, nor would I expect you to.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nPlease refrain from emailing any course content questions (those should go to Slack), and only use email for questions about personal matters that may not be appropriate for the public course forum (e.g., illness, accommodations, etc.). For such matters, you may email Dr. Greg Chism at gchism@arizona.edu.\nIf there is a question that’s not appropriate for the public forum, you are welcome to email me directly. If you email me, please include “INFO 511” in the subject line. Barring extenuating circumstances, I will respond to INFO 511 emails within 48 hours Monday - Friday. I do not respond to emails sent Friday evening - Sunday, nor would I expect you to.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#how-to-ask-for-help",
    "href": "course-support.html#how-to-ask-for-help",
    "title": "Course support",
    "section": "How to Ask For Help",
    "text": "How to Ask For Help\nWe’ll see in this course that a key skill that you should develop as a data scientist is the ability to find solutions to problems. Knowing how to get help is part of that skill.\n\nBefore you ask for help:\n\nCheck for typos. One of the most common causes of errors are typos, which usually throw an error such as NameError: name '_____ ' is not defined due to a variable or function being misspelled.\nCheck imported modules. You also get errors like AttributeError: module '_____ ' has no attribute '_____ ' when you fail to import a module or incorrectly import it.\nRead the error message. Don’t ignore what Python is telling you. Be aware that red text that appears in your console is not always an indication of errors. Sometimes it’s just a warning or a message.\nGoogle is your friend. Copy and paste the exact error message on a Google search. (this step also includes read the documentation on the package you’re trying to use).\nIf you are still stuck, you an always try rubber duck debugging. Describe the problem aloud, explaining it line-by-line, to a rubber duck or another person (who might not have any experience with programming of data science). This is also a good preparation step to asking other people for help (next section).\n\n\n\nAsk other people for help\nLike mentioned before, you should ask your peers for help before you ask your instructor. Relying on a single person to solve all of your problems is dangerous, because that person won’t be available throughout your career as a data scientist.\n\nCheck our Slack to see if someone else has asked a question similar to yours, and whether there’s a solution posted for it.\nBe precise and informative. The more context you can provide about what you’re trying to do and what errors you’re getting, the better. Also describe the steps you took to try to solve the problem yourself.\n\n\n\nList of resources\n\nGetting Help with Python\nRoger Peng’s How To Get Help video\nRubber Duck Debugging",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Student Success & Retention Innovation (SOS) offers free services to all students during their graduate careers at UArizona. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at UArizona.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#mental-health-and-wellness",
    "href": "course-support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\nStudent mental health and wellness are of primary importance at UArizona, and the university offers resources to support students in managing daily stress and self-care. Campus Health offers several resources for students to seek assistance on coursework and to nurture daily habits that support overall well-being, some of which are listed below. For medical appointments, call (520) 621-9202. For After Hours care, call (520) 570-7898. For the Counseling & Psych Services (CAPS) 24/7 hotline, call (520) 621-3334\n\nAcademic advising: If you have questions about your academic progress this semester, or your chosen degree program, consider contacting your department’s academic advisor(s).  Your academic advisor and the Advising Resource Center can guide you toward university resources to help you succeed.\nSpiritual Wellness: CAPS: (520) 621-3334, provides Moments of Mindfulness (stress management and resilience building) and meditation programming to assist students in developing a daily emotional well-being practice. To see schedules for programs please see https://caps.arizona.edu/spiritual-wellness. All are welcome and no experience necessary.\n\nIf your mental health concerns and/or stressful events negatively affect your daily emotional state, academic performance, or ability to participate in your daily activities, many resources are available to help you through difficult times. UArizona encourages all students to access these resources.\n\nStudent Supporter Hub: Provides comprehensive services to identify and support students in managing all aspects of well-being. If you have concerns about a student’s behavior or health visit the website for resources and assistance: https://caps.arizona.edu/student-supporter.\nCounseling & Psychological Services (CAPS): CAPS services include individual and group counseling services, psychiatric services, and workshops. To initiate services, walk-in/call-in 8am-4:30pm M,Tu,Th,F and 9am-4:30pm Wednesdays; (520) 621-3334. CAPS also provides referral to off-campus resources for specialized care: https://caps.arizona.edu/caps-student-support-outreach-request.\nCrisis Support: After-hours crisis callers may speak with a licensed counselor by pressing 1 when prompted by the automatic message: https://caps.arizona.edu/crisis-resources-hotlines.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#course-costs",
    "href": "course-support.html#course-costs",
    "title": "Course support",
    "section": "Course costs",
    "text": "Course costs\n\nTextbooks: The textbooks for this course are freely available on the web.\nLaptops: Each student is expected to have a laptop they can bring to each lecture and lab.\n\nIf you are having difficulty with costs associated with this course, here are some resources:\n\nContact the financial aid office (whether or not you are on aid). They have loans and resources for connecting students with programs on campus that might be able to help alleviate these costs.\nFor course-specific technology needs such as Digital Voice Recorder, HD Video Camera, TI-84 Plus CE, DSLR camera kit, Tripod, Microphones, iPad Mini, a Handheld Projector, or a GoPro, you can reserve rental equipment from the Link.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#assistance-with-zoom-or-d2l",
    "href": "course-support.html#assistance-with-zoom-or-d2l",
    "title": "Course support",
    "section": "Assistance with Zoom or D2L",
    "text": "Assistance with Zoom or D2L\nFor technical help with D2L or Zoom, contact the UArizona OIT Service Desk at it.arizona.edu/get-support. You can also access the self-service help documentation for Zoom here and for D2L here.\nNote that we will be making minimal use of D2L in this course (primarily for announcements and grade book). All assignment submission will take place on GitHub and conversation on Slack.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "computing/computing-python.html",
    "href": "computing/computing-python.html",
    "title": "Setting up Python",
    "section": "",
    "text": "The steps to installing Python are seemingly straightforward but can result in an array of different bugs. For INFO 511, I’ve chosen a workflow that will standardize your installations and (hopefully) prevent these bugs.",
    "crumbs": [
      "Computing",
      "Setting up Python"
    ]
  },
  {
    "objectID": "computing/computing-python.html#introduction",
    "href": "computing/computing-python.html#introduction",
    "title": "Setting up Python",
    "section": "",
    "text": "The steps to installing Python are seemingly straightforward but can result in an array of different bugs. For INFO 511, I’ve chosen a workflow that will standardize your installations and (hopefully) prevent these bugs.",
    "crumbs": [
      "Computing",
      "Setting up Python"
    ]
  },
  {
    "objectID": "computing/computing-python.html#installing-vs-code",
    "href": "computing/computing-python.html#installing-vs-code",
    "title": "Setting up Python",
    "section": "Installing VS Code",
    "text": "Installing VS Code\n\nFor all OS:\n\nSee the following link: https://code.visualstudio.com/download\n\n\n\n\n\n\n\nRun through your device’s appropriate installation.",
    "crumbs": [
      "Computing",
      "Setting up Python"
    ]
  },
  {
    "objectID": "computing/computing-python.html#installing-bash",
    "href": "computing/computing-python.html#installing-bash",
    "title": "Setting up Python",
    "section": "Installing Bash",
    "text": "Installing Bash\n\nFor PC\n\nOpen Windows PowerShell as Administrator\nType wsl –install and press Enter\nRestart your computer\nOpen the Microsoft Store.\nInstall a Linux distribution (e.g., Ubuntu).\n\nSearch for “Ubuntu” (or any other preferred distribution) and click “Install”.\n\nSet up your Linux environment.\n\nOnce installed, open the Linux distribution from the Start menu and follow the setup instructions.\n\n\n\n\nFor Mac:\n\nYou already have zsh, which is a Bash Shell 😊",
    "crumbs": [
      "Computing",
      "Setting up Python"
    ]
  },
  {
    "objectID": "computing/computing-python.html#open-a-bash-shell-terminal",
    "href": "computing/computing-python.html#open-a-bash-shell-terminal",
    "title": "Setting up Python",
    "section": "Open a Bash Shell terminal",
    "text": "Open a Bash Shell terminal\n\nFor PC:\n\nPress CTRL + ALT + T simultaneously to open the terminal.\nType bash then press Enter\nYou should have a Bash shell ready.\n\n\n\nFor Mac:\nDo one of the following:\n\nClick the Launchpad icon  in the Dock, type Terminal in the search field, then click Terminal.\nIn the Finder , open the /Applications/Utilities folder, then double-click Terminal.",
    "crumbs": [
      "Computing",
      "Setting up Python"
    ]
  },
  {
    "objectID": "computing/computing-python.html#install-homebrew",
    "href": "computing/computing-python.html#install-homebrew",
    "title": "Setting up Python",
    "section": "Install Homebrew",
    "text": "Install Homebrew\n\nFor Mac and PC:\n\nHomebrew is a package manager for macOS and Linux that makes it easy to install software. In open Bash Terminal, type:\n\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\nRun through any installation steps found within the terminal.",
    "crumbs": [
      "Computing",
      "Setting up Python"
    ]
  },
  {
    "objectID": "computing/computing-python.html#install-miniconda-via-homebrew",
    "href": "computing/computing-python.html#install-miniconda-via-homebrew",
    "title": "Setting up Python",
    "section": "Install Miniconda (via Homebrew)",
    "text": "Install Miniconda (via Homebrew)\n\nFor both Mac and PC\n\nType the install command into the open terminal:\n\nbrew install --cask miniconda\n\nFun the following to setup your shell:\n\nconda init \"$(basename \"${SHELL}\")\"",
    "crumbs": [
      "Computing",
      "Setting up Python"
    ]
  },
  {
    "objectID": "computing/computing-python.html#install-python3",
    "href": "computing/computing-python.html#install-python3",
    "title": "Setting up Python",
    "section": "Install Python3",
    "text": "Install Python3\n\nFor Mac and PC:\n\nRun the following in your terminal (check the latest Python3 version):\n\nconda create -y -n py38 python=3.12.4 pip\n\n\nFor PC (Bash)\n\nRun the following in your terminal (this step may not work given permissions):\n\necho \"conda activate py38\" &gt;&gt; ~/.bashrc\n\n\nFor Mac (Zsh)\n\nRun the following in your terminal (this step may not work given permissions):\n\necho \"conda activate py38\" &gt;&gt; ~/.zshrc\n\n\nFor Mac and PC:\n\nRun the following in your terminal:\n\nconda activate py38\npip install -U pip\npip install pytest\npip cache purge\nconda clean -y -av\npython -V\npip -V\n\nRestart your computer + Open VSCode",
    "crumbs": [
      "Computing",
      "Setting up Python"
    ]
  },
  {
    "objectID": "computing/computing-python.html#prepare-vs-code-for-python",
    "href": "computing/computing-python.html#prepare-vs-code-for-python",
    "title": "Setting up Python",
    "section": "Prepare VS Code for Python",
    "text": "Prepare VS Code for Python\n\nOnce VS Code is open, click on the Explorer:\n\n\n\n\n\n\n\nClick “Clone Repository”:\n\n\n\n\n\n\n\nPaste the following into the text input that pops up in the top-middle: https://github.com/INFO-511-F24/ae-00-unvotes.git, which can be found at the ae-00-unvotes exercise GitHub page:\n\n\n\n\n\n\n\nClick “Open”:\n\n\n\n\n\n\n\nSelect the unvotes.ipynb file:\n\n\n\n\n\n\n\nClick the “Select Kernel” button in the top-right above the Jupyter Notebook:\n\n\n\n\n\n\n\nSelect “Python Environments” from the middle-center drop-down options:\n\n\n\n\n\n\n\nFrom the options, select the one with “Homebrew” or “Miniconda” within in (this may look different for you than me:",
    "crumbs": [
      "Computing",
      "Setting up Python"
    ]
  },
  {
    "objectID": "computing/computing-python.html#install-python-packages",
    "href": "computing/computing-python.html#install-python-packages",
    "title": "Setting up Python",
    "section": "Install Python Packages",
    "text": "Install Python Packages\n\nType the following into your terminal:\n\npip install numpy pandas matplotlib seaborn scikit-learn scipy statsmodels nltk jupyter notebook jupyterlab ipython plotly xlrd openpyxl requests beautifulsoup4 lxml",
    "crumbs": [
      "Computing",
      "Setting up Python"
    ]
  },
  {
    "objectID": "computing/computing-python.html#move-onto-setting-up-git",
    "href": "computing/computing-python.html#move-onto-setting-up-git",
    "title": "Setting up Python",
    "section": "Move onto setting up Git",
    "text": "Move onto setting up Git",
    "crumbs": [
      "Computing",
      "Setting up Python"
    ]
  },
  {
    "objectID": "computing/computing-cheatsheets.html",
    "href": "computing/computing-cheatsheets.html",
    "title": "Python cheatsheets",
    "section": "",
    "text": "The following cheatsheets come from tsinghua-gongjing.github.io/posts/cheatsheet_collections. We will not covered every function and functionality listed on them, but you might still find them useful as references.",
    "crumbs": [
      "Computing",
      "Cheatsheets"
    ]
  },
  {
    "objectID": "computing/computing-troubleshooting.html",
    "href": "computing/computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you’re having difficulty launching an JupyterLab, go to status.jupyter.org and find the Notebook Viewer dropdown section at the top.\n\nIf the status shows something other than Operational, this means there is a known incident with the cloud. Check back later to see if it’s been resolved. If there’s a deadline coming up soon, post on the course Slack to let us know that there’s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don’t anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you’ve tried and the errors you see (including verbatim errors and/or screenshots).",
    "crumbs": [
      "Computing",
      "Troubleshooting"
    ]
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Course overview",
    "section": "",
    "text": "This is the homepage for INFO 511 - Fundamentals of Data Science taught by Dr. Greg Chism in Spring 2025 at The University of Arizona. All course materials will be posted on this site.\nYou can find the course syllabus here and the course schedule here.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#class-meetings",
    "href": "course-overview.html#class-meetings",
    "title": "Course overview",
    "section": "Class meetings",
    "text": "Class meetings\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLecture\nOnline\nAsynchronous",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  }
]